{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        ['recent', 'developments', 'bifunctional', 'ai...\n",
       "1        ['benefit', 'punishment', 'sensitivity', 'moto...\n",
       "2        ['magic', 'biomarkers', 'predict', 'longterm',...\n",
       "3        ['endocrine', 'disrupting', 'compounds', 'envi...\n",
       "4        ['probabilistic', 'regular', 'grammar', 'infer...\n",
       "                               ...                        \n",
       "20211    ['prediction', 'diagnosis', 'chronic', 'kidney...\n",
       "20212    ['incidence', 'healthcareassociated', 'urinary...\n",
       "20213    ['turmericloaded', 'alginate', 'particulatebas...\n",
       "20214    ['identification', 'novel', 'gut', 'microbiota...\n",
       "20215    ['effectiveness', '1', '2per', 'cent', 'acetic...\n",
       "Name: Processed Words, Length: 20216, dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pandas as pd\n",
    "\n",
    "path1 = \"/Users/dear/Data Science/Project/Data-Sci-project/results/data_formatted_subjectAreas.csv\"\n",
    "path2 = \"C:/Users/PangSunatcha/OneDrive - Chulalongkorn University/Documents/Y2S1 files/Data Sci/proj/Data-Sci-project/results/data_formatted_subjectAreas.csv\"\n",
    "df = pd.read_csv(path2)\n",
    "df[\"Processed Words\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [recent, developments, bifunctional, air, elec...\n",
       "1        [benefit, punishment, sensitivity, motor, perf...\n",
       "2        [magic, biomarkers, predict, longterm, outcome...\n",
       "3        [endocrine, disrupting, compounds, environment...\n",
       "4        [probabilistic, regular, grammar, inference, a...\n",
       "                               ...                        \n",
       "20211    [prediction, diagnosis, chronic, kidney, disea...\n",
       "20212    [incidence, healthcareassociated, urinary, tra...\n",
       "20213    [turmericloaded, alginate, particulatebased, b...\n",
       "20214    [identification, novel, gut, microbiota, signa...\n",
       "20215    [effectiveness, 1, 2per, cent, acetic, acid, s...\n",
       "Name: combined keywords, Length: 20216, dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ast\n",
    "\n",
    "df['Processed Words'] = df['Processed Words'].apply(ast.literal_eval)\n",
    "df['Author Keywords'] = df['Author Keywords'].fillna('')\n",
    "df['combined keywords'] = df.apply(\n",
    "    lambda row: row['Processed Words'] + row['Author Keywords'].split(', '),\n",
    "    axis=1\n",
    ")\n",
    "df['combined keywords']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8830365974282888\n",
      "\n",
      "Classification Report:\n",
      "                                       precision    recall  f1-score   support\n",
      "\n",
      "Agricultural and Biological Sciences       0.94      0.89      0.91       245\n",
      "                 Arts and Humanities       0.85      0.76      0.80        37\n",
      "                        Biochemistry       0.80      0.77      0.78       219\n",
      "                            Business       0.85      0.76      0.80        67\n",
      "                Chemical Engineering       0.94      0.89      0.91       119\n",
      "                           Chemistry       0.85      0.93      0.89       241\n",
      "                    Computer Science       0.88      0.89      0.88       257\n",
      "                   Decision Sciences       1.00      0.25      0.40         4\n",
      "                           Dentistry       0.98      0.94      0.96        53\n",
      "        Earth and Planetary Sciences       0.89      0.78      0.83        60\n",
      "            Econometrics and Finance       0.76      0.76      0.76        38\n",
      "                              Energy       0.86      0.88      0.87       127\n",
      "                         Engineering       0.82      0.85      0.83       259\n",
      "               Environmental Science       0.88      0.86      0.87       180\n",
      "                  Health Professions       0.87      0.74      0.80        27\n",
      "         Immunology and Microbiology       0.93      0.79      0.85       103\n",
      "                   Materials science       0.86      0.89      0.88       198\n",
      "                         Mathematics       0.89      0.74      0.81        54\n",
      "                            Medicine       0.88      0.95      0.91       873\n",
      "                   Multidisciplinary       0.96      0.97      0.96       197\n",
      "                        Neuroscience       0.89      0.78      0.83        76\n",
      "                             Nursing       0.96      0.82      0.88        28\n",
      "               Physics and Astronomy       0.96      0.98      0.97       198\n",
      "                          Psychology       0.86      0.58      0.69        31\n",
      "                     Social Sciences       0.83      0.81      0.82       164\n",
      "        Toxicology and Pharmaceutics       0.92      0.86      0.89       125\n",
      "                          Veterinary       1.00      0.94      0.97        64\n",
      "\n",
      "                            accuracy                           0.88      4044\n",
      "                           macro avg       0.89      0.82      0.84      4044\n",
      "                        weighted avg       0.88      0.88      0.88      4044\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Prepare features and labels\n",
    "# TF-IDF feature extraction\n",
    "df['combined keywords'] = df['combined keywords'].apply(lambda x: ' '.join(x))\n",
    "tfidf = TfidfVectorizer(max_features=5000)\n",
    "tfidf_kw = tfidf.fit_transform(df['combined keywords'])\n",
    "\n",
    "new_tfidf = TfidfVectorizer(max_features=5000)\n",
    "tfidf_pn = new_tfidf.fit_transform(df['Publication Name'])\n",
    "\n",
    "from scipy.sparse import hstack\n",
    "X = hstack([tfidf_kw, tfidf_pn])\n",
    "y = df['Subject Areas']\n",
    "\n",
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# Train Logistic Regression model\n",
    "logreg = LogisticRegression(C = 100, max_iter= 500, penalty= 'l2', solver = 'saga' ,random_state=42) \n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = logreg.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "Best Parameters: {'C': 100, 'max_iter': 500, 'penalty': 'l2', 'solver': 'saga'}\n",
      "Accuracy: 0.8830365974282888\n",
      "\n",
      "Classification Report:\n",
      "                                       precision    recall  f1-score   support\n",
      "\n",
      "Agricultural and Biological Sciences       0.94      0.89      0.91       245\n",
      "                 Arts and Humanities       0.85      0.76      0.80        37\n",
      "                        Biochemistry       0.80      0.77      0.78       219\n",
      "                            Business       0.85      0.76      0.80        67\n",
      "                Chemical Engineering       0.94      0.89      0.91       119\n",
      "                           Chemistry       0.85      0.93      0.89       241\n",
      "                    Computer Science       0.88      0.89      0.88       257\n",
      "                   Decision Sciences       1.00      0.25      0.40         4\n",
      "                           Dentistry       0.98      0.94      0.96        53\n",
      "        Earth and Planetary Sciences       0.89      0.78      0.83        60\n",
      "            Econometrics and Finance       0.76      0.76      0.76        38\n",
      "                              Energy       0.86      0.88      0.87       127\n",
      "                         Engineering       0.82      0.85      0.83       259\n",
      "               Environmental Science       0.88      0.86      0.87       180\n",
      "                  Health Professions       0.87      0.74      0.80        27\n",
      "         Immunology and Microbiology       0.93      0.79      0.85       103\n",
      "                   Materials science       0.86      0.89      0.88       198\n",
      "                         Mathematics       0.89      0.74      0.81        54\n",
      "                            Medicine       0.88      0.95      0.91       873\n",
      "                   Multidisciplinary       0.96      0.97      0.96       197\n",
      "                        Neuroscience       0.89      0.78      0.83        76\n",
      "                             Nursing       0.96      0.82      0.88        28\n",
      "               Physics and Astronomy       0.96      0.98      0.97       198\n",
      "                          Psychology       0.86      0.58      0.69        31\n",
      "                     Social Sciences       0.83      0.81      0.82       164\n",
      "        Toxicology and Pharmaceutics       0.92      0.86      0.89       125\n",
      "                          Veterinary       1.00      0.94      0.97        64\n",
      "\n",
      "                            accuracy                           0.88      4044\n",
      "                           macro avg       0.89      0.82      0.84      4044\n",
      "                        weighted avg       0.88      0.88      0.88      4044\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "# df = pd.read_csv(\"/path/to/data_formatted_subjectAreas.csv\")\n",
    "# df['Processed Words'] = df['Processed Words'].apply(eval)\n",
    "\n",
    "# # Prepare features and labels\n",
    "# X = df['Processed Words'].apply(lambda x: ' '.join(x))\n",
    "# y = df['Subject Areas']\n",
    "\n",
    "# # Split the dataset\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# # TF-IDF feature extraction\n",
    "# tfidf = TfidfVectorizer(max_features=5000)\n",
    "# X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "# X_test_tfidf = tfidf.transform(X_test)\n",
    "\n",
    "# Define parameter grid\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'penalty': ['l2'],\n",
    "    'solver': ['lbfgs', 'saga'],\n",
    "    'max_iter': [100, 500, 1000]\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=LogisticRegression(random_state=42),\n",
    "    param_grid=param_grid,\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters and evaluation\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = best_model.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DSenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
