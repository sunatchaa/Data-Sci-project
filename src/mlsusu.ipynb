{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PangSunatcha\\OneDrive - Chulalongkorn University\\Documents\\Y2S1 files\\Data Sci\\proj\\Data-Sci-project\\src\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Path relative to the script's directory\n",
    "script_dir = os.getcwd()\n",
    "print (script_dir)\n",
    "path = os.path.join(script_dir, \"../results/data_formatted_subjectAreas.csv\")\n",
    "\n",
    "df = pd.read_csv(path)\n",
    "\n",
    "df.dropna(subset=['Title', 'Abstract', 'Author Keywords', 'Publication Name'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Title', 'Cover Date', 'Aggregation Type', 'Authors', 'Subject Areas', 'Author Keywords', 'Abstract', 'Reference Count', 'Publication Name', 'Year', 'Processed Words', 'subject_area_encoded'], dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(16289, 12)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.columns)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8710865561694291\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.87      0.87       222\n",
      "           1       0.85      0.71      0.77        24\n",
      "           2       0.82      0.75      0.78       211\n",
      "           3       0.81      0.84      0.83        68\n",
      "           4       0.92      0.85      0.89        96\n",
      "           5       0.91      0.88      0.90       165\n",
      "           6       0.88      0.88      0.88       214\n",
      "           7       1.00      0.33      0.50         6\n",
      "           8       1.00      0.92      0.96        61\n",
      "           9       0.87      0.82      0.85        50\n",
      "          10       0.72      0.62      0.67        29\n",
      "          11       0.85      0.92      0.88       114\n",
      "          12       0.84      0.84      0.84       217\n",
      "          13       0.84      0.86      0.85       145\n",
      "          14       0.81      0.65      0.72        26\n",
      "          15       0.92      0.80      0.85        84\n",
      "          16       0.85      0.89      0.87       162\n",
      "          17       0.84      0.80      0.82        46\n",
      "          18       0.87      0.96      0.91       697\n",
      "          19       0.90      0.94      0.92        49\n",
      "          20       0.95      0.71      0.81        52\n",
      "          21       0.86      0.69      0.77        26\n",
      "          22       0.93      0.93      0.93       131\n",
      "          23       1.00      0.47      0.64        30\n",
      "          24       0.82      0.87      0.85       148\n",
      "          25       0.94      0.90      0.92       127\n",
      "          26       0.95      0.97      0.96        58\n",
      "\n",
      "    accuracy                           0.87      3258\n",
      "   macro avg       0.88      0.80      0.83      3258\n",
      "weighted avg       0.87      0.87      0.87      3258\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "# Encode the target variable\n",
    "label_encoder = LabelEncoder()\n",
    "df['subject_area_encoded'] = label_encoder.fit_transform(df['Subject Areas'])\n",
    "\n",
    "# Split data into features and target\n",
    "X = df[['Title', 'Abstract', 'Author Keywords', 'Publication Name']]\n",
    "y = df['subject_area_encoded']\n",
    "\n",
    "# Split into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define vectorizers for each column\n",
    "title_vectorizer = TfidfVectorizer(max_features=10000, stop_words='english', max_df=0.2)\n",
    "abstract_vectorizer = TfidfVectorizer(max_features=10000, stop_words='english', max_df=0.2)\n",
    "keywords_vectorizer = TfidfVectorizer(max_features=10000, stop_words='english', max_df=0.2)\n",
    "publication_vectorizer = TfidfVectorizer(max_features=5000, stop_words='english', max_df=0.2)\n",
    "\n",
    "# Fit and transform each column separately for the training set\n",
    "X_train_title = title_vectorizer.fit_transform(X_train['Title'])\n",
    "X_train_abstract = abstract_vectorizer.fit_transform(X_train['Abstract'])\n",
    "X_train_keywords = keywords_vectorizer.fit_transform(X_train['Author Keywords'])\n",
    "X_train_publication = publication_vectorizer.fit_transform(X_train['Publication Name'])\n",
    "\n",
    "# Transform the test set using the same vectorizers\n",
    "X_test_title = title_vectorizer.transform(X_test['Title'])\n",
    "X_test_abstract = abstract_vectorizer.transform(X_test['Abstract'])\n",
    "X_test_keywords = keywords_vectorizer.transform(X_test['Author Keywords'])\n",
    "X_test_publication = publication_vectorizer.transform(X_test['Publication Name'])\n",
    "\n",
    "# Combine the transformed columns using hstack\n",
    "X_train_combined = hstack([X_train_title, X_train_abstract, X_train_keywords, X_train_publication])\n",
    "X_test_combined = hstack([X_test_title, X_test_abstract, X_test_keywords, X_test_publication])\n",
    "\n",
    "# Define and train the classifier\n",
    "classifier = LogisticRegression(C=100, max_iter=500, penalty='l2', solver='saga', random_state=50)\n",
    "classifier.fit(X_train_combined, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = classifier.predict(X_test_combined)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1100, 12)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scopus_path = os.path.join(script_dir, \"../results/sscopus_api.csv\")\n",
    "scopusdf = pd.read_csv(scopus_path)\n",
    "scopusdf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['title', 'author', 'publicationName', 'cover_date', 'scopus_id',\n",
      "       'cited_by_count', 'open_access', 'eid', 'aggregationType',\n",
      "       'affiliations', 'link', 'abstract'],\n",
      "      dtype='object') \n",
      " (748, 12)\n"
     ]
    }
   ],
   "source": [
    "scopus = scopusdf[scopusdf.abstract != '[No abstract available]'] \n",
    "scopus = scopus.dropna(subset='abstract')\n",
    "print(scopus.columns,\"\\n\",scopus.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>predicted_subject_area</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Analysing trends of computational urban science and data science approaches for sustainable development</td>\n",
       "      <td>Computer Science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A landmark federal interagency collaboration to promote data science in health care: Million Veteran Program-Computational Health Analytics for Medical Precision to Improve Outcomes Now</td>\n",
       "      <td>Social Sciences</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Regional planning: A failed or flawed project for Africa? Taking advantage of big data science on the horizon</td>\n",
       "      <td>Health Professions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Science and Model Predictive Control:: A survey of recent advances on data-driven MPC algorithms</td>\n",
       "      <td>Biochemistry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Assessment of the relationship between central venous pressure waveform and the severity of tricuspid valve regurgitation using data science</td>\n",
       "      <td>Medicine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data science basis and influencing factors for the evaluation of environmental safety perception in Macau parishes</td>\n",
       "      <td>Engineering</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2D magnetotelluric imaging method based on visionary self-attention mechanism and data science</td>\n",
       "      <td>Mathematics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data science in sustainable entrepreneurship: A multidisciplinary field of applications</td>\n",
       "      <td>Social Sciences</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>A data science framework for profit health assessment: development and validation</td>\n",
       "      <td>Engineering</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Community-Engaged Data Science (CEDS): A Case Study of Working with Communities to Use Data to Inform Change</td>\n",
       "      <td>Social Sciences</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                       title predicted_subject_area\n",
       "0                                                                                    Analysing trends of computational urban science and data science approaches for sustainable development       Computer Science\n",
       "1  A landmark federal interagency collaboration to promote data science in health care: Million Veteran Program-Computational Health Analytics for Medical Precision to Improve Outcomes Now        Social Sciences\n",
       "2                                                                              Regional planning: A failed or flawed project for Africa? Taking advantage of big data science on the horizon     Health Professions\n",
       "3                                                                                      Data Science and Model Predictive Control:: A survey of recent advances on data-driven MPC algorithms           Biochemistry\n",
       "4                                               Assessment of the relationship between central venous pressure waveform and the severity of tricuspid valve regurgitation using data science               Medicine\n",
       "5                                                                         Data science basis and influencing factors for the evaluation of environmental safety perception in Macau parishes            Engineering\n",
       "6                                                                                             2D magnetotelluric imaging method based on visionary self-attention mechanism and data science            Mathematics\n",
       "7                                                                                                    Data science in sustainable entrepreneurship: A multidisciplinary field of applications        Social Sciences\n",
       "8                                                                                                          A data science framework for profit health assessment: development and validation            Engineering\n",
       "9                                                                               Community-Engaged Data Science (CEDS): A Case Study of Working with Communities to Use Data to Inform Change        Social Sciences"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scopus['author_keywords'] = ''\n",
    "\n",
    "# Preprocess the required columns from the scopus DataFrame\n",
    "scopus_transformed_title = title_vectorizer.transform(scopus['title'].fillna(''))\n",
    "scopus_transformed_abstract = abstract_vectorizer.transform(scopus['abstract'].fillna(''))\n",
    "scopus_transformed_keywords = keywords_vectorizer.transform(scopus['author_keywords'].fillna('')) \n",
    "scopus_transformed_publication = publication_vectorizer.transform(scopus['publicationName'].fillna(''))\n",
    "\n",
    "# Combine the features using hstack\n",
    "scopus_combined_features = hstack([\n",
    "    scopus_transformed_title,\n",
    "    scopus_transformed_abstract,\n",
    "    scopus_transformed_keywords,\n",
    "    scopus_transformed_publication\n",
    "])\n",
    "\n",
    "# Use the trained model to predict subject areas\n",
    "scopus_predictions = classifier.predict(scopus_combined_features)\n",
    "\n",
    "# Decode the predicted labels to the original subject area names\n",
    "scopus['predicted_subject_area'] = label_encoder.inverse_transform(scopus_predictions)\n",
    "\n",
    "# Display the results\n",
    "scopus[['title', 'predicted_subject_area']].head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "scopus.to_csv(os.path.join(script_dir, \"../results/predicted_scopus.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ID', 'Title', 'Abstract', 'Authors', 'Published Date', 'Updated Date',\n",
      "       'Comments', 'Primary Category', 'PDF Link', 'Language'],\n",
      "      dtype='object') \n",
      " (300, 10)\n"
     ]
    }
   ],
   "source": [
    "arxiv_path = os.path.join(script_dir, \"../results/arxiv_data.csv\")\n",
    "arxiv = pd.read_csv(arxiv_path)\n",
    "print(arxiv.columns,\"\\n\",arxiv.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>predicted_subject_area</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A framework for understanding data science</td>\n",
       "      <td>Computer Science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Defining Data Science</td>\n",
       "      <td>Physics and Astronomy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Science in Perspective</td>\n",
       "      <td>Computer Science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Science: A Comprehensive Overview</td>\n",
       "      <td>Physics and Astronomy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ten Research Challenge Areas in Data Science</td>\n",
       "      <td>Medicine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>A Survey on Semantics in Automated Data Science</td>\n",
       "      <td>Medicine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>The cost of reading research. A study of Compu...</td>\n",
       "      <td>Medicine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>Accuracy of citation data in Web of Science an...</td>\n",
       "      <td>Medicine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>The KM3NeT Open Science System</td>\n",
       "      <td>Social Sciences</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>Comparing graph data science libraries for que...</td>\n",
       "      <td>Computer Science</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Title predicted_subject_area\n",
       "0           A framework for understanding data science       Computer Science\n",
       "1                                Defining Data Science  Physics and Astronomy\n",
       "2                          Data Science in Perspective       Computer Science\n",
       "3               Data Science: A Comprehensive Overview  Physics and Astronomy\n",
       "4         Ten Research Challenge Areas in Data Science               Medicine\n",
       "..                                                 ...                    ...\n",
       "295    A Survey on Semantics in Automated Data Science               Medicine\n",
       "296  The cost of reading research. A study of Compu...               Medicine\n",
       "297  Accuracy of citation data in Web of Science an...               Medicine\n",
       "298                     The KM3NeT Open Science System        Social Sciences\n",
       "299  Comparing graph data science libraries for que...       Computer Science\n",
       "\n",
       "[300 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arxiv['author_keywords'] = ''\n",
    "arxiv[\"publicationName\"] = ''\n",
    "\n",
    "# Preprocess the required columns from the scopus DataFrame\n",
    "scopus_transformed_title = title_vectorizer.transform(arxiv['Title'].fillna(''))\n",
    "scopus_transformed_abstract = abstract_vectorizer.transform(arxiv['Abstract'].fillna(''))\n",
    "scopus_transformed_keywords = keywords_vectorizer.transform(arxiv['author_keywords'].fillna('')) \n",
    "scopus_transformed_publication = publication_vectorizer.transform(arxiv['publicationName'].fillna(''))\n",
    "\n",
    "# Combine the features using hstack\n",
    "arxiv_combined_features = hstack([\n",
    "    scopus_transformed_title,\n",
    "    scopus_transformed_abstract,\n",
    "    scopus_transformed_keywords,\n",
    "    scopus_transformed_publication\n",
    "])\n",
    "\n",
    "# Use the trained model to predict subject areas\n",
    "arxiv_predictions = classifier.predict(arxiv_combined_features)\n",
    "\n",
    "# Decode the predicted labels to the original subject area names\n",
    "arxiv['predicted_subject_area'] = label_encoder.inverse_transform(arxiv_predictions)\n",
    "\n",
    "# Display the results\n",
    "arxiv[['Title', 'predicted_subject_area']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "arxiv.to_csv(os.path.join(script_dir, \"../results/predicted_arxiv.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Below are previous trials of ml model that were not successful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8717004297114794\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.87      0.87       222\n",
      "           1       0.85      0.71      0.77        24\n",
      "           2       0.82      0.76      0.79       211\n",
      "           3       0.81      0.84      0.83        68\n",
      "           4       0.92      0.85      0.89        96\n",
      "           5       0.90      0.88      0.89       165\n",
      "           6       0.86      0.89      0.88       214\n",
      "           7       1.00      0.33      0.50         6\n",
      "           8       1.00      0.92      0.96        61\n",
      "           9       0.88      0.84      0.86        50\n",
      "          10       0.82      0.62      0.71        29\n",
      "          11       0.86      0.92      0.89       114\n",
      "          12       0.83      0.83      0.83       217\n",
      "          13       0.84      0.85      0.84       145\n",
      "          14       0.81      0.65      0.72        26\n",
      "          15       0.92      0.79      0.85        84\n",
      "          16       0.85      0.88      0.87       162\n",
      "          17       0.84      0.78      0.81        46\n",
      "          18       0.87      0.96      0.91       697\n",
      "          19       0.90      0.94      0.92        49\n",
      "          20       0.97      0.71      0.82        52\n",
      "          21       0.85      0.65      0.74        26\n",
      "          22       0.94      0.93      0.93       131\n",
      "          23       1.00      0.47      0.64        30\n",
      "          24       0.82      0.87      0.84       148\n",
      "          25       0.94      0.91      0.92       127\n",
      "          26       0.95      0.97      0.96        58\n",
      "\n",
      "    accuracy                           0.87      3258\n",
      "   macro avg       0.89      0.80      0.83      3258\n",
      "weighted avg       0.87      0.87      0.87      3258\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Encode the target variable\n",
    "label_encoder = LabelEncoder()\n",
    "df['subject_area_encoded'] = label_encoder.fit_transform(df['Subject Areas'])\n",
    "\n",
    "# Split data into features and target\n",
    "X = df[['Title', 'Abstract', 'Author Keywords', 'Publication Name']]\n",
    "y = df['subject_area_encoded']\n",
    "\n",
    "# Split into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define a ColumnTransformer for preprocessing\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('title_tfidf', TfidfVectorizer(max_features=10000,stop_words='english'), 'Title'),\n",
    "        ('abstract_tfidf', TfidfVectorizer(max_features=10000,stop_words='english'), 'Abstract'),\n",
    "        ('keywords_tfidf', TfidfVectorizer(max_features=10000,stop_words='english'), 'Author Keywords'),\n",
    "        ('publication_tfidf', TfidfVectorizer(max_features=5000,stop_words='english'), 'Publication Name')\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Define the pipeline with a Logistic Regression classifier\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', LogisticRegression(C=100, max_iter=500, penalty='l2', solver='saga', random_state=50))\n",
    "])\n",
    "\n",
    "# Train the pipeline\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6347452424800492\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.58      0.59       222\n",
      "           1       0.50      0.46      0.48        24\n",
      "           2       0.43      0.39      0.41       211\n",
      "           3       0.65      0.59      0.62        68\n",
      "           4       0.53      0.43      0.47        96\n",
      "           5       0.56      0.58      0.57       165\n",
      "           6       0.76      0.79      0.77       214\n",
      "           7       0.00      0.00      0.00         6\n",
      "           8       0.76      0.62      0.68        61\n",
      "           9       0.57      0.40      0.47        50\n",
      "          10       0.58      0.38      0.46        29\n",
      "          11       0.63      0.62      0.63       114\n",
      "          12       0.56      0.65      0.60       217\n",
      "          13       0.58      0.52      0.55       145\n",
      "          14       0.46      0.23      0.31        26\n",
      "          15       0.64      0.54      0.58        84\n",
      "          16       0.59      0.64      0.61       162\n",
      "          17       0.53      0.50      0.52        46\n",
      "          18       0.73      0.88      0.80       697\n",
      "          19       0.26      0.18      0.21        49\n",
      "          20       0.67      0.38      0.49        52\n",
      "          21       0.67      0.38      0.49        26\n",
      "          22       0.87      0.75      0.80       131\n",
      "          23       0.40      0.13      0.20        30\n",
      "          24       0.56      0.68      0.62       148\n",
      "          25       0.55      0.50      0.52       127\n",
      "          26       0.81      0.81      0.81        58\n",
      "\n",
      "    accuracy                           0.63      3258\n",
      "   macro avg       0.57      0.50      0.53      3258\n",
      "weighted avg       0.63      0.63      0.63      3258\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PangSunatcha\\.conda\\envs\\DSenv\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\PangSunatcha\\.conda\\envs\\DSenv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\PangSunatcha\\.conda\\envs\\DSenv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\PangSunatcha\\.conda\\envs\\DSenv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from scipy.sparse import hstack\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Target variable encoding\n",
    "label_encoder = LabelEncoder()\n",
    "df['subject_area_encoded'] = label_encoder.fit_transform(df['Subject Areas'])\n",
    "\n",
    "# Vectorize textual columns\n",
    "tfidf_title = TfidfVectorizer(max_features=500,stop_words='english').fit_transform(df['Title'])\n",
    "tfidf_abstract = TfidfVectorizer(max_features=1000, stop_words='english').fit_transform(df['Abstract'])\n",
    "cv_keywords = CountVectorizer(binary=True).fit_transform(df['Author Keywords'])\n",
    "tfidf_pub_name = TfidfVectorizer(max_features=100,stop_words='english').fit_transform(df['Publication Name'])\n",
    "\n",
    "# Combine features\n",
    "X_combined = hstack([tfidf_title, tfidf_abstract, cv_keywords, tfidf_pub_name])\n",
    "y = df['subject_area_encoded']\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_combined, y, test_size=0.2, random_state=42)\n",
    "\n",
    "logreg = LogisticRegression(C = 100, max_iter= 500, penalty= 'l2', solver = 'saga' ,random_state=50) \n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = logreg.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Subject Areas: ['Medicine' 'Energy' 'Social Sciences' ...\n",
      " 'Agricultural and Biological Sciences' 'Social Sciences' 'Biochemistry']\n",
      "Accuracy: 0.6080417434008594\n",
      "\n",
      "Classification Report:\n",
      "                                       precision    recall  f1-score   support\n",
      "\n",
      "Agricultural and Biological Sciences       0.61      0.54      0.57       222\n",
      "                 Arts and Humanities       1.00      0.25      0.40        24\n",
      "                        Biochemistry       0.59      0.27      0.38       211\n",
      "                            Business       0.86      0.65      0.74        68\n",
      "                Chemical Engineering       0.59      0.42      0.49        96\n",
      "                           Chemistry       0.61      0.67      0.64       165\n",
      "                    Computer Science       0.62      0.88      0.73       214\n",
      "                   Decision Sciences       0.00      0.00      0.00         6\n",
      "                           Dentistry       1.00      0.10      0.18        61\n",
      "        Earth and Planetary Sciences       0.92      0.22      0.35        50\n",
      "            Econometrics and Finance       0.88      0.24      0.38        29\n",
      "                              Energy       0.75      0.68      0.72       114\n",
      "                         Engineering       0.64      0.63      0.64       217\n",
      "               Environmental Science       0.70      0.50      0.58       145\n",
      "                  Health Professions       0.00      0.00      0.00        26\n",
      "         Immunology and Microbiology       0.91      0.24      0.38        84\n",
      "                   Materials science       0.59      0.71      0.65       162\n",
      "                         Mathematics       0.81      0.54      0.65        46\n",
      "                            Medicine       0.51      0.98      0.67       697\n",
      "                   Multidisciplinary       0.87      0.27      0.41        49\n",
      "                        Neuroscience       1.00      0.04      0.07        52\n",
      "                             Nursing       1.00      0.12      0.21        26\n",
      "               Physics and Astronomy       0.98      0.69      0.81       131\n",
      "                          Psychology       1.00      0.10      0.18        30\n",
      "                     Social Sciences       0.63      0.66      0.64       148\n",
      "        Toxicology and Pharmaceutics       0.96      0.17      0.29       127\n",
      "                          Veterinary       0.88      0.50      0.64        58\n",
      "\n",
      "                            accuracy                           0.61      3258\n",
      "                           macro avg       0.74      0.41      0.46      3258\n",
      "                        weighted avg       0.68      0.61      0.57      3258\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PangSunatcha\\.conda\\envs\\DSenv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\PangSunatcha\\.conda\\envs\\DSenv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\PangSunatcha\\.conda\\envs\\DSenv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "\n",
    "# Split data into features and target\n",
    "X = df[['Title', 'Abstract', 'Author Keywords', 'Publication Name']]\n",
    "y = df['Subject Areas']\n",
    "\n",
    "# Split into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define a ColumnTransformer for preprocessing\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('title_tfidf', TfidfVectorizer(stop_words='english'), 'Title'),\n",
    "        ('keywords_tfidf', TfidfVectorizer(stop_words='english'), 'Author Keywords'),\n",
    "        ('abstract_tfidf', TfidfVectorizer(stop_words='english'), 'Abstract'),\n",
    "        ('publication_tfidf', TfidfVectorizer(stop_words='english'), 'Publication Name')\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Define the pipeline with a classifier\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', RandomForestClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "# Train the pipeline\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Display predictions\n",
    "print(\"Predicted Subject Areas:\", y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [fuel, cells, Bifunctional air electrode, Cata...\n",
       "1        [benefit, performance, punishment, reinforceme...\n",
       "2        [, biomarkers, gvhd, predict, acute, outcomes,...\n",
       "3        [Epigenetics, endocrine, Gene expression, Endo...\n",
       "4        [Probabilistic finite state machine, inference...\n",
       "                               ...                        \n",
       "20211    [metaanalysis, development, , chronic, systema...\n",
       "20212    [infections, tertiary care hospital, child, tr...\n",
       "20213    [Gas-generating agent, release, Turmeric extra...\n",
       "20214    [, cancer, signature, identification, gut, nov...\n",
       "20215    [cent, Tympanic membrane, acetic, granular, 1,...\n",
       "Name: combined keywords, Length: 20216, dtype: object"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ast\n",
    "\n",
    "df['Processed Words'] = df['Processed Words'].apply(ast.literal_eval)\n",
    "df['Author Keywords'] = df['Author Keywords'].fillna('')\n",
    "df['combined keywords'] = df.apply(\n",
    "    lambda row: row['Processed Words'] + row['Author Keywords'].split(', '),\n",
    "    axis=1\n",
    ")\n",
    "df['combined keywords'].apply(lambda row: list(set(row)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                   combined keywords\n",
      "0  of URPEMFC due maximum mainly Irbased implemen...\n",
      "1  of often threat performance reinforcement eith...\n",
      "2  development of utero neurological discuss spec...\n",
      "3  of Incremental incremental positive introduce ...\n",
      "4  surfactant of prepare °C optimizing PIT medium...\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "# Combine the relevant text columns into one column for each row\n",
    "df['combined keywords'] = df['Title'] + \" \" + df['Author Keywords'] + \" \" + df['Abstract']\n",
    "\n",
    "# Now split each row's combined text into words (tokens)\n",
    "df['combined keywords'] = df['combined keywords'].apply(lambda x: x.split())\n",
    "\n",
    "# Remove duplicates by converting the list to a set, then back to a list\n",
    "df['combined keywords'] = df['combined keywords'].apply(lambda x: list(set(x)))\n",
    "\n",
    "# Finally, join the words back into a single string for each row\n",
    "df['combined keywords'] = df['combined keywords'].apply(lambda x: ' '.join(x))\n",
    "\n",
    "# Optionally, reset index if necessary\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "df[\"combined keywords\"] = df[\"combined keywords\"].apply(lambda x: ''.join([char for char in x if char not in string.punctuation]))\n",
    "# Check the result\n",
    "print(df[['combined keywords']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9057704112952731\n",
      "\n",
      "Classification Report:\n",
      "                                       precision    recall  f1-score   support\n",
      "\n",
      "Agricultural and Biological Sciences       0.93      0.91      0.92       206\n",
      "                 Arts and Humanities       0.90      0.68      0.78        28\n",
      "                        Biochemistry       0.84      0.81      0.82       183\n",
      "                            Business       0.83      0.85      0.84        62\n",
      "                Chemical Engineering       0.92      0.93      0.92        84\n",
      "                           Chemistry       0.93      0.91      0.92       169\n",
      "                    Computer Science       0.85      0.93      0.89       204\n",
      "                   Decision Sciences       0.00      0.00      0.00         4\n",
      "                           Dentistry       0.96      0.96      0.96        55\n",
      "        Earth and Planetary Sciences       0.88      0.93      0.90        45\n",
      "            Econometrics and Finance       0.88      0.83      0.86        36\n",
      "                              Energy       0.97      0.93      0.95       141\n",
      "                         Engineering       0.87      0.84      0.86       239\n",
      "               Environmental Science       0.92      0.89      0.90       140\n",
      "                  Health Professions       0.87      0.80      0.83        25\n",
      "         Immunology and Microbiology       0.89      0.90      0.90        73\n",
      "                   Materials science       0.88      0.94      0.91       147\n",
      "                         Mathematics       0.95      0.89      0.92        46\n",
      "                            Medicine       0.92      0.95      0.93       745\n",
      "                   Multidisciplinary       0.98      0.95      0.97        66\n",
      "                        Neuroscience       0.88      0.86      0.87        50\n",
      "                             Nursing       0.96      0.93      0.95        28\n",
      "               Physics and Astronomy       0.95      0.93      0.94       120\n",
      "                          Psychology       0.94      0.83      0.88        36\n",
      "                     Social Sciences       0.86      0.86      0.86       148\n",
      "        Toxicology and Pharmaceutics       0.93      0.94      0.93       109\n",
      "                          Veterinary       0.96      0.96      0.96        69\n",
      "\n",
      "                            accuracy                           0.91      3258\n",
      "                           macro avg       0.88      0.86      0.87      3258\n",
      "                        weighted avg       0.91      0.91      0.90      3258\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PangSunatcha\\.conda\\envs\\DSenv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\PangSunatcha\\.conda\\envs\\DSenv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\PangSunatcha\\.conda\\envs\\DSenv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Prepare features and labels\n",
    "# TF-IDF feature extraction\n",
    "\n",
    "tfidf = TfidfVectorizer(max_features=5000,stop_words='english')\n",
    "tfidf_kw = tfidf.fit_transform(df['combined keywords'])\n",
    "\n",
    "new_tfidf = TfidfVectorizer(max_features=5000,stop_words='english')\n",
    "tfidf_pn = new_tfidf.fit_transform(df['Publication Name'])\n",
    "\n",
    "from scipy.sparse import hstack\n",
    "X = hstack([tfidf_kw, tfidf_pn])\n",
    "y = df['Subject Areas']\n",
    "\n",
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=50)\n",
    "\n",
    "\n",
    "# Train Logistic Regression model\n",
    "logreg = LogisticRegression(C = 100, max_iter= 500, penalty= 'l2', solver = 'saga' ,random_state=50) \n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = logreg.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8936696340257171\n",
      "\n",
      "Classification Report:\n",
      "                                       precision    recall  f1-score   support\n",
      "\n",
      "Agricultural and Biological Sciences       0.93      0.90      0.91       220\n",
      "                 Arts and Humanities       0.97      0.88      0.92        33\n",
      "                        Biochemistry       0.84      0.78      0.81       236\n",
      "                            Business       0.82      0.85      0.83        65\n",
      "                Chemical Engineering       0.94      0.82      0.88       102\n",
      "                           Chemistry       0.87      0.96      0.92       260\n",
      "                    Computer Science       0.87      0.90      0.88       232\n",
      "                   Decision Sciences       1.00      0.20      0.33         5\n",
      "                           Dentistry       0.97      0.90      0.93        70\n",
      "        Earth and Planetary Sciences       0.88      0.79      0.84        58\n",
      "            Econometrics and Finance       0.80      0.77      0.79        31\n",
      "                              Energy       0.88      0.85      0.87       117\n",
      "                         Engineering       0.87      0.86      0.87       273\n",
      "               Environmental Science       0.87      0.89      0.88       152\n",
      "                  Health Professions       0.93      0.58      0.72        24\n",
      "         Immunology and Microbiology       0.93      0.83      0.88       107\n",
      "                   Materials science       0.88      0.83      0.86       203\n",
      "                         Mathematics       0.88      0.75      0.81        59\n",
      "                            Medicine       0.88      0.96      0.92       897\n",
      "                   Multidisciplinary       0.97      0.99      0.98       223\n",
      "                        Neuroscience       0.94      0.80      0.86        55\n",
      "                             Nursing       0.96      0.88      0.92        26\n",
      "               Physics and Astronomy       0.96      0.94      0.95       204\n",
      "                          Psychology       0.87      0.77      0.82        35\n",
      "                     Social Sciences       0.85      0.85      0.85       171\n",
      "        Toxicology and Pharmaceutics       0.95      0.91      0.93       117\n",
      "                          Veterinary       0.98      0.93      0.96        69\n",
      "\n",
      "                            accuracy                           0.89      4044\n",
      "                           macro avg       0.91      0.83      0.86      4044\n",
      "                        weighted avg       0.89      0.89      0.89      4044\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Prepare features and labels\n",
    "# TF-IDF feature extraction\n",
    "df['combined keywords'] = df['combined keywords'].apply(lambda x: ' '.join(x))\n",
    "tfidf = TfidfVectorizer(max_features=5000)\n",
    "tfidf_kw = tfidf.fit_transform(df['combined keywords'])\n",
    "\n",
    "new_tfidf = TfidfVectorizer(max_features=5000)\n",
    "tfidf_pn = new_tfidf.fit_transform(df['Publication Name'])\n",
    "\n",
    "from scipy.sparse import hstack\n",
    "X = hstack([tfidf_kw, tfidf_pn])\n",
    "y = df['Subject Areas']\n",
    "\n",
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=50)\n",
    "\n",
    "\n",
    "# Train Logistic Regression model\n",
    "logreg = LogisticRegression(C = 100, max_iter= 500, penalty= 'l2', solver = 'saga' ,random_state=50) \n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = logreg.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PangSunatcha\\.conda\\envs\\DSenv\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'C': 100, 'max_iter': 100, 'penalty': 'l2', 'solver': 'saga'}\n",
      "Accuracy: 0.8919386745796242\n",
      "\n",
      "Classification Report:\n",
      "                                       precision    recall  f1-score   support\n",
      "\n",
      "Agricultural and Biological Sciences       0.93      0.90      0.91       220\n",
      "                 Arts and Humanities       0.97      0.88      0.92        33\n",
      "                        Biochemistry       0.83      0.78      0.81       236\n",
      "                            Business       0.82      0.85      0.83        65\n",
      "                Chemical Engineering       0.93      0.82      0.88       102\n",
      "                           Chemistry       0.87      0.96      0.91       260\n",
      "                    Computer Science       0.87      0.89      0.88       232\n",
      "                   Decision Sciences       1.00      0.20      0.33         5\n",
      "                           Dentistry       0.97      0.91      0.94        70\n",
      "        Earth and Planetary Sciences       0.89      0.81      0.85        58\n",
      "            Econometrics and Finance       0.79      0.74      0.77        31\n",
      "                              Energy       0.87      0.83      0.85       117\n",
      "                         Engineering       0.86      0.86      0.86       273\n",
      "               Environmental Science       0.87      0.89      0.88       152\n",
      "                  Health Professions       0.93      0.58      0.72        24\n",
      "         Immunology and Microbiology       0.93      0.82      0.87       107\n",
      "                   Materials science       0.88      0.83      0.86       203\n",
      "                         Mathematics       0.86      0.75      0.80        59\n",
      "                            Medicine       0.88      0.96      0.92       897\n",
      "                   Multidisciplinary       0.96      0.99      0.98       223\n",
      "                        Neuroscience       0.93      0.78      0.85        55\n",
      "                             Nursing       0.96      0.88      0.92        26\n",
      "               Physics and Astronomy       0.96      0.94      0.95       204\n",
      "                          Psychology       0.87      0.77      0.82        35\n",
      "                     Social Sciences       0.86      0.85      0.86       171\n",
      "        Toxicology and Pharmaceutics       0.95      0.91      0.93       117\n",
      "                          Veterinary       0.98      0.93      0.96        69\n",
      "\n",
      "                            accuracy                           0.89      4044\n",
      "                           macro avg       0.90      0.83      0.85      4044\n",
      "                        weighted avg       0.89      0.89      0.89      4044\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "# df = pd.read_csv(\"/path/to/data_formatted_subjectAreas.csv\")\n",
    "# df['Processed Words'] = df['Processed Words'].apply(eval)\n",
    "\n",
    "# # Prepare features and labels\n",
    "# X = df['Processed Words'].apply(lambda x: ' '.join(x))\n",
    "# y = df['Subject Areas']\n",
    "\n",
    "# # Split the dataset\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# # TF-IDF feature extraction\n",
    "# tfidf = TfidfVectorizer(max_features=5000)\n",
    "# X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "# X_test_tfidf = tfidf.transform(X_test)\n",
    "\n",
    "# Define parameter grid\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'penalty': ['l2'],\n",
    "    'solver': ['lbfgs', 'saga'],\n",
    "    'max_iter': [100, 500, 1000]\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=LogisticRegression(random_state=50),\n",
    "    param_grid=param_grid,\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters and evaluation\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = best_model.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DSenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
