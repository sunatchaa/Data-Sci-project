{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        ['recent', 'developments', 'bifunctional', 'ai...\n",
       "1        ['benefit', 'punishment', 'sensitivity', 'moto...\n",
       "2        ['magic', 'biomarkers', 'predict', 'longterm',...\n",
       "3        ['endocrine', 'disrupting', 'compounds', 'envi...\n",
       "4        ['probabilistic', 'regular', 'grammar', 'infer...\n",
       "                               ...                        \n",
       "20211    ['prediction', 'diagnosis', 'chronic', 'kidney...\n",
       "20212    ['incidence', 'healthcareassociated', 'urinary...\n",
       "20213    ['turmericloaded', 'alginate', 'particulatebas...\n",
       "20214    ['identification', 'novel', 'gut', 'microbiota...\n",
       "20215    ['effectiveness', '1', '2per', 'cent', 'acetic...\n",
       "Name: Processed Words, Length: 20216, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pandas as pd\n",
    "\n",
    "path1 = \"/Users/dear/Data Science/Project/Data-Sci-project/results/data_formatted_subjectAreas.csv\"\n",
    "path2 = \"C:/Users/PangSunatcha/OneDrive - Chulalongkorn University/Documents/Y2S1 files/Data Sci/proj/Data-Sci-project/results/data_formatted_subjectAreas.csv\"\n",
    "df = pd.read_csv(path2)\n",
    "df[\"Processed Words\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [recent, developments, bifunctional, air, elec...\n",
       "1        [benefit, punishment, sensitivity, motor, perf...\n",
       "2        [magic, biomarkers, predict, longterm, outcome...\n",
       "3        [endocrine, disrupting, compounds, environment...\n",
       "4        [probabilistic, regular, grammar, inference, a...\n",
       "                               ...                        \n",
       "20211    [prediction, diagnosis, chronic, kidney, disea...\n",
       "20212    [incidence, healthcareassociated, urinary, tra...\n",
       "20213    [turmericloaded, alginate, particulatebased, b...\n",
       "20214    [identification, novel, gut, microbiota, signa...\n",
       "20215    [effectiveness, 1, 2per, cent, acetic, acid, s...\n",
       "Name: combined keywords, Length: 20216, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ast\n",
    "\n",
    "df['Processed Words'] = df['Processed Words'].apply(ast.literal_eval)\n",
    "df['Author Keywords'] = df['Author Keywords'].fillna('')\n",
    "df['combined keywords'] = df.apply(\n",
    "    lambda row: row['Processed Words'] + row['Author Keywords'].split(', '),\n",
    "    axis=1\n",
    ")\n",
    "df['combined keywords']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4735410484668645\n",
      "\n",
      "Classification Report:\n",
      "                                       precision    recall  f1-score   support\n",
      "\n",
      "Agricultural and Biological Sciences       0.52      0.55      0.53       245\n",
      "                 Arts and Humanities       0.62      0.14      0.22        37\n",
      "                        Biochemistry       0.24      0.19      0.21       219\n",
      "                            Business       0.47      0.22      0.30        67\n",
      "                Chemical Engineering       0.45      0.25      0.32       119\n",
      "                           Chemistry       0.32      0.35      0.33       241\n",
      "                    Computer Science       0.52      0.61      0.56       257\n",
      "                   Decision Sciences       0.00      0.00      0.00         4\n",
      "                           Dentistry       0.53      0.30      0.39        53\n",
      "        Earth and Planetary Sciences       0.63      0.20      0.30        60\n",
      "            Econometrics and Finance       0.29      0.05      0.09        38\n",
      "                              Energy       0.39      0.39      0.39       127\n",
      "                         Engineering       0.36      0.43      0.39       259\n",
      "               Environmental Science       0.38      0.35      0.36       180\n",
      "                  Health Professions       0.00      0.00      0.00        27\n",
      "         Immunology and Microbiology       0.49      0.23      0.32       103\n",
      "                   Materials science       0.36      0.40      0.38       198\n",
      "                         Mathematics       0.85      0.20      0.33        54\n",
      "                            Medicine       0.53      0.92      0.67       873\n",
      "                   Multidisciplinary       0.31      0.11      0.16       197\n",
      "                        Neuroscience       0.63      0.16      0.25        76\n",
      "                             Nursing       0.88      0.25      0.39        28\n",
      "               Physics and Astronomy       0.78      0.62      0.69       198\n",
      "                          Psychology       0.00      0.00      0.00        31\n",
      "                     Social Sciences       0.49      0.52      0.51       164\n",
      "        Toxicology and Pharmaceutics       0.43      0.12      0.19       125\n",
      "                          Veterinary       0.57      0.25      0.35        64\n",
      "\n",
      "                            accuracy                           0.47      4044\n",
      "                           macro avg       0.45      0.29      0.32      4044\n",
      "                        weighted avg       0.46      0.47      0.44      4044\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PangSunatcha\\.conda\\envs\\DSenv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\PangSunatcha\\.conda\\envs\\DSenv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\PangSunatcha\\.conda\\envs\\DSenv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "\n",
    "# Prepare features and labels\n",
    "X = df['combined keywords'].apply(lambda x: ' '.join(x))\n",
    "y = df['Subject Areas']\n",
    "\n",
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# TF-IDF feature extraction\n",
    "tfidf = TfidfVectorizer(max_features=5000)\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)\n",
    "\n",
    "# Train Logistic Regression model\n",
    "logreg = LogisticRegression(max_iter=1000, random_state=42)\n",
    "logreg.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = logreg.predict(X_test_tfidf)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "Best Parameters: {'C': 1, 'max_iter': 100, 'penalty': 'l2', 'solver': 'saga'}\n",
      "Accuracy: 0.4735410484668645\n",
      "\n",
      "Classification Report:\n",
      "                                       precision    recall  f1-score   support\n",
      "\n",
      "Agricultural and Biological Sciences       0.52      0.55      0.53       245\n",
      "                 Arts and Humanities       0.62      0.14      0.22        37\n",
      "                        Biochemistry       0.25      0.19      0.21       219\n",
      "                            Business       0.47      0.22      0.30        67\n",
      "                Chemical Engineering       0.45      0.25      0.32       119\n",
      "                           Chemistry       0.32      0.35      0.33       241\n",
      "                    Computer Science       0.51      0.60      0.56       257\n",
      "                   Decision Sciences       0.00      0.00      0.00         4\n",
      "                           Dentistry       0.53      0.30      0.39        53\n",
      "        Earth and Planetary Sciences       0.63      0.20      0.30        60\n",
      "            Econometrics and Finance       0.38      0.08      0.13        38\n",
      "                              Energy       0.39      0.39      0.39       127\n",
      "                         Engineering       0.36      0.43      0.39       259\n",
      "               Environmental Science       0.38      0.35      0.36       180\n",
      "                  Health Professions       0.00      0.00      0.00        27\n",
      "         Immunology and Microbiology       0.49      0.23      0.32       103\n",
      "                   Materials science       0.36      0.40      0.38       198\n",
      "                         Mathematics       0.83      0.19      0.30        54\n",
      "                            Medicine       0.53      0.92      0.67       873\n",
      "                   Multidisciplinary       0.30      0.11      0.16       197\n",
      "                        Neuroscience       0.63      0.16      0.25        76\n",
      "                             Nursing       0.88      0.25      0.39        28\n",
      "               Physics and Astronomy       0.79      0.62      0.69       198\n",
      "                          Psychology       0.00      0.00      0.00        31\n",
      "                     Social Sciences       0.49      0.52      0.51       164\n",
      "        Toxicology and Pharmaceutics       0.41      0.10      0.17       125\n",
      "                          Veterinary       0.55      0.27      0.36        64\n",
      "\n",
      "                            accuracy                           0.47      4044\n",
      "                           macro avg       0.45      0.29      0.32      4044\n",
      "                        weighted avg       0.46      0.47      0.44      4044\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PangSunatcha\\.conda\\envs\\DSenv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\PangSunatcha\\.conda\\envs\\DSenv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\PangSunatcha\\.conda\\envs\\DSenv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "# df = pd.read_csv(\"/path/to/data_formatted_subjectAreas.csv\")\n",
    "# df['Processed Words'] = df['Processed Words'].apply(eval)\n",
    "\n",
    "# # Prepare features and labels\n",
    "# X = df['Processed Words'].apply(lambda x: ' '.join(x))\n",
    "# y = df['Subject Areas']\n",
    "\n",
    "# # Split the dataset\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# # TF-IDF feature extraction\n",
    "# tfidf = TfidfVectorizer(max_features=5000)\n",
    "# X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "# X_test_tfidf = tfidf.transform(X_test)\n",
    "\n",
    "# Define parameter grid\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'penalty': ['l2'],\n",
    "    'solver': ['lbfgs', 'saga'],\n",
    "    'max_iter': [100, 500, 1000]\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=LogisticRegression(random_state=42),\n",
    "    param_grid=param_grid,\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "grid_search.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Best parameters and evaluation\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = best_model.predict(X_test_tfidf)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
