{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PangSunatcha\\OneDrive - Chulalongkorn University\\Documents\\Y2S1 files\\Data Sci\\proj\\Data-Sci-project\\src\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0        ['recent', 'developments', 'bifunctional', 'ai...\n",
       "1        ['benefit', 'punishment', 'sensitivity', 'moto...\n",
       "2        ['magic', 'biomarkers', 'predict', 'longterm',...\n",
       "3        ['endocrine', 'disrupting', 'compounds', 'envi...\n",
       "4        ['probabilistic', 'regular', 'grammar', 'infer...\n",
       "                               ...                        \n",
       "20211    ['prediction', 'diagnosis', 'chronic', 'kidney...\n",
       "20212    ['incidence', 'healthcareassociated', 'urinary...\n",
       "20213    ['turmericloaded', 'alginate', 'particulatebas...\n",
       "20214    ['identification', 'novel', 'gut', 'microbiota...\n",
       "20215    ['effectiveness', '1', '2per', 'cent', 'acetic...\n",
       "Name: Processed Words, Length: 20216, dtype: object"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Path relative to the script's directory\n",
    "script_dir = os.getcwd()\n",
    "print (script_dir)\n",
    "path = os.path.join(script_dir, \"../results/data_formatted_subjectAreas.csv\")\n",
    "\n",
    "df = pd.read_csv(path)\n",
    "df[\"Processed Words\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [fuel, cells, Bifunctional air electrode, Cata...\n",
       "1        [benefit, performance, punishment, reinforceme...\n",
       "2        [, biomarkers, gvhd, predict, acute, outcomes,...\n",
       "3        [Epigenetics, endocrine, Gene expression, Endo...\n",
       "4        [Probabilistic finite state machine, inference...\n",
       "                               ...                        \n",
       "20211    [metaanalysis, development, , chronic, systema...\n",
       "20212    [infections, tertiary care hospital, child, tr...\n",
       "20213    [Gas-generating agent, release, Turmeric extra...\n",
       "20214    [, cancer, signature, identification, gut, nov...\n",
       "20215    [cent, Tympanic membrane, acetic, granular, 1,...\n",
       "Name: combined keywords, Length: 20216, dtype: object"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ast\n",
    "\n",
    "df['Processed Words'] = df['Processed Words'].apply(ast.literal_eval)\n",
    "df['Author Keywords'] = df['Author Keywords'].fillna('')\n",
    "df['combined keywords'] = df.apply(\n",
    "    lambda row: row['Processed Words'] + row['Author Keywords'].split(', '),\n",
    "    axis=1\n",
    ")\n",
    "df['combined keywords'].apply(lambda row: list(set(row)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8936696340257171\n",
      "\n",
      "Classification Report:\n",
      "                                       precision    recall  f1-score   support\n",
      "\n",
      "Agricultural and Biological Sciences       0.93      0.90      0.91       220\n",
      "                 Arts and Humanities       0.97      0.88      0.92        33\n",
      "                        Biochemistry       0.84      0.78      0.81       236\n",
      "                            Business       0.82      0.85      0.83        65\n",
      "                Chemical Engineering       0.94      0.82      0.88       102\n",
      "                           Chemistry       0.87      0.96      0.92       260\n",
      "                    Computer Science       0.87      0.90      0.88       232\n",
      "                   Decision Sciences       1.00      0.20      0.33         5\n",
      "                           Dentistry       0.97      0.90      0.93        70\n",
      "        Earth and Planetary Sciences       0.88      0.79      0.84        58\n",
      "            Econometrics and Finance       0.80      0.77      0.79        31\n",
      "                              Energy       0.88      0.85      0.87       117\n",
      "                         Engineering       0.87      0.86      0.87       273\n",
      "               Environmental Science       0.87      0.89      0.88       152\n",
      "                  Health Professions       0.93      0.58      0.72        24\n",
      "         Immunology and Microbiology       0.93      0.83      0.88       107\n",
      "                   Materials science       0.88      0.83      0.86       203\n",
      "                         Mathematics       0.88      0.75      0.81        59\n",
      "                            Medicine       0.88      0.96      0.92       897\n",
      "                   Multidisciplinary       0.97      0.99      0.98       223\n",
      "                        Neuroscience       0.94      0.80      0.86        55\n",
      "                             Nursing       0.96      0.88      0.92        26\n",
      "               Physics and Astronomy       0.96      0.94      0.95       204\n",
      "                          Psychology       0.87      0.77      0.82        35\n",
      "                     Social Sciences       0.85      0.85      0.85       171\n",
      "        Toxicology and Pharmaceutics       0.95      0.91      0.93       117\n",
      "                          Veterinary       0.98      0.93      0.96        69\n",
      "\n",
      "                            accuracy                           0.89      4044\n",
      "                           macro avg       0.91      0.83      0.86      4044\n",
      "                        weighted avg       0.89      0.89      0.89      4044\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Prepare features and labels\n",
    "# TF-IDF feature extraction\n",
    "df['combined keywords'] = df['combined keywords'].apply(lambda x: ' '.join(x))\n",
    "tfidf = TfidfVectorizer(max_features=5000)\n",
    "tfidf_kw = tfidf.fit_transform(df['combined keywords'])\n",
    "\n",
    "new_tfidf = TfidfVectorizer(max_features=5000)\n",
    "tfidf_pn = new_tfidf.fit_transform(df['Publication Name'])\n",
    "\n",
    "from scipy.sparse import hstack\n",
    "X = hstack([tfidf_kw, tfidf_pn])\n",
    "y = df['Subject Areas']\n",
    "\n",
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=50)\n",
    "\n",
    "\n",
    "# Train Logistic Regression model\n",
    "logreg = LogisticRegression(C = 100, max_iter= 500, penalty= 'l2', solver = 'saga' ,random_state=50) \n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = logreg.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PangSunatcha\\.conda\\envs\\DSenv\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'C': 100, 'max_iter': 100, 'penalty': 'l2', 'solver': 'saga'}\n",
      "Accuracy: 0.8919386745796242\n",
      "\n",
      "Classification Report:\n",
      "                                       precision    recall  f1-score   support\n",
      "\n",
      "Agricultural and Biological Sciences       0.93      0.90      0.91       220\n",
      "                 Arts and Humanities       0.97      0.88      0.92        33\n",
      "                        Biochemistry       0.83      0.78      0.81       236\n",
      "                            Business       0.82      0.85      0.83        65\n",
      "                Chemical Engineering       0.93      0.82      0.88       102\n",
      "                           Chemistry       0.87      0.96      0.91       260\n",
      "                    Computer Science       0.87      0.89      0.88       232\n",
      "                   Decision Sciences       1.00      0.20      0.33         5\n",
      "                           Dentistry       0.97      0.91      0.94        70\n",
      "        Earth and Planetary Sciences       0.89      0.81      0.85        58\n",
      "            Econometrics and Finance       0.79      0.74      0.77        31\n",
      "                              Energy       0.87      0.83      0.85       117\n",
      "                         Engineering       0.86      0.86      0.86       273\n",
      "               Environmental Science       0.87      0.89      0.88       152\n",
      "                  Health Professions       0.93      0.58      0.72        24\n",
      "         Immunology and Microbiology       0.93      0.82      0.87       107\n",
      "                   Materials science       0.88      0.83      0.86       203\n",
      "                         Mathematics       0.86      0.75      0.80        59\n",
      "                            Medicine       0.88      0.96      0.92       897\n",
      "                   Multidisciplinary       0.96      0.99      0.98       223\n",
      "                        Neuroscience       0.93      0.78      0.85        55\n",
      "                             Nursing       0.96      0.88      0.92        26\n",
      "               Physics and Astronomy       0.96      0.94      0.95       204\n",
      "                          Psychology       0.87      0.77      0.82        35\n",
      "                     Social Sciences       0.86      0.85      0.86       171\n",
      "        Toxicology and Pharmaceutics       0.95      0.91      0.93       117\n",
      "                          Veterinary       0.98      0.93      0.96        69\n",
      "\n",
      "                            accuracy                           0.89      4044\n",
      "                           macro avg       0.90      0.83      0.85      4044\n",
      "                        weighted avg       0.89      0.89      0.89      4044\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "# df = pd.read_csv(\"/path/to/data_formatted_subjectAreas.csv\")\n",
    "# df['Processed Words'] = df['Processed Words'].apply(eval)\n",
    "\n",
    "# # Prepare features and labels\n",
    "# X = df['Processed Words'].apply(lambda x: ' '.join(x))\n",
    "# y = df['Subject Areas']\n",
    "\n",
    "# # Split the dataset\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# # TF-IDF feature extraction\n",
    "# tfidf = TfidfVectorizer(max_features=5000)\n",
    "# X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "# X_test_tfidf = tfidf.transform(X_test)\n",
    "\n",
    "# Define parameter grid\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'penalty': ['l2'],\n",
    "    'solver': ['lbfgs', 'saga'],\n",
    "    'max_iter': [100, 500, 1000]\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=LogisticRegression(random_state=50),\n",
    "    param_grid=param_grid,\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters and evaluation\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = best_model.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DSenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
