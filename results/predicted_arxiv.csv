,ID,Title,Abstract,Authors,Published Date,Updated Date,Comments,Primary Category,PDF Link,Language,author_keywords,publicationName,predicted_subject_area
0,http://arxiv.org/abs/2403.00776v1,A framework for understanding data science,"The objective of this research is to provide a framework with which the datascience community can understand, define, and develop data science as a fieldof inquiry. The framework is based on the classical reference framework(axiology, ontology, epistemology, methodology) used for 200 years to defineknowledge discovery paradigms and disciplines in the humanities, sciences,algorithms, and now data science. I augmented it for automated problem-solvingwith (methods, technology, community). The resulting data science referenceframework is used to define the data science knowledge discovery paradigm interms of the philosophy of data science addressed in previous papers and thedata science problem-solving paradigm, i.e., the data science method, and thedata science problem-solving workflow, both addressed in this paper. Theframework is a much called for unifying framework for data science as itcontains the components required to define data science. For insights to betterunderstand data science, this paper uses the framework to define the emerging,often enigmatic, data science problem-solving paradigm and workflow, and tocompare them with their well-understood scientific counterparts, scientificproblem-solving paradigm and workflow.",Michael L Brodie,2024-02-14T15:55:40Z,2024-02-14T15:55:40Z,"28 pages, 10 figures",stat.OT,http://arxiv.org/pdf/2403.00776v1,eng,,,Computer Science
1,http://arxiv.org/abs/1501.05039v1,Defining Data Science,"Data science is gaining more and more and widespread attention, but noconsensus viewpoint on what data science is has emerged. As a new science, itsobjects of study and scientific issues should not be covered by establishedsciences. Data in cyberspace have formed what we call datanature. In thepresent paper, data science is defined as the science of exploring datanature.","Yangyong Zhu, Yun Xiong",2015-01-21T02:41:55Z,2015-01-21T02:41:55Z,,cs.DB,http://arxiv.org/pdf/1501.05039v1,eng,,,Physics and Astronomy
2,http://arxiv.org/abs/2201.05852v1,Data Science in Perspective,"Data and Science has stood out in the generation of results, whether in theprojects of the scientific domain or business domain. CERN Project, ScientificInstitutes, companies like Walmart, Google, Apple, among others, need data topresent their results and make predictions in the competitive data world. Dataand Science are words that together culminated in a globally recognized termcalled Data Science. Data Science is in its initial phase, possibly being partof formal sciences and also being presented as part of applied sciences,capable of generating value and supporting decision making. Data Scienceconsiders science and, consequently, the scientific method to promote decisionmaking through data intelligence. In many cases, the application of the method(or part of it) is considered in Data Science projects in scientific domain(social sciences, bioinformatics, geospatial projects) or business domain(finance, logistic, retail), among others. In this sense, this articleaddresses the perspectives of Data Science as a multidisciplinary area,considering science and the scientific method, and its formal structure whichintegrate Statistics, Computer Science, and Business Science, also taking intoaccount Artificial Intelligence, emphasizing Machine Learning, among others.The article also deals with the perspective of applied Data Science, since DataScience is used for generating value through scientific and business projects.Data Science persona is also discussed in the article, concerning the educationof Data Science professionals and its corresponding profiles, since itsprojection changes the field of data in the world.",Rogerio Rossi,2022-01-15T13:51:12Z,2022-01-15T13:51:12Z,Information Society Conference - i-Society 2021,cs.GL,http://arxiv.org/pdf/2201.05852v1,eng,,,Computer Science
3,http://arxiv.org/abs/2007.03606v1,Data Science: A Comprehensive Overview,"The twenty-first century has ushered in the age of big data and data economy,in which data DNA, which carries important knowledge, insights and potential,has become an intrinsic constituent of all data-based organisms. An appropriateunderstanding of data DNA and its organisms relies on the new field of datascience and its keystone, analytics. Although it is widely debated whether bigdata is only hype and buzz, and data science is still in a very early phase,significant challenges and opportunities are emerging or have been inspired bythe research, innovation, business, profession, and education of data science.This paper provides a comprehensive survey and tutorial of the fundamentalaspects of data science: the evolution from data analysis to data science, thedata science concepts, a big picture of the era of data science, the majorchallenges and directions in data innovation, the nature of data analytics, newindustrialization and service opportunities in the data economy, the professionand competency of data education, and the future of data science. This articleis the first in the field to draw a comprehensive big picture, in addition tooffering rich observations, lessons and thinking about data science andanalytics.",Longbing Cao,2020-07-01T02:33:58Z,2020-07-01T02:33:58Z,,cs.CY,http://arxiv.org/pdf/2007.03606v1,eng,,,Physics and Astronomy
4,http://arxiv.org/abs/2002.05658v1,Ten Research Challenge Areas in Data Science,"Although data science builds on knowledge from computer science, mathematics,statistics, and other disciplines, data science is a unique field with manymysteries to unlock: challenging scientific questions and pressing questions ofsocietal importance. This article starts with meta-questions about data scienceas a discipline and then elaborates on ten ideas for the basis of a researchagenda for data science.",Jeannette M. Wing,2020-01-27T21:39:57Z,2020-01-27T21:39:57Z,,cs.CY,http://arxiv.org/pdf/2002.05658v1,eng,,,Medicine
5,http://arxiv.org/abs/2112.01590v3,"The Art and Practice of Data Science Pipelines: A Comprehensive Study of  Data Science Pipelines In Theory, In-The-Small, and In-The-Large","Increasingly larger number of software systems today are including datascience components for descriptive, predictive, and prescriptive analytics. Thecollection of data science stages from acquisition, to cleaning/curation, tomodeling, and so on are referred to as data science pipelines. To facilitateresearch and practice on data science pipelines, it is essential to understandtheir nature. What are the typical stages of a data science pipeline? How arethey connected? Do the pipelines differ in the theoretical representations andthat in the practice? Today we do not fully understand these architecturalcharacteristics of data science pipelines. In this work, we present athree-pronged comprehensive study to answer this for the state-of-the-art, datascience in-the-small, and data science in-the-large. Our study analyzes threedatasets: a collection of 71 proposals for data science pipelines and relatedconcepts in theory, a collection of over 105 implementations of curated datascience pipelines from Kaggle competitions to understand data sciencein-the-small, and a collection of 21 mature data science projects from GitHubto understand data science in-the-large. Our study has led to threerepresentations of data science pipelines that capture the essence of oursubjects in theory, in-the-small, and in-the-large.","Sumon Biswas, Mohammad Wardat, Hridesh Rajan",2021-12-02T20:16:03Z,2022-02-14T17:35:39Z,,cs.SE,http://arxiv.org/pdf/2112.01590v3,eng,,,Physics and Astronomy
6,http://arxiv.org/abs/1607.00858v1,Embracing Data Science,"Statistics is running the risk of appearing irrelevant to today'sundergraduate students. Today's undergraduate students are familiar with datascience projects and they judge statistics against what they have seen.Statistics, especially at the introductory level, should take inspiration fromdata science so that the discipline is not seen as somehow lesser than datascience. This article provides a brief overview of data science, outlines ideasfor how introductory courses could take inspiration from data science, andprovides a reference to materials for developing stand-alone data sciencecourses.",Adam Loy,2016-07-04T12:40:15Z,2016-07-04T12:40:15Z,"9 pages, 1 figure",stat.OT,http://arxiv.org/pdf/1607.00858v1,eng,,,Social Sciences
7,http://arxiv.org/abs/2306.16177v3,Defining data science: a new field of inquiry,"Data science is not a science. It is a research paradigm. Its power, scope,and scale will surpass science, our most powerful research paradigm, to enableknowledge discovery and change our world. We have yet to understand and defineit, vital to realizing its potential and managing its risks. Modern datascience is in its infancy. Emerging slowly since 1962 and rapidly since 2000,it is a fundamentally new field of inquiry, one of the most active, powerful,and rapidly evolving 21st century innovations. Due to its value, power, andapplicability, it is emerging in over 40 disciplines, hundreds of researchareas, and thousands of applications. Millions of data science publicationscontain myriad definitions of data science and data science problem solving.Due to its infancy, many definitions are independent, application specific,mutually incomplete, redundant, or inconsistent, hence so is data science. Thisresearch addresses this data science multiple definitions challenge byproposing the development of coherent, unified definition based on a datascience reference framework using a data science journal for the data sciencecommunity to achieve such a definition. This paper provides candidatedefinitions for essential data science artifacts that are required to discusssuch a definition. They are based on the classical research paradigm conceptconsisting of a philosophy of data science, the data science problem solvingparadigm, and the six component data science reference framework (axiology,ontology, epistemology, methodology, methods, technology) that is a frequentlycalled for unifying framework with which to define, unify, and evolve datascience. It presents challenges for defining data science, solution approaches,i.e., means for defining data science, and their requirements and benefits asthe basis of a comprehensive solution.",Michael L Brodie,2023-06-28T12:58:42Z,2023-07-24T12:32:58Z,,cs.LG,http://arxiv.org/pdf/2306.16177v3,eng,,,Physics and Astronomy
8,http://arxiv.org/abs/2403.03387v1,Undergraduate data science education: Who has the microphone and what  are they saying?,"The presence of data science has been profound in the scientific community inalmost every discipline. An important part of the data science educationexpansion has been at the undergraduate level. We conducted a systematicliterature review to (1) specify current evidence and knowledge gaps inundergraduate data science education and (2) inform policymakers and datascience educators/practitioners about the present status of data scienceeducation research. The majority of the publications in data science educationthat met our search criteria were available open-access. Our results indicatethat data science education research lacks empirical data and reproducibility.Not all disciplines contribute equally to the field of data science education.Computer science and data science as a separate field emerge as the leadingcontributors to the literature. In contrast, fields such as statistics,mathematics, as well as other fields closely related to data science exhibit alimited presence in studies. We recommend that federal agencies and researchers1) invest in empirical data science education research; 2) diversify researchefforts to enrich the spectrum of types of studies; 3) encourage scholars inkey data science fields that are currently underrepresented in the literatureto contribute more to research and publications.","Mine Dogucu, Sinem Demirci, Harry Bendekgey, Federica Zoe Ricci, Catalina M. Medina",2024-03-06T00:49:08Z,2024-03-06T00:49:08Z,1 figure and 2 tables,stat.OT,http://arxiv.org/pdf/2403.03387v1,eng,,,Social Sciences
9,http://arxiv.org/abs/2308.04896v1,Why Data Science Projects Fail,"Data Science is a modern Data Intelligence practice, which is the core ofmany businesses and helps businesses build smart strategies around to deal withbusinesses challenges more efficiently. Data Science practice also helps inautomating business processes using the algorithm, and it has several otherbenefits, which also deliver in a non-profitable framework. In regards to datascience, three key components primarily influence the effective outcome of adata science project. Those are 1.Availability of Data 2.Algorithm 3.Processingpower or infrastructure",Balaram Panda,2023-08-08T06:45:15Z,2023-08-08T06:45:15Z,Proposed Enhanced Approach for Advancing Data Science Excellence,cs.LG,http://arxiv.org/pdf/2308.04896v1,eng,,,Social Sciences
10,http://arxiv.org/abs/2307.06896v1,Citizen Science in the European Open Science Cloud,"The European Open Science Cloud aims to make all data Findable, Accessible,Interoperable and Reusable. By far the largest community of users of theEuropean Open Science Cloud is the science-inclined public. These users need amore curated experience of open science than subject specialists, butnevertheless make very substantial research contributions in open science,especially in crowdsourced data mining, i.e. citizen science. This short,non-technical invited review presents applications of citizen science in theEuropean Open Science Cloud, with a particular focus on astrophysics andastroparticle physics.",Stephen Serjeant,2023-07-13T16:48:53Z,2023-07-13T16:48:53Z,"Published in Europhysics News, vol. 54(2), 2023, pages 20-23. 4
  pages, published version",astro-ph.IM,http://arxiv.org/pdf/2307.06896v1,eng,,,Social Sciences
11,http://arxiv.org/abs/1805.05401v1,Building Data Science Capabilities into University Data Warehouse to  Predict Graduation,"The discipline of data science emerged to combine statistical methods withcomputing. At Aalto University, Finland, we have taken first steps to bringeducational data science as a part of daily operations of ManagementInformation Services. This required changes in IT environment: we enhanced datawarehouse infrastructure with a data science lab, where we can read predictivemodel training data from data warehouse database and use the created predictivemodels in database queries. We then conducted a data science pilot with anobjective to predict students' graduation probability and time-to-degree withstudent registry data. Further ethical and legal considerations are neededbefore using predictions in daily operations of the university.","Joonas Pesonen, Anna Fomkin, Lauri Jokipii",2018-05-04T12:28:03Z,2018-05-04T12:28:03Z,EUNIS 2018,cs.CY,http://arxiv.org/pdf/1805.05401v1,eng,,,Medicine
12,http://arxiv.org/abs/2007.08087v1,Starting with data: advancing spatial data science by building and  sharing high-quality datasets,Spatial data science has emerged in recent years as an interdisciplinaryfield. This position paper discusses the importance of building and sharinghigh-quality datasets for spatial data science.,Yingjie Hu,2020-07-16T03:15:56Z,2020-07-16T03:15:56Z,,cs.CY,http://arxiv.org/pdf/2007.08087v1,eng,,,Computer Science
13,http://arxiv.org/abs/1909.04486v1,Data Science in Biomedicine,"We highlight the role of Data Science in Biomedicine. Our manuscript goesfrom the general to the particular, presenting a global definition of DataScience and showing the trend for this discipline together with the terms ofcloud computing and big data. In addition, since Data Science is mostly relatedto areas like economy or business, we describe its importance in biomedicine.Biomedical Data Science (BDS) presents the challenge of dealing with datacoming from a range of biological and medical research, focusing onmethodologies to advance the biomedical science discoveries, in aninterdisciplinary context.","Yovaninna Alarcón-Soto, Jenifer Espasandín-Domínguez, Ipek Guler, Mercedes Conde-Amboage, Francisco Gude-Sampedro, Klaus Langohr, Carmen Cadarso-Suárez, Guadalupe Gómez-Melis",2019-09-09T11:31:40Z,2019-09-09T11:31:40Z,,stat.OT,http://arxiv.org/pdf/1909.04486v1,eng,,,Computer Science
14,http://arxiv.org/abs/1610.04276v1,Perspectives on Surgical Data Science,"The availability of large amounts of data together with advances inanalytical techniques afford an opportunity to address difficult challenges inensuring that healthcare is safe, effective, efficient, patient-centered,equitable, and timely. Surgical care and training stand to tremendously gainthrough surgical data science. Herein, we discuss a few perspectives on thescope and objectives for surgical data science.","S. Swaroop Vedula, Masaru Ishii, Gregory D. Hager",2016-10-13T22:06:46Z,2016-10-13T22:06:46Z,"Workshop on Surgical Data Science, Heidelberg, Germany, June 20, 2016",cs.CY,http://arxiv.org/pdf/1610.04276v1,eng,,,Medicine
15,http://arxiv.org/abs/2006.16964v1,Data Science: Nature and Pitfalls,"Data science is creating very exciting trends as well as significantcontroversy. A critical matter for the healthy development of data science inits early stages is to deeply understand the nature of data and data science,and to discuss the various pitfalls. These important issues motivate thediscussions in this article.",Longbing Cao,2020-06-28T02:06:54Z,2020-06-28T02:06:54Z,,cs.CY,http://arxiv.org/pdf/2006.16964v1,eng,,,Medicine
16,http://arxiv.org/abs/1807.03750v1,Navigating Diverse Data Science Learning: Critical Reflections Towards  Future Practice,"Data Science is currently a popular field of science attracting expertisefrom very diverse backgrounds. Current learning practices need to acknowledgethis and adapt to it. This paper summarises some experiences relating to suchlearning approaches from teaching a postgraduate Data Science module, and drawssome learned lessons that are of relevance to others teaching Data Science.",Yehia Elkhatib,2018-07-05T21:32:18Z,2018-07-05T21:32:18Z,,cs.GL,http://arxiv.org/pdf/1807.03750v1,eng,,,Physics and Astronomy
17,http://arxiv.org/abs/2307.16650v1,ChatGPT for Teaching and Learning: An Experience from Data Science  Education,"ChatGPT, an implementation and application of large language models, hasgained significant popularity since its initial release. Researchers have beenexploring ways to harness the practical benefits of ChatGPT in real-worldscenarios. Educational researchers have investigated its potential in varioussubjects, e.g., programming, mathematics, finance, clinical decision support,etc. However, there has been limited attention given to its application in datascience education. This paper aims to bridge that gap by utilizing ChatGPT in adata science course, gathering perspectives from students, and presenting ourexperiences and feedback on using ChatGPT for teaching and learning in datascience education. The findings not only distinguish data science educationfrom other disciplines but also uncover new opportunities and challengesassociated with incorporating ChatGPT into the data science curriculum.",Yong Zheng,2023-07-31T13:31:19Z,2023-07-31T13:31:19Z,,cs.CY,http://arxiv.org/pdf/2307.16650v1,eng,,,Social Sciences
18,http://arxiv.org/abs/2002.03389v1,"Trust in Data Science: Collaboration, Translation, and Accountability in  Corporate Data Science Projects","The trustworthiness of data science systems in applied and real-worldsettings emerges from the resolution of specific tensions through situated,pragmatic, and ongoing forms of work. Drawing on research in CSCW, criticaldata studies, and history and sociology of science, and six months of immersiveethnographic fieldwork with a corporate data science team, we describe fourcommon tensions in applied data science work: (un)equivocal numbers,(counter)intuitive knowledge, (in)credible data, and (in)scrutable models. Weshow how organizational actors establish and re-negotiate trust under messy anduncertain analytic conditions through practices of skepticism, assessment, andcredibility. Highlighting the collaborative and heterogeneous nature ofreal-world data science, we show how the management of trust in appliedcorporate data science settings depends not only on pre-processing andquantification, but also on negotiation and translation. We conclude bydiscussing the implications of our findings for data science research andpractice, both within and beyond CSCW.","Samir Passi, Steven J. Jackson",2020-02-09T15:50:50Z,2020-02-09T15:50:50Z,,cs.CY,http://arxiv.org/pdf/2002.03389v1,eng,,,Social Sciences
19,http://arxiv.org/abs/2109.13656v2,"Opinionated practices for teaching reproducibility: motivation, guided  instruction and practice","In the data science courses at the University of British Columbia, we definedata science as the study, development and practice of reproducible andauditable processes to obtain insight from data. While reproducibility is coreto our definition, most data science learners enter the field with otheraspects of data science in mind, for example predictive modelling, which isoften one of the most interesting topic to novices. This fact, along with thehighly technical nature of the industry standard reproducibility toolscurrently employed in data science, present out-of-the gate challenges inteaching reproducibility in the data science classroom. Put simply, studentsare not as intrinsically motivated to learn this topic, and it is not an easyone for them to learn. What can a data science educator do? Over severaliterations of teaching courses focused on reproducible data science tools andworkflows, we have found that providing extra motivation, guided instructionand lots of practice are key to effectively teaching this challenging, yetimportant subject. Here we present examples of how we deeply motivate,effectively guide and provide ample practice opportunities to data sciencestudents to effectively engage them in learning about this topic.","Joel Ostblom, Tiffany Timbers",2021-09-17T19:15:41Z,2022-02-16T03:21:17Z,,cs.CY,http://arxiv.org/pdf/2109.13656v2,eng,,,Medicine
20,http://arxiv.org/abs/2207.01934v1,"How sustainable is ""common"" data science in terms of power consumption?","Continuous developments in data science have brought forth an exponentialincrease in complexity of machine learning models. Additionally, datascientists have become ubiquitous in the private market, academic environmentsand even as a hobby. All of these trends are on a steady rise, and areassociated with an increase in power consumption and associated carbonfootprint. The increasing carbon footprint of large-scale advanced data sciencehas already received attention, but the latter trend has not. This work aims toestimate the contribution of the increasingly popular ""common"" data science tothe global carbon footprint. To this end, the power consumption of severaltypical tasks in the aforementioned common data science tasks will be measuredand compared to: large-scale ""advanced"" data science, common computer-relatedtasks, and everyday non-computer related tasks. This is done by converting themeasurements to the equivalent unit of ""km driven by car"". Our main findingsare: ""common"" data science consumes $2.57$ more power than regular computerusage, but less than some common everyday power-consuming tasks such aslighting or heating; large-scale data science consumes substantially more powerthan common data science.","Bjorge Meulemeester, David Martens",2022-07-05T10:15:22Z,2022-07-05T10:15:22Z,"conference paper, working paper, under review, 9 pages, 4 figures",cs.CY,http://arxiv.org/pdf/2207.01934v1,eng,,,Social Sciences
21,http://arxiv.org/abs/2210.03305v1,How Do Data Science Workers Communicate Intermediate Results?,"Data science workers increasingly collaborate on large-scale projects beforecommunicating insights to a broader audience in the form of visualization.While prior work has modeled how data science teams, oftentimes with distinctroles and work processes, communicate knowledge to outside stakeholders, wehave little knowledge of how data science workers communicate intermediatelybefore delivering the final products. In this work, we contribute a nuanceddescription of the intermediate communication process within data scienceteams. By analyzing interview data with 8 self-identified data science workers,we characterized the data science intermediate communication process with fourfactors, including the types of audience, communication goals, sharedartifacts, and mode of communication. We also identified overarching challengesin the current communication process. We also discussed design implicationsthat might inform better tools that facilitate intermediate communicationwithin data science teams.","Rock Yuren Pang, Ruotong Wang, Joely Nelson, Leilani Battle",2022-10-07T03:28:33Z,2022-10-07T03:28:33Z,"This paper was accepted for presentation as part of the eighth
  Symposium on Visualization in Data Science (VDS) at ACM KDD 2022 as well as
  IEEE VIS 2022. http://www.visualdatascience.org/2022/index.html",cs.HC,http://arxiv.org/pdf/2210.03305v1,eng,,,Social Sciences
22,http://arxiv.org/abs/2307.10460v2,"A data science axiology: the nature, value, and risks of data science","Data science is not a science. It is a research paradigm with an unfathomedscope, scale, complexity, and power for knowledge discovery that is nototherwise possible and can be beyond human reasoning. It is changing our worldpractically and profoundly already widely deployed in tens of thousands ofapplications in every discipline in an AI Arms Race that, due to itsinscrutability, can lead to unfathomed risks. This paper presents an axiologyof data science, its purpose, nature, importance, risks, and value for problemsolving, by exploring and evaluating its remarkable, definitive features. Asdata science is in its infancy, this initial, speculative axiology is intendedto aid in understanding and defining data science to recognize its potentialbenefits, risks, and open research challenges. AI based data science isinherently about uncertainty that may be more realistic than our preference forthe certainty of science. Data science will have impacts far beyond knowledgediscovery and will take us into new ways of understanding the world.",Michael L. Brodie,2023-07-19T21:12:04Z,2023-07-21T21:32:12Z,,cs.AI,http://arxiv.org/pdf/2307.10460v2,eng,,,Physics and Astronomy
23,http://arxiv.org/abs/2409.05969v1,Challenges and Opportunities of Teaching Data Visualization Together  with Data Science,"With the increasing amount of data globally, analyzing and visualizing dataare becoming essential skills across various professions. It is important toequip university students with these essential data skills. To learn, design,and develop data visualization, students need knowledge of programming and datascience topics. Many university programs lack dedicated data science coursesfor undergraduate students, making it important to introduce these conceptsthrough integrated courses. However, combining data science and datavisualization into one course can be challenging due to the time constraintsand the heavy load of learning. In this paper, we discuss the development ofteaching data science and data visualization together in one course and sharethe results of the post-course evaluation survey. From the survey's results, weidentified four challenges, including difficulty in learning multiple tools anddiverse data science topics, varying proficiency levels with tools andlibraries, and selecting and cleaning datasets. We also distilled fiveopportunities for developing a successful data science and visualizationcourse. These opportunities include clarifying the course structure,emphasizing visualization literacy early in the course, updating the coursecontent according to student needs, using large real-world datasets, learningfrom industry professionals, and promoting collaboration among students.","Shri Harini Ramesh, Fateme Rajabiyazdi",2024-09-09T18:06:25Z,2024-09-09T18:06:25Z,"7 pages, to be published in IEEE Explore, accepted to EduVis'24",cs.HC,http://arxiv.org/pdf/2409.05969v1,eng,,,Social Sciences
24,http://arxiv.org/abs/2310.02444v3,Philosophy within Data Science Ethics Courses,"There is wide agreement that ethical considerations are a valuable aspect ofa data science curriculum, and to that end, many data science programs offercourses in data science ethics. There are not always, however, explicitconnections between data science ethics and the centuries-old work on ethicswithin the discipline of philosophy. Here, we present a framework for bringingtogether key data science practices with ethics topics. The ethics topics werecollated from sixteen data science ethics courses with public-facing syllabiand reading lists. We encourage individuals who are teaching data scienceethics to engage with the philosophical literature and its connection tocurrent data science practices, which are rife with potentially morally chargeddecision points.","Sara Colando, Johanna Hardin",2023-10-03T21:25:26Z,2024-08-08T02:19:12Z,,stat.OT,http://arxiv.org/pdf/2310.02444v3,eng,,,Biochemistry
25,http://arxiv.org/abs/2311.07631v1,The 4+1 Model of Data Science,"Data Science is a complex and evolving field, but most agree that it can bedefined as a combination of expertise drawn from three broad areascomputerscience and technology, math and statistics, and domain knowledge -- with thepurpose of extracting knowledge and value from data. Beyond this, the field isoften defined as a series of practical activities ranging from the cleaning andwrangling of data, to its analysis and use to infer models, to the visual andrhetorical representation of results to stakeholders and decision-makers. Thisessay proposes a model of data science that goes beyond laundry-listdefinitions to get at the specific nature of data science and help distinguishit from adjacent fields such as computer science and statistics. We define datascience as an interdisciplinary field comprising four broad areas of expertise:value, design, systems, and analytics. A fifth area, practice, integrates theother four in specific contexts of domain knowledge. We call this the 4+1 modelof data science. Together, these areas belong to every data science project,even if they are often unconnected and siloed in the academy.",Rafael C. Alvarado,2023-11-13T12:12:32Z,2023-11-13T12:12:32Z,28 pages,cs.DB,http://arxiv.org/pdf/2311.07631v1,eng,,,Social Sciences
26,http://arxiv.org/abs/1907.05644v2,"Data-driven materials science: status, challenges and perspectives","Data-driven science is heralded as a new paradigm in materials science. Inthis field, data is the new resource, and knowledge is extracted from materialsdata sets that are too big or complex for traditional human reasoning -typically with the intent to discover new or improved materials or materialsphenomena. Multiple factors, including the open science movement, nationalfunding, and progress in information technology, have fueled its development.Such related tools as materials databases, machine learning, andhigh-throughput methods are now established as parts of the materials researchtoolset. However, there are a variety of challenges that impede progress indata-driven materials science: data veracity, integration of experimental andcomputational data, data longevity, standardization, and the gap betweenindustrial interests and academic efforts. In this perspective article, wediscuss the historical development and current state of data-driven materialsscience, building from the early evolution of open science to the rapidexpansion of materials data infrastructures. We also review key successes andchallenges so far, providing a perspective on the future development of thefield.","Lauri Himanen, Amber Geurts, Adam S. Foster, Patrick Rinke",2019-07-12T09:44:01Z,2019-08-19T07:57:54Z,"Added new entries to the materials data infrastucture tables, updated
  references and affiliations",physics.comp-ph,http://arxiv.org/pdf/1907.05644v2,eng,,,Social Sciences
27,http://arxiv.org/abs/2001.06684v3,"How do Data Science Workers Collaborate? Roles, Workflows, and Tools","Today, the prominence of data science within organizations has given rise toteams of data science workers collaborating on extracting insights from data,as opposed to individual data scientists working alone. However, we still lacka deep understanding of how data science workers collaborate in practice. Inthis work, we conducted an online survey with 183 participants who work invarious aspects of data science. We focused on their reported interactions witheach other (e.g., managers with engineers) and with different tools (e.g.,Jupyter Notebook). We found that data science teams are extremely collaborativeand work with a variety of stakeholders and tools during the six common stepsof a data science workflow (e.g., clean data and train model). We also foundthat the collaborative practices workers employ, such as documentation, varyaccording to the kinds of tools they use. Based on these findings, we discussdesign implications for supporting data science team collaborations and futureresearch directions.","Amy X. Zhang, Michael Muller, Dakuo Wang",2020-01-18T15:11:56Z,2020-04-16T16:38:43Z,CSCW'2020,cs.HC,http://arxiv.org/pdf/2001.06684v3,eng,,,Social Sciences
28,http://arxiv.org/abs/2210.12528v2,Data science transfer pathways from associate's to bachelor's programs,"A substantial fraction of students who complete their college education at apublic university in the United States begin their journey at one of the 935public two-year colleges. While the number of four-year colleges offeringbachelor's degrees in data science continues to increase, data scienceinstruction at many two-year colleges lags behind. A major impediment is therelative paucity of introductory data science courses that serve multiplestudent audiences and can easily transfer. In addition, the lack of pre-definedtransfer pathways (or articulation agreements) for data science creates agrowing disconnect that leaves students who want to study data science at adisadvantage. We describe opportunities and barriers to data science transferpathways. Five points of curricular friction merit attention: 1) a first coursein data science, 2) a second course in data science, 3) a course in scientificcomputing, data science workflow, and/or reproducible computing, 4) labsciences, and 5) navigating communication, ethics, and application domainrequirements in the context of general education and liberal arts coursemappings. We catalog existing transfer pathways, efforts to align curriculaacross institutions, obstacles to overcome with minimally-disruptive solutions,and approaches to foster these pathways. Improvements in these areas arecritically important to ensure that a broad and diverse set of students areable to engage and succeed in undergraduate data science programs.","Benjamin S. Baumer, Nicholas J. Horton",2022-10-22T19:07:08Z,2023-01-06T14:23:08Z,,stat.OT,http://arxiv.org/pdf/2210.12528v2,eng,,,Social Sciences
29,http://arxiv.org/abs/2411.03007v1,Data Quality Awareness: A Journey from Traditional Data Management to  Data Science Systems,"Artificial intelligence (AI) has transformed various fields, significantlyimpacting our daily lives. A major factor in AI success is high-quality data.In this paper, we present a comprehensive review of the evolution of dataquality (DQ) awareness from traditional data management systems to moderndata-driven AI systems, which are integral to data science. We synthesize theexisting literature, highlighting the quality challenges and techniques thathave evolved from traditional data management to data science including bigdata and ML fields. As data science systems support a wide range of activities,our focus in this paper lies specifically in the analytics aspect driven bymachine learning. We use the cause-effect connection between the qualitychallenges of ML and those of big data to allow a more thorough understandingof emerging DQ challenges and the related quality awareness techniques in datascience systems. To the best of our knowledge, our paper is the first toprovide a review of DQ awareness spanning traditional and emergent data sciencesystems. We hope that readers will find this journey through the evolution ofdata quality awareness insightful and valuable.","Sijie Dong, Soror Sahri, Themis Palpanas",2024-11-05T11:12:25Z,2024-11-05T11:12:25Z,12 pages,cs.DB,http://arxiv.org/pdf/2411.03007v1,eng,,,Medicine
30,http://arxiv.org/abs/1804.10846v6,Data science is science's second chance to get causal inference right: A  classification of data science tasks,"Causal inference from observational data is the goal of many data analyses inthe health and social sciences. However, academic statistics has often frownedupon data analyses with a causal objective. The introduction of the term ""datascience"" provides a historic opportunity to redefine data analysis in such away that it naturally accommodates causal inference from observational data.Like others before, we organize the scientific contributions of data scienceinto three classes of tasks: Description, prediction, and counterfactualprediction (which includes causal inference). An explicit classification ofdata science tasks is necessary to discuss the data, assumptions, and analyticsrequired to successfully accomplish each task. We argue that a failure toadequately describe the role of subject-matter expert knowledge in dataanalysis is a source of widespread misunderstandings about data science.Specifically, causal analyses typically require not only good data andalgorithms, but also domain expert knowledge. We discuss the implications forthe use of data science to guide decision-making in the real world and to traindata scientists.","Miguel A. Hernán, John Hsu, Brian Healy",2018-04-28T20:23:45Z,2019-04-07T03:10:51Z,,stat.ML,http://arxiv.org/pdf/1804.10846v6,eng,,,Social Sciences
31,http://arxiv.org/abs/2007.08978v2,A large-scale comparative analysis of Coding Standard conformance in  Open-Source Data Science projects,"Background: Meeting the growing industry demand for Data Science requirescross-disciplinary teams that can translate machine learning research intoproduction-ready code. Software engineering teams value adherence to codingstandards as an indication of code readability, maintainability, and developerexpertise. However, there are no large-scale empirical studies of codingstandards focused specifically on Data Science projects. Aims: This studyinvestigates the extent to which Data Science projects follow code standards.In particular, which standards are followed, which are ignored, and how doesthis differ to traditional software projects? Method: We compare a corpus of1048 Open-Source Data Science projects to a reference group of 1099 non-DataScience projects with a similar level of quality and maturity. Results: DataScience projects suffer from a significantly higher rate of functions that usean excessive numbers of parameters and local variables. Data Science projectsalso follow different variable naming conventions to non-Data Science projects.Conclusions: The differences indicate that Data Science codebases are distinctfrom traditional software codebases and do not follow traditional softwareengineering conventions. Our conjecture is that this may be because traditionalsoftware engineering conventions are inappropriate in the context of DataScience projects.","Andrew J. Simmons, Scott Barnett, Jessica Rivera-Villicana, Akshat Bajaj, Rajesh Vasa",2020-07-17T13:45:00Z,2020-07-28T15:19:25Z,"11 pages, 7 figures. To appear in ESEM 2020. Updated based on peer
  review",cs.SE,http://arxiv.org/pdf/2007.08978v2,eng,,,Medicine
32,http://arxiv.org/abs/2407.11824v1,The Future of Data Science Education,"The definition of Data Science is a hotly debated topic. For many, thedefinition is a simple shortcut to Artificial Intelligence or Machine Learning.However, there is far more depth and nuance to the field of Data Science than asimple shortcut can provide. The School of Data Science at the University ofVirginia has developed a novel model for the definition of Data Science. Thismodel is based on identifying a unified understanding of the data work doneacross all areas of Data Science. It represents a generational leap forward inhow we understand and teach Data Science. In this paper we will present thecore features of the model and explain how it unifies various concepts goingfar beyond the analytics component of AI. From this foundation we will presentour Undergraduate Major curriculum in Data Science and demonstrate how itprepares students to be well-rounded Data Science team members and leaders. Thepaper will conclude with an in-depth overview of the Foundations of DataScience course designed to introduce students to the field while alsoimplementing proven STEM oriented pedagogical methods. These include, forexample, specifications grading, active learning lectures, guest lectures fromindustry experts and weekly gamification labs.","Brian Wright, Peter Alonzi, Ali Riveria",2024-07-16T15:11:54Z,2024-07-16T15:11:54Z,"12 pages, 5 figures, publish at the 53rd Annual Southeast Decision
  Science Institute 2024, won best paper for Innovation track",stat.OT,http://arxiv.org/pdf/2407.11824v1,eng,,,Social Sciences
33,http://arxiv.org/abs/2012.15358v1,A Review into Data Science and Its Approaches in Mechanical Engineering,"Nowadays it is inevitable to use intelligent systems to improve theperformance and optimization of different components of devices or factories.Furthermore, it's so essential to have appropriate predictions to make betterdecisions in businesses, medical studies, and engineering studies, etc. One ofthe newest and most widely used of these methods is a field called Data Sciencethat all of the scientists, engineers, and factories need to learn and use intheir careers. This article briefly introduced data science and reviewed itsmethods, especially it's usages in mechanical engineering and challenges andways of developing data science in mechanical engineering. In the introduction,different definitions of data science and its background in technologyreviewed. In the following, data science methodology which is the process thata data scientist needs to do in its works been discussed. Further, someresearches in the mechanical engineering area that used data science methods intheir studies, are reviewed. Eventually, it has been discussed according to thesubjects that have been reviewed in the article, why it is necessary to usedata science in mechanical engineering researches and projects.","Ashkan Yousefi Zadeh, Meysam Shahbazy",2020-12-30T23:05:29Z,2020-12-30T23:05:29Z,"For associated information, see https://civilica.com/doc/1128400/",cs.AI,http://arxiv.org/pdf/2012.15358v1,eng,,,Medicine
34,http://arxiv.org/abs/2405.00684v1,Science Fiction Media Representations of Exoplanets: Portrayals of  Changing Astronomical Discoveries,"Interest in science fiction's (SF's) potential science communication use ishindered by concerns about SF misrepresenting science. This study addressesthese concerns by asking how SF media reflects scientific findings in exoplanetscience. A database of SF exoplanets was analysed using a Bayesian network tofind interconnected interactions between planetary characterisation featuresand literary data. Results reveal SF exoplanets designed after the discovery ofreal exoplanets are less Earth-like, providing statistical evidence that SFincorporates rapidly-evolving science. Understanding SF's portrayal of scienceis crucial for its potential use in science communication.","Emma Johanna Puranen, Emily Finer, Christiane Helling, V Anne Smith",2024-03-04T13:45:55Z,2024-03-04T13:45:55Z,"19 pages, 1 table, 2 figures",physics.pop-ph,http://arxiv.org/pdf/2405.00684v1,eng,,,Medicine
35,http://arxiv.org/abs/2208.02565v1,Teaching Visual Accessibility in Introductory Data Science Classes with  Multi-Modal Data Representations,"Although there are various ways to represent data patterns and models,visualization has been primarily taught in many data science courses for itsefficiency. Such vision-dependent output may cause critical barriers againstthose who are blind and visually impaired and people with learningdisabilities. We argue that instructors need to teach multiple datarepresentation methods so that all students can produce data products that aremore accessible. In this paper, we argue that accessibility should be taught asearly as the introductory course as part of the data science curriculum so thatregardless of whether learners major in data science or not, they can havefoundational exposure to accessibility. As data science educators who teachaccessibility as part of our lower-division courses in two differentinstitutions, we share specific examples that can be utilized by other datascience instructors.","JooYoung Seo, Mine Dogucu",2022-08-04T10:20:10Z,2022-08-04T10:20:10Z,"17 pages, 6 figures",cs.HC,http://arxiv.org/pdf/2208.02565v1,eng,,,Computer Science
36,http://arxiv.org/abs/1012.1620v1,Linked Environment Data for the Life Sciences,Environment Agencies from Europe and the US are setting up a network ofLinked Environment Data and are looking to crosslink it with Linked Datacontributions from the life sciences.,"Maria Rüther, Thomas Bandholtz, Antoine Logean",2010-12-07T21:49:42Z,2010-12-07T21:49:42Z,"in Adrian Paschke, Albert Burger, Andrea Splendiani, M. Scott
  Marshall, Paolo Romano: Proceedings of the 3rd International Workshop on
  Semantic Web Applications and Tools for the Life Sciences, Berlin,Germany,
  December 8-10, 2010",cs.OH,http://arxiv.org/pdf/1012.1620v1,eng,,,Medicine
37,http://arxiv.org/abs/1909.03033v1,The Difficulties of Addressing Interdisciplinary Challenges at the  Foundations of Data Science,"The National Science Foundation's Transdisciplinary Research in Principles ofData Science (TRIPODS) program aims to integrate three areas central to thefoundations of data by uniting the statistics, mathematics, and theoreticalcomputer science research communities. The program aims to provide a model forfunding cross-cutting research and facilitating interactions among the threedisciplines. Challenges associated with orchestrating fruitful interactions aredescribed.",Michael W. Mahoney,2019-09-04T06:07:26Z,2019-09-04T06:07:26Z,"Appearing in SIAM News, SIGACT News, etc",cs.CY,http://arxiv.org/pdf/1909.03033v1,eng,,,Social Sciences
38,http://arxiv.org/abs/2405.17690v1,Data Makes Better Data Scientists,"With the goal of identifying common practices in data science projects, thispaper proposes a framework for logging and understanding incremental codeexecutions in Jupyter notebooks. This framework aims to allow reasoning abouthow insights are generated in data science and extract key observations intobest data science practices in the wild. In this paper, we show an earlyprototype of this framework and ran an experiment to log a machine learningproject for 25 undergraduate students.","Jinjin Zhao, Avidgor Gal, Sanjay Krishnan",2024-05-27T22:46:17Z,2024-05-27T22:46:17Z,,cs.HC,http://arxiv.org/pdf/2405.17690v1,eng,,,Computer Science
39,http://arxiv.org/abs/1811.10454v1,Square Kilometre Array Science Data Challenge 1,"The Square Kilometre Array (SKA, https://skatelescope.org) will be theworld's largest radio telescope. SKA Science Data Challenges will be regularlyissued to the community as part of the science preparatory activities. Thepurpose of these challenges is to inform the development of the data reductionworkflows, to allow the science community to get familiar with the standardproducts the SKA will deliver, and optimise their analyses to extract sciencefrom them. These challenges may consist of real data from currently operatingradio facilities or of simulated SKA data. The purpose of this document is toprovide information on how the SKA Science data challenge #1 (SDC1) has beenproduced and to set the challenge for the community. For more information onhow to take part in the challenge and to download the data seehttps://astronomers.skatelescope.org/ska-science-data-challenge-1/","Anna Bonaldi, Robert Braun",2018-11-26T15:33:19Z,2018-11-26T15:33:19Z,"7 pages, extracted from the document released by the SKA Office:
  SKA-TEL-SKO-00001001",astro-ph.IM,http://arxiv.org/pdf/1811.10454v1,eng,,,Medicine
40,http://arxiv.org/abs/1504.02878v1,Data Science and Ebola,"Data Science---Today, everybody and everything produces data. People producelarge amounts of data in social networks and in commercial transactions.Medical, corporate, and government databases continue to grow. Sensors continueto get cheaper and are increasingly connected, creating an Internet of Things,and generating even more data. In every discipline, large, diverse, and richdata sets are emerging, from astrophysics, to the life sciences, to thebehavioral sciences, to finance and commerce, to the humanities and to thearts. In every discipline people want to organize, analyze, optimize andunderstand their data to answer questions and to deepen insights. The sciencethat is transforming this ocean of data into a sea of knowledge is called datascience. This lecture will discuss how data science has changed the way inwhich one of the most visible challenges to public health is handled, the 2014Ebola outbreak in West Africa.",Aske Plaat,2015-04-11T14:14:08Z,2015-04-11T14:14:08Z,Inaugural lecture Leiden University,cs.AI,http://arxiv.org/pdf/1504.02878v1,eng,,,Social Sciences
41,http://arxiv.org/abs/1805.05039v1,NOMAD: The FAIR Concept for Big-Data-Driven Materials Science,"Data is a crucial raw material of this century, and the amount of data thathas been created in materials science in recent years and is being createdevery new day is immense. Without a proper infrastructure that allows forcollecting and sharing data (including the original data), the envisionedsuccess of materials science and, in particular, Big-Data driven materialsscience will be hampered. For the field of computational materials science, theNOMAD (Novel Materials Discovery) Center of Excellence (CoE) has changed thescientific culture towards a comprehensive and FAIR data sharing, opening newavenues for mining Big-Data of materials science. Novel data-analytics conceptsand tools turn data into knowledge and help the prediction of new materials orthe identification of new properties of already known materials.","Claudia Draxl, Matthias Scheffler",2018-05-14T07:43:10Z,2018-05-14T07:43:10Z,,cond-mat.mtrl-sci,http://arxiv.org/pdf/1805.05039v1,eng,,,Computer Science
42,http://arxiv.org/abs/2006.16966v1,Data Science: Challenges and Directions,"While data science has emerged as a contentious new scientific field,enormous debates and discussions have been made on it why we need data scienceand what makes it as a science. In reviewing hundreds of pieces of literaturewhich include data science in their titles, we find that the majority of thediscussions essentially concern statistics, data mining, machine learning, bigdata, or broadly data analytics, and only a limited number of new data-drivenchallenges and directions have been explored. In this paper, we explore theintrinsic challenges and directions inspired by comprehensively exploring thecomplexities and intelligence embedded in data science problems. We focus onthe research and innovation challenges inspired by the nature of data scienceproblems as complex systems, and the methodologies for handling such systems.",Longbing Cao,2020-06-28T01:49:00Z,2020-06-28T01:49:00Z,,cs.CY,http://arxiv.org/pdf/2006.16966v1,eng,,,Social Sciences
43,http://arxiv.org/abs/2010.07017v1,Computational Skills by Stealth in Secondary School Data Science,"The unprecedented growth in the availability of data of all types andqualities and the emergence of the field of data science has provided animpetus to finally realizing the implementation of the full breadth of theNolan and Temple Lang proposed integration of computing concepts intostatistics curricula at all levels in statistics and new data science programsand courses. Moreover, data science, implemented carefully, opens accessiblepathways to stem for students for whom neither mathematics nor computer scienceare natural affinities, and who would traditionally be excluded. We discuss aproposal for the stealth development of computational skills in students' firstexposure to data science through careful, scaffolded exposure to computationand its power. The intent of this approach is to support students, regardlessof interest and self-efficacy in coding, in becoming data-driven learners, whoare capable of asking complex questions about the world around them, and thenanswering those questions through the use of data-driven inquiry. Thisdiscussion is presented in the context of the International Data Science inSchools Project which recently published computer science and statisticsconsensus curriculum frameworks for a two-year secondary school data scienceprogram, designed to make data science accessible to all.","Wesley Burr, Fanny Chevalier, Christopher Collins, Alison L Gibbs, Raymond Ng, Chris Wild",2020-10-08T09:11:51Z,2020-10-08T09:11:51Z,"38 pages, 8 figures",cs.CY,http://arxiv.org/pdf/2010.07017v1,eng,,,Social Sciences
44,http://arxiv.org/abs/2201.06310v1,A survey study of success factors in data science projects,"In recent years, the data science community has pursued excellence and madesignificant research efforts to develop advanced analytics, focusing on solvingtechnical problems at the expense of organizational and socio-technicalchallenges. According to previous surveys on the state of data science projectmanagement, there is a significant gap between technical and organizationalprocesses. In this article we present new empirical data from a survey to 237data science professionals on the use of project management methodologies fordata science. We provide additional profiling of the survey respondents' rolesand their priorities when executing data science projects. Based on this surveystudy, the main findings are: (1) Agile data science lifecycle is the mostwidely used framework, but only 25% of the survey participants state to followa data science project methodology. (2) The most important success factors areprecisely describing stakeholders' needs, communicating the results toend-users, and team collaboration and coordination. (3) Professionals whoadhere to a project methodology place greater emphasis on the project'spotential risks and pitfalls, version control, the deployment pipeline toproduction, and data security and privacy.","Iñigo Martinez, Elisabeth Viles, Igor G. Olaizola",2022-01-17T09:50:46Z,2022-01-17T09:50:46Z,"6 pages, 7 figures, 2 tables, accepted at IEEE Big Data 2021,
  International Workshop on Methods to Improve Big Data Science Projects",cs.DB,http://arxiv.org/pdf/2201.06310v1,eng,,,Medicine
45,http://arxiv.org/abs/1903.10579v1,Categorical Data Integration for Computational Science,"Categorical Query Language is an open-source query and data integrationscripting language that can be applied to common challenges in the field ofcomputational science. We discuss how the structure-preserving nature of CQLdata migrations protect those who publicly share data from themisinterpretation of their data. Likewise, this feature of CQL migrationsallows those who draw from public data sources to be sure only data which meetstheir specification will actually be transferred. We argue some open problemsin the field of data sharing in computational science are addressable byworking within this paradigm of functorial data migration. We demonstrate thesetools by integrating data from the Open Quantum Materials Database with somealternative materials databases.","Kristopher Brown, David I. Spivak, Ryan Wisnesky",2019-03-25T20:08:22Z,2019-03-25T20:08:22Z,"10 pages, 5 figures",cs.DB,http://arxiv.org/pdf/1903.10579v1,eng,,,Social Sciences
46,http://arxiv.org/abs/2106.11077v2,Toward a Knowledge Discovery Framework for Data Science Job Market in  the United States,"The growth of the data science field requires better tools to understand sucha fast-paced growing domain. Moreover, individuals from different backgroundsbecame interested in following a career as data scientists. Therefore,providing a quantitative guide for individuals and organizations to understandthe skills required in the job market would be crucial. This paper introduces aframework to analyze the job market for data science-related jobs within the USwhile providing an interface to access insights in this market. The proposedframework includes three sub-modules allowing continuous data collection,information extraction, and a web-based dashboard visualization to investigatethe spatial and temporal distribution of data science-related jobs and skills.The result of this work shows important skills for the main branches of datascience jobs and attempts to provide a skill-based definition of these datascience branches. The current version of this application is deployed on theweb and allows individuals and institutes to investigate skills required fordata science positions through the industry lens.","Mojtaba Heidarysafa, Kamran Kowsari, Masoud Bashiri, Donald E. Brown",2021-06-14T21:23:15Z,2021-07-20T15:40:25Z,,cs.CY,http://arxiv.org/pdf/2106.11077v2,eng,,,Computer Science
47,http://arxiv.org/abs/2105.06324v1,Perspective on Data Science,"The field of data science currently enjoys a broad definition that includes awide array of activities which borrow from many other established fields ofstudy. Having such a vague characterization of a field in the early stagesmight be natural, but over time maintaining such a broad definition becomesunwieldy and impedes progress. In particular, the teaching of data science ishampered by the seeming need to cover many different points of interest. Datascientists must ultimately identify the core of the field by determining whatmakes the field unique and what it means to develop new knowledge in datascience. In this review we attempt to distill some core ideas from data scienceby focusing on the iterative process of data analysis and develop somegeneralizations from past experience. Generalizations of this nature could formthe basis of a theory of data science and would serve to unify and scale theteaching of data science to large audiences.","Roger D. Peng, Hilary S. Parker",2021-05-13T14:24:26Z,2021-05-13T14:24:26Z,,stat.OT,http://arxiv.org/pdf/2105.06324v1,eng,,,Physics and Astronomy
48,http://arxiv.org/abs/2106.11209v4,Facilitating team-based data science: lessons learned from the DSC-WAV  project,"While coursework provides undergraduate data science students with somerelevant analytic skills, many are not given the rich experiences with data andcomputing they need to be successful in the workplace. Additionally, studentsoften have limited exposure to team-based data science and the principles andtools of collaboration that are encountered outside of school. In this paper,we describe the DSC-WAV program, an NSF-funded data science workforcedevelopment project in which teams of undergraduate sophomores and juniors workwith a local non-profit organization on a data-focused problem. To helpstudents develop a sense of agency and improve confidence in their technicaland non-technical data science skills, the project promoted a team-basedapproach to data science, adopting several processes and tools intended tofacilitate this collaboration. Evidence from the project evaluation, includingparticipant survey and interview data, is presented to document the degree towhich the project was successful in engaging students in team-based datascience, and how the project changed the students' perceptions of theirtechnical and non-technical skills. We also examine opportunities forimprovement and offer insight to other data science educators who may want toimplement a similar team-based approach to data science projects at their owninstitutions.","Chelsey Legacy, Andrew Zieffler, Benjamin S. Baumer, Valerie Barr, Nicholas J. Horton",2021-06-21T15:51:34Z,2021-10-21T19:35:09Z,,stat.OT,http://arxiv.org/pdf/2106.11209v4,eng,,,Social Sciences
49,http://arxiv.org/abs/2109.01661v1,Data science and Machine learning in the Clouds: A Perspective for the  Future,"As we are fast approaching the beginning of a paradigm shift in the field ofscience, Data driven science (the so called fourth science paradigm) is goingto be the driving force in research and innovation. From medicine tobiodiversity and astronomy to geology, all these terms are somehow going to beaffected by this paradigm shift. The huge amount of data to be processed underthis new paradigm will be a major concern in the future and one will stronglyrequire cloud based services in all the aspects of these computations (fromstorage to compute and other services). Another aspect will be energyconsumption and performance of prediction jobs and tasks within such ascientific paradigm which will change the way one sees computation. Datascience has heavily impacted or rather triggered the emergence of MachineLearning, Signal/Image/Video processing related algorithms, Artificialintelligence, Robotics, health informatics, geoinformatics, and many more suchareas of interest. Hence, we envisage an era where Data science can deliver itspromises with the help of the existing cloud based platforms and services withthe addition of new services. In this article, we discuss about data drivenscience and Machine learning and how they are going to be linked through cloudbased services in the future. It also discusses the rise of paradigms likeapproximate computing, quantum computing and many more in recent times andtheir applicability in big data processing, data science, analytics, predictionand machine learning in the cloud environments.",Hrishav Bakul Barua,2021-09-02T17:36:24Z,2021-09-02T17:36:24Z,Preprint submitted for review,cs.DC,http://arxiv.org/pdf/2109.01661v1,eng,,,Computer Science
50,http://arxiv.org/abs/1811.03435v4,Data Science as Political Action: Grounding Data Science in a Politics  of Justice,"In response to public scrutiny of data-driven algorithms, the field of datascience has adopted ethics training and principles. Although ethics can helpdata scientists reflect on certain normative aspects of their work, suchefforts are ill-equipped to generate a data science that avoids social harmsand promotes social justice. In this article, I argue that data science mustembrace a political orientation. Data scientists must recognize themselves aspolitical actors engaged in normative constructions of society and evaluatetheir work according to its downstream impacts on people's lives. I firstarticulate why data scientists must recognize themselves as political actors.In this section, I respond to three arguments that data scientists commonlyinvoke when challenged to take political positions regarding their work. Inconfronting these arguments, I describe why attempting to remain apolitical isitself a political stance--a fundamentally conservative one--and why datascience's attempts to promote ""social good"" dangerously rely on unarticulatedand incrementalist political assumptions. I then propose a framework for howdata science can evolve toward a deliberative and rigorous politics of socialjustice. I conceptualize the process of developing a politically engaged datascience as a sequence of four stages. Pursuing these new approaches willempower data scientists with new methods for thoughtfully and rigorouslycontributing to social justice.",Ben Green,2018-11-06T03:11:09Z,2022-02-01T01:24:56Z,,cs.CY,http://arxiv.org/pdf/1811.03435v4,eng,,,Social Sciences
51,http://arxiv.org/abs/1410.3127v3,"Data Science in Statistics Curricula: Preparing Students to ""Think with  Data""","A growing number of students are completing undergraduate degrees instatistics and entering the workforce as data analysts. In these positions,they are expected to understand how to utilize databases and other datawarehouses, scrape data from Internet sources, program solutions to complexproblems in multiple languages, and think algorithmically as well asstatistically. These data science topics have not traditionally been a majorcomponent of undergraduate programs in statistics. Consequently, a curricularshift is needed to address additional learning outcomes. The goal of this paperis to motivate the importance of data science proficiency and to provideexamples and resources for instructors to implement data science in their ownstatistics curricula. We provide case studies from seven institutions. Thesevaried approaches to teaching data science demonstrate curricular innovationsto address new needs. Also included here are examples of assignments designedfor courses that foster engagement of undergraduates with data and datascience.","Johanna Hardin, Roger Hoerl, Nicholas J. Horton, Deborah Nolan",2014-10-12T18:17:04Z,2015-08-04T20:16:03Z,,stat.OT,http://arxiv.org/pdf/1410.3127v3,eng,,,Social Sciences
52,http://arxiv.org/abs/2008.03640v1,Prediction Methods and Applications in the Science of Science: A Survey,"Science of science has become a popular topic that attracts great attentionsfrom the research community. The development of data analytics technologies andthe readily available scholarly data enable the exploration of data-drivenprediction, which plays a pivotal role in finding the trend of scientificimpact. In this paper, we analyse methods and applications in data-drivenprediction in the science of science, and discuss their significance. First, weintroduce the background and review the current state of the science ofscience. Second, we review data-driven prediction based on paper citationcount, and investigate research issues in this area. Then, we discuss methodsto predict scholar impact, and we analyse different approaches to promote thescholarly collaboration in the collaboration network. This paper also discussesopen issues and existing challenges, and suggests potential researchdirections.","Jie Hou, Hanxiao Pan, Teng Guo, Ivan Lee, Xiangjie Kong, Feng Xia",2020-08-09T03:42:43Z,2020-08-09T03:42:43Z,"17 pages, 6 figures",cs.SI,http://arxiv.org/pdf/2008.03640v1,eng,,,Physics and Astronomy
53,http://arxiv.org/abs/2106.07287v2,Data Science Methodologies: Current Challenges and Future Approaches,"Data science has employed great research efforts in developing advancedanalytics, improving data models and cultivating new algorithms. However, notmany authors have come across the organizational and socio-technical challengesthat arise when executing a data science project: lack of vision and clearobjectives, a biased emphasis on technical issues, a low level of maturity forad-hoc projects and the ambiguity of roles in data science are among thesechallenges. Few methodologies have been proposed on the literature that tacklethese type of challenges, some of them date back to the mid-1990, andconsequently they are not updated to the current paradigm and the latestdevelopments in big data and machine learning technologies. In addition, fewermethodologies offer a complete guideline across team, project and data &information management. In this article we would like to explore the necessityof developing a more holistic approach for carrying out data science projects.We first review methodologies that have been presented on the literature towork on data science projects and classify them according to the their focus:project, team, data and information management. Finally, we propose aconceptual framework containing general characteristics that a methodology formanaging data science projects with a holistic point of view should have. Thisframework can be used by other researchers as a roadmap for the design of newdata science methodologies or the updating of existing ones.","Iñigo Martinez, Elisabeth Viles, Igor G. Olaizola",2021-06-14T10:34:50Z,2022-01-14T11:48:38Z,"23 pages, 23 figures, 5 tables",cs.LG,http://arxiv.org/pdf/2106.07287v2,eng,,,Computer Science
54,http://arxiv.org/abs/2302.01041v1,TAPS Responsibility Matrix: A tool for responsible data science by  design,"Data science is an interdisciplinary research area where scientists aretypically working with data coming from different fields. When using andanalyzing data, the scientists implicitly agree to follow standards,procedures, and rules set in these fields. However, guidance on theresponsibilities of the data scientists and the other involved actors in a datascience project is typically missing. While literature shows that novelframeworks and tools are being proposed in support of open-science, data reuse,and research data management, there are currently no frameworks that can fullyexpress responsibilities of a data science project. In this paper, we describethe Transparency, Accountability, Privacy, and Societal Responsibility Matrix(TAPS-RM) as framework to explore social, legal, and ethical aspects of datascience projects. TAPS-RM acts as a tool to provide users with a holistic viewof their project beyond key outcomes and clarifies the responsibilities ofactors. We map the developed model of TAPS-RM with well-known initiatives foropen data (such as FACT, FAIR and Datasheets for datasets). We conclude thatTAPS-RM is a tool to reflect on responsibilities at a data science projectlevel and can be used to advance responsible data science by design.","Visara Urovi, Remzi Celebi, Chang Sun, Linda Rieswijk, Michael Erard, Arif Yilmaz, Kody Moodley, Parveen Kumar, Michel Dumontier",2023-02-02T12:09:14Z,2023-02-02T12:09:14Z,,cs.CY,http://arxiv.org/pdf/2302.01041v1,eng,,,Computer Science
55,http://arxiv.org/abs/2409.07703v1,DSBench: How Far Are Data Science Agents to Becoming Data Science  Experts?,"Large Language Models (LLMs) and Large Vision-Language Models (LVLMs) havedemonstrated impressive language/vision reasoning abilities, igniting therecent trend of building agents for targeted applications such as shoppingassistants or AI software engineers. Recently, many data science benchmarkshave been proposed to investigate their performance in the data science domain.However, existing data science benchmarks still fall short when compared toreal-world data science applications due to their simplified settings. Tobridge this gap, we introduce DSBench, a comprehensive benchmark designed toevaluate data science agents with realistic tasks. This benchmark includes 466data analysis tasks and 74 data modeling tasks, sourced from Eloquence andKaggle competitions. DSBench offers a realistic setting by encompassing longcontexts, multimodal task backgrounds, reasoning with large data files andmulti-table structures, and performing end-to-end data modeling tasks. Ourevaluation of state-of-the-art LLMs, LVLMs, and agents shows that they strugglewith most tasks, with the best agent solving only 34.12% of data analysis tasksand achieving a 34.74% Relative Performance Gap (RPG). These findingsunderscore the need for further advancements in developing more practical,intelligent, and autonomous data science agents.","Liqiang Jing, Zhehui Huang, Xiaoyang Wang, Wenlin Yao, Wenhao Yu, Kaixin Ma, Hongming Zhang, Xinya Du, Dong Yu",2024-09-12T02:08:00Z,2024-09-12T02:08:00Z,,cs.AI,http://arxiv.org/pdf/2409.07703v1,eng,,,Physics and Astronomy
56,http://arxiv.org/abs/2410.17273v1,Behavior Matters: An Alternative Perspective on Promoting Responsible  Data Science,"Data science pipelines inform and influence many daily decisions, from whatwe buy to who we work for and even where we live. When designed incorrectly,these pipelines can easily propagate social inequity and harm. Traditionalsolutions are technical in nature; e.g., mitigating biased algorithms. In thisvision paper, we introduce a novel lens for promoting responsible data scienceusing theories of behavior change that emphasize not only technical solutionsbut also the behavioral responsibility of practitioners. By integratingbehavior change theories from cognitive psychology with data science workflowknowledge and ethics guidelines, we present a new perspective on responsibledata science. We present example data science interventions in machine learningand visual data analysis, contextualized in behavior change theories that couldbe implemented to interrupt and redirect potentially suboptimal or negligentpractices while reinforcing ethically conscious behaviors. We conclude with acall to action to our community to explore this new research area of behaviorchange interventions for responsible data science.","Ziwei Dong, Ameya Patil, Yuichi Shoda, Leilani Battle, Emily Wall",2024-10-07T16:59:18Z,2024-10-07T16:59:18Z,"23 pages, 4 figures, to be published in CSCW 2025",cs.CY,http://arxiv.org/pdf/2410.17273v1,eng,,,Social Sciences
57,http://arxiv.org/abs/2311.10969v1,MATILDA: Inclusive Data Science Pipelines Design through Computational  Creativity,"We argue for the need for a new generation of data science solutions that candemocratize recent advances in data engineering and artificial intelligence fornon-technical users from various disciplines, enabling them to unlock the fullpotential of these solutions. To do so, we adopt an approach wherebycomputational creativity and conversational computing are combined to guidenon-specialists intuitively to explore and extract knowledge from datacollections. The paper introduces MATILDA, a creativity-based data sciencedesign platform, showing how it can support the design process of data sciencepipelines guided by human and computational creativity.","Genoveva Vargas-Solar, Santiago Negrete-Yankelevich, Javier A. Espinosa-Oviedo, Khalid Belhajjame, José-Luis Zechinelli-Martini",2023-11-18T04:37:07Z,2023-11-18T04:37:07Z,,cs.DB,http://arxiv.org/pdf/2311.10969v1,eng,,,Computer Science
58,http://arxiv.org/abs/2105.05160v1,Research Data Infrastructure for High-Throughput Experimental Materials  Science,"The High-Throughput Experimental Materials Database (HTEM-DB) is the endpointrepository for inorganic thin-film materials data collected duringcombinatorial experiments at the National Renewable Energy Laboratory (NREL).This unique data asset is enabled by the Research Data Infrastructure (RDI) - aset of custom data tools that collect, process, and store experimental data andmetadata. Here, we describe the experimental data-tool workflow from the RDI tothe HTEM-DB to illustrate the strategies and best practices currently used formaterials data at NREL. Integration of these data tools with the experimentalprocesses establishes a data communication pipeline between experimental anddata science communities. In doing so, this work motivates the creation ofsimilar data workflows at other institutions to aggregate valuable data andincrease its usefulness for future data studies. These types of investments cangreatly accelerate the pace of learning and discovery in the materials sciencefield, by making data accessible to new and rapidly evolving data methods.","Kevin R. Talley, Robert White, Nick Wunder, Matthew Eash, Marcus Schwarting, Dave Evenson, John Perkins, William Tumas, Kristin Munch, Caleb Phillips, Andriy Zakutayev",2021-05-11T16:12:22Z,2021-05-11T16:12:22Z,,cond-mat.mtrl-sci,http://arxiv.org/pdf/2105.05160v1,eng,,,Computer Science
59,http://arxiv.org/abs/1210.6636v1,"Informaticology: combining Computer Science, Data Science, and Fiction  Science","Motivated by an intention to remedy current complications with Dutchterminology concerning informatics, the term informaticology is positioned todenote an academic counterpart of informatics where informatics is conceived ofas a container for a coherent family of practical disciplines ranging fromcomputer engineering and software engineering to network technology, datacenter management, information technology, and information management in abroad sense.  Informaticology escapes from the limitations of instrumental objectives andthe perspective of usage that both restrict the scope of informatics. That isachieved by including fiction science in informaticology and by ranking fictionscience on equal terms with computer science and data science, and framing (thestudy of) game design, evelopment, assessment and distribution, ranging fromserious gaming to entertainment gaming, as a chapter of fiction science. Asuggestion for the scope of fiction science is specified in some detail.  In order to illustrate the coherence of informaticology thus conceived, apotential application of fiction to the ontology of instruction sequences andto software quality assessment is sketched, thereby highlighting a possiblerole of fiction (science) within informaticology but outside gaming.",Jan A. Bergstra,2012-10-24T19:24:59Z,2012-10-24T19:24:59Z,,cs.SE,http://arxiv.org/pdf/1210.6636v1,eng,,,Computer Science
60,http://arxiv.org/abs/2101.12150v2,The Agnostic Structure of Data Science Methods,"In this paper we argue that data science is a coherent and novel approach toempirical problems that, in its most general form, does not build understandingabout phenomena. Within the new type of mathematization at work in datascience, mathematical methods are not selected because of any relevance for aproblem at hand; mathematical methods are applied to a specific problem only by'forcing', i.e. on the basis of their ability to reorganize the data forfurther analysis and the intrinsic richness of their mathematical structure. Inparticular, we argue that deep learning neural networks are best understoodwithin the context of forcing optimization methods. We finally explore thebroader question of the appropriateness of data science methods in solvingproblems. We argue that this question should not be interpreted as a search fora correspondence between phenomena and specific solutions found by data sciencemethods; rather, it is the internal structure of data science methods that isopen to precise forms of understanding.","Domenico Napoletani, Marco Panza, Daniele Struppa",2021-01-27T02:32:35Z,2021-03-29T19:59:47Z,"24 pp., no figures, a new abstract and new key-words added",stat.OT,http://arxiv.org/pdf/2101.12150v2,eng,,,Social Sciences
61,http://arxiv.org/abs/2211.08637v2,Near-peer mentoring in data science: Two experiences at Stanford  University,"Universities have been expanding the data science programs for undergraduatestudents, with the simultaneous goal of reaching and retaining students fromunderrepresented groups in the data science workforce. The set of new programsalso offer opportunities to involve graduate students, fostering their growthas future leaders in data science education. We describe two programs that usethe near peer mentoring structure to provide pathways for graduate students todevelop teaching and mentoring skills, while providing research and learningopportunities for undergraduate students from diverse backgrounds. In the DataScience for Social Good Summer program, graduate students mentor a group ofundergraduate fellows as they tackle a data science project with positivesocial impact. In the Inclusive Mentoring in Data Science course, graduatestudents participate in workshops on effective and inclusive mentorshipstrategies. In an experiential learning framework, they are paired withundergraduate students from non-R1 schools, who they mentor through weeklyone-on-one on-line meetings. These initiatives offer a prototype of futureprograms that serve the dual goal of providing both hands-on mentoringexperience for graduate students and research opportunities for undergraduatestudents, in a high-touch inclusive and encouraging environment.","Chiara Sabatti, Qian Zhao",2022-11-16T03:13:01Z,2024-06-08T17:20:37Z,,stat.OT,http://arxiv.org/pdf/2211.08637v2,eng,,,Social Sciences
62,http://arxiv.org/abs/2403.00961v2,Data Science Education in Undergraduate Physics: Lessons Learned from a  Community of Practice,"It is becoming increasingly important that physics educators equip theirstudents with the skills to work with data effectively. However, many educatorsmay lack the necessary training and expertise in data science to teach theseskills. To address this gap, we created the Data Science Education Community ofPractice (DSECOP), bringing together graduate students and physics educatorsfrom different institutions and backgrounds to share best practices and lessonslearned from integrating data science into undergraduate physics education. Inthis article we present insights and experiences from this community ofpractice, highlighting key strategies and challenges in incorporating datascience into the introductory physics curriculum. Our goal is to provideguidance and inspiration to educators who seek to integrate data science intotheir teaching, helping to prepare the next generation of physicists for adata-driven world.","Karan Shah, Julie Butler, Alexis Knaub, Anıl Zenginoğlu, William Ratcliff, Mohammad Soltanieh-ha",2024-03-01T20:21:42Z,2024-06-16T16:47:56Z,"21 pages, 4 figures, 2 tables. The associated GItHub repository can
  be found at https://github.com/GDS-Education-Community-of-Practice/DSECOP",physics.ed-ph,http://arxiv.org/pdf/2403.00961v2,eng,,,Social Sciences
63,http://arxiv.org/abs/1502.00318v1,Setting the stage for data science: integration of data management  skills in introductory and second courses in statistics,"Many have argued that statistics students need additional facility to expressstatistical computations. By introducing students to commonplace tools for datamanagement, visualization, and reproducible analysis in data science andapplying these to real-world scenarios, we prepare them to think statistically.In an era of increasingly big data, it is imperative that students developdata-related capacities, beginning with the introductory course. We believethat the integration of these precursors to data science into ourcurricula-early and often-will help statisticians be part of the dialogueregarding ""Big Data"" and ""Big Questions"".","Nicholas J. Horton, Benjamin S. Baumer, Hadley Wickham",2015-02-01T21:43:51Z,2015-02-01T21:43:51Z,,stat.CO,http://arxiv.org/pdf/1502.00318v1,eng,,,Social Sciences
64,http://arxiv.org/abs/1709.07493v1,Big Data Systems Meet Machine Learning Challenges: Towards Big Data  Science as a Service,"Recently, we have been witnessing huge advancements in the scale of data weroutinely generate and collect in pretty much everything we do, as well as ourability to exploit modern technologies to process, analyze and understand thisdata. The intersection of these trends is what is called, nowadays, as Big DataScience. Cloud computing represents a practical and cost-effective solution forsupporting Big Data storage, processing and for sophisticated analyticsapplications. We analyze in details the building blocks of the software stackfor supporting big data science as a commodity service for data scientists. Weprovide various insights about the latest ongoing developments and openchallenges in this domain.","Radwa Elshawi, Sherif Sakr",2017-09-21T18:50:32Z,2017-09-21T18:50:32Z,,cs.DB,http://arxiv.org/pdf/1709.07493v1,eng,,,Computer Science
65,http://arxiv.org/abs/1804.08293v1,Materials science and engineering: New vision in the era of artificial  intelligence,"Scientific discovery evolves from the experimental, through the theoreticaland computational, to the current data-intensive paradigm. Materials science isno exception, especially for computational materials science. In recent years,great achievements have been made in the field of materials science andengineering (MSE). Here, we review the previous paradigms of materials scienceand some classical MSE models. Then, our data-intensive MSE (DIMSE) model isproposed to reshape future materials innovations. This work will help toaddress the global challenge for materials discovery in the era of artificialintelligence (AI), and essentially contribute to accelerating future materialscontinuum.","Tao Qiang, Honghong Gao",2018-04-23T09:01:57Z,2018-04-23T09:01:57Z,"4 pages, 1 figure, 16 references",cond-mat.mtrl-sci,http://arxiv.org/pdf/1804.08293v1,eng,,,Medicine
66,http://arxiv.org/abs/2205.01553v1,Why The Trans Programmer?,"Through online anecdotal evidence and online communities, there is anin-group idea of trans people (specifically trans-feminine individuals)disproportionately entering computer science education & fields. Existing datasuggests this is a plausible trend, yet no research has been done into exactlywhy. As computer science education (traditional schooling or self-taughtmethods) is integral to working in computer science fields, a simple researchsurvey was conducted to gather data on 138 trans people's experiences withcomputer science & computer science education. This article's purpose is toshed insight on the motivations for trans individuals choosing computer sciencepaths, while acting as a basis and call to action for further research.",Skye Kychenthal,2022-05-03T15:06:23Z,2022-05-03T15:06:23Z,IEEE Integrated STEM Education Conference 2022,cs.CY,http://arxiv.org/pdf/2205.01553v1,eng,,,Agricultural and Biological Sciences
67,http://arxiv.org/abs/1906.10686v2,Wise Data: A Novel Approach in Data Science from a Network Science  Perspective,"Human beings have been generating data since very long times ago. We ask thefollowing common-sense and wise questions (WizQuestions):  1. Why do we refer to some pieces of data more often than referring to otherpieces? 2. What does make those commonly-referred pieces of data so unique anddifferent? 3. What are the characteristics of data that sometimes make the dataso unique and different?  In this article, we introduce a novel approach (model) that helps us answerthese questions from data science and network science perspectives. WizWordilyspeaking, our proposed approach enables us to model the data (as a network),measure the quality of data, and study the network of data deeply andthoroughly.",Mike Raeini,2019-06-26T03:17:43Z,2019-07-28T01:21:25Z,"16 pages, 3 figures",cs.OH,http://arxiv.org/pdf/1906.10686v2,eng,,,Medicine
68,http://arxiv.org/abs/2101.05273v1,AutoDS: Towards Human-Centered Automation of Data Science,"Data science (DS) projects often follow a lifecycle that consists oflaborious tasks for data scientists and domain experts (e.g., data exploration,model training, etc.). Only till recently, machine learning(ML) researchershave developed promising automation techniques to aid data workers in thesetasks. This paper introduces AutoDS, an automated machine learning (AutoML)system that aims to leverage the latest ML automation techniques to supportdata science projects. Data workers only need to upload their dataset, then thesystem can automatically suggest ML configurations, preprocess data, selectalgorithm, and train the model. These suggestions are presented to the user viaa web-based graphical user interface and a notebook-based programming userinterface.  We studied AutoDS with 30 professional data scientists, where one group usedAutoDS, and the other did not, to complete a data science project. As expected,AutoDS improves productivity; Yet surprisingly, we find that the modelsproduced by the AutoDS group have higher quality and less errors, but lowerhuman confidence scores. We reflect on the findings by presenting designimplications for incorporating automation techniques into human work in thedata science lifecycle.","Dakuo Wang, Josh Andres, Justin Weisz, Erick Oduor, Casey Dugan",2021-01-13T08:35:14Z,2021-01-13T08:35:14Z,,cs.HC,http://arxiv.org/pdf/2101.05273v1,eng,,,Social Sciences
69,http://arxiv.org/abs/2111.11872v1,"Real-time intelligent big data processing: technology, platform, and  applications","Human beings keep exploring the physical space using information means. Onlyrecently, with the rapid development of information technologies and theincreasing accumulation of data, human beings can learn more about the unknownworld with data-driven methods. Given data timeliness, there is a growingawareness of the importance of real-time data. There are two categories oftechnologies accounting for data processing: batching big data and streamingprocessing, which have not been integrated well. Thus, we propose an innovativeincremental processing technology named after Stream Cube to process both bigdata and stream data. Also, we implement a real-time intelligent dataprocessing system, which is based on real-time acquisition, real-timeprocessing, real-time analysis, and real-time decision-making. The real-timeintelligent data processing technology system is equipped with a batching bigdata platform, data analysis tools, and machine learning models. Based on ourapplications and analysis, the real-time intelligent data processing system isa crucial solution to the problems of the national society and economy.","Tongya Zheng, Gang Chen, Xinyu Wang, Chun Chen, Xingen Wang, Sihui Luo",2021-11-23T13:40:22Z,2021-11-23T13:40:22Z,"13 pages, 8 figures, Accpeted 13 February 2019 by Science China
  Information Sciences",cs.DC,http://arxiv.org/pdf/2111.11872v1,eng,,,Computer Science
70,http://arxiv.org/abs/1008.3795v1,"Machine Science in Biomedicine: Practicalities, Pitfalls and Potential","Machine Science, or Data-driven Research, is a new and interesting scientificmethodology that uses advanced computational techniques to identify, retrieve,classify and analyse data in order to generate hypotheses and develop models.In this paper we describe three recent biomedical Machine Science studies, anduse these to assess the current state of the art with specific emphasis on datamining, data assessment, costs, limitations, skills and tool support.","T W Kelsey, W H B Wallace",2010-08-23T11:30:15Z,2010-08-23T11:30:15Z,,cs.IR,http://arxiv.org/pdf/1008.3795v1,eng,,,Engineering
71,http://arxiv.org/abs/2103.15787v1,Meeting in the notebook: a notebook-based environment for  micro-submissions in data science collaborations,"Developers in data science and other domains frequently use computationalnotebooks to create exploratory analyses and prototype models. However, theyoften struggle to incorporate existing software engineering tooling into thesenotebook-based workflows, leading to fragile development processes. Weintroduce Assembl\'{e}, a new development environment for collaborative datascience projects, in which promising code fragments of data science pipelinescan be contributed as pull requests to an upstream repository entirely fromwithin JupyterLab, abstracting away low-level version control tool usage. Wedescribe the design and implementation of Assembl\'{e} and report on a userstudy of 23 data scientists.","Micah J. Smith, Jürgen Cito, Kalyan Veeramachaneni",2021-03-29T17:31:07Z,2021-03-29T17:31:07Z,,cs.HC,http://arxiv.org/pdf/2103.15787v1,eng,,,Computer Science
72,http://arxiv.org/abs/1905.03121v1,A First Course in Data Science,"Data science is a discipline that provides principles, methodology andguidelines for the analysis of data for tools, values, or insights. Driven by ahuge workforce demand, many academic institutions have started to offer degreesin data science, with many at the graduate, and a few at the undergraduatelevel. Curricula may differ at different institutions, because of varyinglevels of faculty expertise, and different disciplines (such as Math, computerscience, and business etc) in developing the curriculum. The University ofMassachusetts Dartmouth started offering degree programs in data science fromFall 2015, at both the undergraduate and the graduate level. Quite a fewarticles have been published that deal with graduate data science courses, muchless so dealing with undergraduate ones. Our discussion will focus onundergraduate course structure and function, and specifically, a first coursein data science. Our design of this course centers around a concept called thedata science life cycle. That is, we view tasks or steps in the practice ofdata science as forming a process, consisting of states that indicate how itcomes into life, how different tasks in data science depend on or interact withothers until the birth of a data product or the reach of a conclusion.Naturally, different pieces of the data science life cycle then form individualparts of the course. Details of each piece are filled up by concepts,techniques, or skills that are popular in industry. Consequently, the design ofour course is both ""principled"" and practical. A significant feature of ourcourse philosophy is that, in line with activity theory, the course is based onthe use of tools to transform real data in order to answer strongly motivatedquestions related to the data.","Donghui Yan, Gary E. Davis",2019-05-08T14:54:14Z,2019-05-08T14:54:14Z,"25 pages, 5 figures",stat.OT,http://arxiv.org/pdf/1905.03121v1,eng,,,Social Sciences
73,http://arxiv.org/abs/2409.10580v1,Veridical Data Science for Medical Foundation Models,"The advent of foundation models (FMs) such as large language models (LLMs)has led to a cultural shift in data science, both in medicine and beyond. Thisshift involves moving away from specialized predictive models trained forspecific, well-defined domain questions to generalist FMs pre-trained on vastamounts of unstructured data, which can then be adapted to various clinicaltasks and questions. As a result, the standard data science workflow inmedicine has been fundamentally altered; the foundation model lifecycle (FMLC)now includes distinct upstream and downstream processes, in which computationalresources, model and data access, and decision-making power are distributedamong multiple stakeholders. At their core, FMs are fundamentally statisticalmodels, and this new workflow challenges the principles of Veridical DataScience (VDS), hindering the rigorous statistical analysis expected intransparent and scientifically reproducible data science practices. Wecritically examine the medical FMLC in light of the core principles of VDS:predictability, computability, and stability (PCS), and explain how it deviatesfrom the standard data science workflow. Finally, we propose recommendationsfor a reimagined medical FMLC that expands and refines the PCS principles forVDS including considering the computational and accessibility constraintsinherent to FMs.","Ahmed Alaa, Bin Yu",2024-09-15T18:44:38Z,2024-09-15T18:44:38Z,,cs.LG,http://arxiv.org/pdf/2409.10580v1,eng,,,Social Sciences
74,http://arxiv.org/abs/2107.14652v1,Meeting the challenge of Open Science in KM3NeT,"In the upcoming decades, the KM3NeT detectors will produce valuable data thatcan be used in various scientific contexts from astro- and particle physics toenvironmental and Earth and Sea science. Based on the Open Science policyestablished by the KM3NeT Collaboration, several efforts to offer science-readydata, foster common analysis approaches and publish open source software arecurrently pursued. In this contribution, ongoing projects focusing on theexchange of high-level data and simulation derivatives, production of particleevent simulations and establishment of an integrated computing environmentsupporting an open-science focused workflow will be discussed.","Jutta Schnabel, Piotr Kalaczyński, Cristiano Bozza, Tamas Gal",2021-07-30T14:20:05Z,2021-07-30T14:20:05Z,,astro-ph.IM,http://arxiv.org/pdf/2107.14652v1,eng,,,Social Sciences
75,http://arxiv.org/abs/2310.10693v1,Network Analysis of the iNaturalist Citizen Science Community,"In recent years, citizen science has become a larger and larger part of thescientific community. Its ability to crowd source data and expertise fromthousands of citizen scientists makes it invaluable. Despite the field'sgrowing popularity, the interactions and structure of citizen science projectsare still poorly understood and under analyzed. We use the iNaturalist citizenscience platform as a case study to analyze the structure of citizen scienceprojects. We frame the data from iNaturalist as a bipartite network and usevisualizations as well as established network science techniques to gaininsights into the structure and interactions between users in citizen scienceprojects. Finally, we propose a novel unique benchmark for network scienceresearch by using the iNaturalist data to create a network which has an unusualstructure relative to other common benchmark networks. We demonstrate using alink prediction task that this network can be used to gain novel insights intoa variety of network science methods.","Yu Lu Liu, Thomas Jiralerspong",2023-10-16T00:41:13Z,2023-10-16T00:41:13Z,,cs.SI,http://arxiv.org/pdf/2310.10693v1,eng,,,Medicine
76,http://arxiv.org/abs/2204.04887v2,Research on Cross-media Science and Technology Information Data  Retrieval,"Since the era of big data, the Internet has been flooded with all kinds ofinformation. Browsing information through the Internet has become an integralpart of people's daily life. Unlike the news data and social data in theInternet, the cross-media technology information data has differentcharacteristics. This data has become an important basis for researchers andscholars to track the current hot spots and explore the future direction oftechnology development. As the volume of science and technology informationdata becomes richer, the traditional science and technology informationretrieval system, which only supports unimodal data retrieval and uses outdateddata keyword matching model, can no longer meet the daily retrieval needs ofscience and technology scholars. Therefore, in view of the above researchbackground, it is of profound practical significance to study the cross-mediascience and technology information data retrieval system based on deep semanticfeatures, which is in line with the development trend of domestic andinternational technologies.","Yang Jiang, Zhe Xue, Ang Li",2022-04-11T06:10:21Z,2022-10-25T01:20:28Z,We found some errors in the algorithm and need to withdraw this paper,cs.IR,http://arxiv.org/pdf/2204.04887v2,eng,,,Social Sciences
77,http://arxiv.org/abs/1710.06881v1,Children and the Data Cycle: Rights and Ethics in a Big Data World,"In an era of increasing dependence on data science and big data, the voicesof one set of major stakeholders - the world's children and those who advocateon their behalf - have been largely absent. A recent paper estimates one inthree global internet users is a child, yet there has been little rigorousdebate or understanding of how to adapt traditional, offline ethical standardsfor research, involving data collection from children, to a big data, onlineenvironment (Livingstone et al., 2015). This paper argues that due to thepotential for severe, long-lasting and differential impacts on children, childrights need to be firmly integrated onto the agendas of global debates aboutethics and data science. The authors outline their rationale for a greaterfocus on child rights and ethics in data science and suggest steps to moveforward, focussing on the various actors within the data chain including datagenerators, collectors, analysts and end users. It concludes by calling for amuch stronger appreciation of the links between child rights, ethics and datascience disciplines and for enhanced discourse between stakeholders in the datachain and those responsible for upholding the rights of children globally.","Gabrielle Berman, Kerry Albright",2017-10-18T18:08:13Z,2017-10-18T18:08:13Z,Presented at the Data For Good Exchange 2017,cs.CY,http://arxiv.org/pdf/1710.06881v1,eng,,,Social Sciences
78,http://arxiv.org/abs/1909.05682v1,Augmented Data Science: Towards Industrialization and Democratization of  Data Science,"Conversion of raw data into insights and knowledge requires substantialamounts of effort from data scientists. Despite breathtaking advances inMachine Learning (ML) and Artificial Intelligence (AI), data scientists stillspend the majority of their effort in understanding and then preparing the rawdata for ML/AI. The effort is often manual and ad hoc, and requires some levelof domain knowledge. The complexity of the effort increases dramatically whendata diversity, both in form and context, increases. In this paper, weintroduce our solution, Augmented Data Science (ADS), towards addressing this""human bottleneck"" in creating value from diverse datasets. ADS is adata-driven approach and relies on statistics and ML to extract insights fromany data set in a domain-agnostic way to facilitate the data science process.Key features of ADS are the replacement of rudimentary data exploration andprocessing steps with automation and the augmentation of data scientistjudgment with automatically-generated insights. We present building blocks ofour end-to-end solution and provide a case study to exemplify its capabilities.","Huseyin Uzunalioglu, Jin Cao, Chitra Phadke, Gerald Lehmann, Ahmet Akyamac, Ran He, Jeongran Lee, Maria Able",2019-09-12T14:00:03Z,2019-09-12T14:00:03Z,,cs.AI,http://arxiv.org/pdf/1909.05682v1,eng,,,Medicine
79,http://arxiv.org/abs/2210.00847v1,Review of Clustering Methods for Functional Data,"Functional data clustering is to identify heterogeneous morphologicalpatterns in the continuous functions underlying the discretemeasurements/observations. Application of functional data clustering hasappeared in many publications across various fields of sciences, including butnot limited to biology, (bio)chemistry, engineering, environmental science,medical science, psychology, social science, etc. The phenomenal growth of theapplication of functional data clustering indicates the urgent need for asystematic approach to develop efficient clustering methods and scalablealgorithmic implementations. On the other hand, there is abundant literature onthe cluster analysis of time series, trajectory data, spatio-temporal data,etc., which are all related to functional data. Therefore, an overarchingstructure of existing functional data clustering methods will enable thecross-pollination of ideas across various research fields. We here conduct acomprehensive review of original clustering methods for functional data. Wepropose a systematic taxonomy that explores the connections and differencesamong the existing functional data clustering methods and relates them to theconventional multivariate clustering methods. The structure of the taxonomy isbuilt on three main attributes of a functional data clustering method andtherefore is more reliable than existing categorizations. The review aims tobridge the gap between the functional data analysis community and theclustering community and to generate new principles for functional dataclustering.","Mimi Zhang, Andrew Parnell",2022-10-03T12:15:23Z,2022-10-03T12:15:23Z,,stat.ME,http://arxiv.org/pdf/2210.00847v1,eng,,,Biochemistry
80,http://arxiv.org/abs/2003.10534v1,A new paradigm for accelerating clinical data science at Stanford  Medicine,"Stanford Medicine is building a new data platform for our academic researchcommunity to do better clinical data science. Hospitals have a large amount ofpatient data and researchers have demonstrated the ability to reuse that dataand AI approaches to derive novel insights, support patient care, and improvecare quality. However, the traditional data warehouse and Honest Brokerapproaches that are in current use, are not scalable. We are establishing a newsecure Big Data platform that aims to reduce time to access and analyze data.In this platform, data is anonymized to preserve patient data privacy and madeavailable preparatory to Institutional Review Board (IRB) submission.Furthermore, the data is standardized such that analysis done at Stanford canbe replicated elsewhere using the same analytical code and clinical concepts.Finally, the analytics data warehouse integrates with a secure data sciencecomputational facility to support large scale data analytics. The ecosystem isdesigned to bring the modern data science community to highly sensitiveclinical data in a secure and collaborative big data analytics environment witha goal to enable bigger, better and faster science.","Somalee Datta, Jose Posada, Garrick Olson, Wencheng Li, Ciaran O'Reilly, Deepa Balraj, Joseph Mesterhazy, Joseph Pallas, Priyamvada Desai, Nigam Shah",2020-03-17T16:21:42Z,2020-03-17T16:21:42Z,Total of 44 pages. Main has total of 18 pages including references,cs.CY,http://arxiv.org/pdf/2003.10534v1,eng,,,Medicine
81,http://arxiv.org/abs/2106.09399v2,Using current research information systems to investigate data  acquisition and data sharing practices of computer scientists,"Without sufficient information about research data practices occurring in aparticular research organisation, there is a risk of mismatching research dataservice efforts with the needs of its researchers. This study describes howdata acquiring and data sharing occurring within a particular researchorganisation can be investigated by using current research information systempublication data. A sample of 193 journal articles published by researchers inthe computer science department of the case study's university during 2019 wereextracted for scrutiny from the current research information system. For these193 articles, a classification of the main study types was developed toaccommodate the multidisciplinary nature of the case department's researchagenda. Furthermore, a coding framework was developed to capture the keyelements of data acquiring and data sharing. The articles representing lifesciences and computational research relatively frequently reused open data,whereas data acquisition of experimental research, human interaction studiesand human intervention studies often relied on collecting original data. Datasharing also differed between the computationally intensive study types of lifesciences and computational research and the study types relying on collectionof original data. Research data were not available for reuse in only a minorityof life science (n= 2; 7%) and computational research (n = 15; 14%) studies.The study types of experimental research, human interaction studies and humanintervention studies less frequently made their data available for reuse. Thisstudy demonstrates that analyses of publications listed in current researchinformation systems provide detailed descriptions how the affiliatedresearchers acquire and share research data.",Antti Mikael Rousi,2021-06-17T11:34:26Z,2022-05-11T10:49:57Z,e-pub ahead of print version,cs.DL,http://arxiv.org/pdf/2106.09399v2,eng,,,Social Sciences
82,http://arxiv.org/abs/1901.04824v1,Approaching Ethical Guidelines for Data Scientists,"The goal of this article is to inspire data scientists to participate in thedebate on the impact that their professional work has on society, and to becomeactive in public debates on the digital world as data science professionals.How do ethical principles (e.g., fairness, justice, beneficence, andnon-maleficence) relate to our professional lives? What lies in ourresponsibility as professionals by our expertise in the field? Morespecifically this article makes an appeal to statisticians to join that debate,and to be part of the community that establishes data science as a properprofession in the sense of Airaksinen, a philosopher working on professionalethics. As we will argue, data science has one of its roots in statistics andextends beyond it. To shape the future of statistics, and to takeresponsibility for the statistical contributions to data science, statisticiansshould actively engage in the discussions. First the term data science isdefined, and the technical changes that have led to a strong influence of datascience on society are outlined. Next the systematic approach from CNIL isintroduced. Prominent examples are given for ethical issues arising from thework of data scientists. Further we provide reasons why data scientists shouldengage in shaping morality around and to formulate codes of conduct and codesof practice for data science. Next we present established ethical guidelinesfor the related fields of statistics and computing machinery. Thereafternecessary steps in the community to develop professional ethics for datascience are described. Finally we give our starting statement for the debate:Data science is in the focal point of current societal development. Withoutbecoming a profession with professional ethics, data science will fail inbuilding trust in its interaction with and its much needed contributions tosociety!","Ursula Garzcarek, Detlef Steuer",2019-01-14T16:13:27Z,2019-01-14T16:13:27Z,"18 pages, submitted Nov 12th 2018",stat.OT,http://arxiv.org/pdf/1901.04824v1,eng,,,Social Sciences
83,http://arxiv.org/abs/2304.05325v1,Mining the Characteristics of Jupyter Notebooks in Data Science Projects,"Nowadays, numerous industries have exceptional demand for skills in datascience, such as data analysis, data mining, and machine learning. Thecomputational notebook (e.g., Jupyter Notebook) is a well-known data sciencetool adopted in practice. Kaggle and GitHub are two platforms where datascience communities are used for knowledge-sharing, skill-practicing, andcollaboration. While tutorials and guidelines for novice data science areavailable on both platforms, there is a low number of Jupyter Notebooks thatreceived high numbers of votes from the community. The high-voted notebook isconsidered well-documented, easy to understand, and applies the best datascience and software engineering practices. In this research, we aim tounderstand the characteristics of high-voted Jupyter Notebooks on Kaggle andthe popular Jupyter Notebooks for data science projects on GitHub. We plan tomine and analyse the Jupyter Notebooks on both platforms. We will performexploratory analytics, data visualization, and feature importances tounderstand the overall structure of these notebooks and to identify commonpatterns and best-practice features separating the low-voted and high-votednotebooks. Upon the completion of this research, the discovered insights can beapplied as training guidelines for aspiring data scientists and machinelearning practitioners looking to improve their performance from novice rankingJupyter Notebook on Kaggle to a deployable project on GitHub.","Morakot Choetkiertikul, Apirak Hoonlor, Chaiyong Ragkhitwetsagul, Siripen Pongpaichet, Thanwadee Sunetnanta, Tasha Settewong, Vacharavich Jiravatvanich, Urisayar Kaewpichai",2023-04-11T16:30:53Z,2023-04-11T16:30:53Z,,cs.SE,http://arxiv.org/pdf/2304.05325v1,eng,,,Social Sciences
84,http://arxiv.org/abs/2305.02420v2,Beyond case studies: Teaching data science critique and ethics through  sociotechnical surveillance studies,"Ethics have become an urgent concern for data science research, practice, andinstruction in the wake of growing critique of algorithms and systems showingthat they reinforce structural oppression. There has been increasing desire onthe part of data science educators to craft curricula that speak to thesecritiques, yet much ethics education remains individualized, focused onspecific cases, or too abstract and unapplicable. We synthesized some of themost popular critical data science works and designed a data science ethicscourse that spoke to the social phenomena at the root of critical data studies-- theories of oppression, social systems, power, history, and change --through analysis of a pressing sociotechnical system: surveillance systems.Through analysis of student reflections and final projects, we determined thatat the conclusion of the semester, all students had developed critical analysisskills that allowed them to investigate surveillance systems of their own andidentify their benefits, harms, main proponents, those who resist them, andtheir interplay with social systems, all while considering dimensions of race,class, gender, and more. We argue that this type of instruction -- directlyteaching data science ethics alongside social theory -- is a crucial next stepfor the field.","Nicholas Rabb, Desen Ozkan",2023-05-03T20:24:42Z,2024-12-05T17:44:02Z,,cs.CY,http://arxiv.org/pdf/2305.02420v2,eng,,,Social Sciences
85,http://arxiv.org/abs/2403.02568v2,Designing Born-Accessible Courses in Data Science and Visualization:  Challenges and Opportunities of a Remote Curriculum Taught by Blind  Instructors to Blind Students,"While recent years have seen a growing interest in accessible visualizationtools and techniques for blind people, little attention is paid to the learningopportunities and teaching strategies of data science and visualizationtailored for blind individuals. Whereas the former focuses on the accessibilityissues of data visualization tools, the latter is concerned with thelearnability of concepts and skills for data science and visualization. In thispaper, we present novel approaches to teaching data science and visualizationto blind students in an online setting. Taught by blind instructors, nine blindlearners having a wide range of professional backgrounds participated in atwo-week summer course. We describe the course design, teaching strategies, andlearning outcomes. We also discuss the challenges and opportunities of teachingdata science and visualization to blind students. Our work contributes to thegrowing body of knowledge on accessible data science and visualizationeducation, and provides insights into the design of online courses for blindstudents.","JooYoung Seo, Sile O'Modhrain, Yilin Xia, Sanchita Kamath, Bongshin Lee, James M. Coughlan",2024-03-05T00:49:13Z,2024-05-22T19:45:14Z,,cs.HC,http://arxiv.org/pdf/2403.02568v2,eng,,,Medicine
86,http://arxiv.org/abs/2011.06820v1,Practical Privacy-Preserving Data Science With Homomorphic Encryption:  An Overview,"Privacy has gained a growing interest nowadays due to the increasing andunmanageable amount of produced confidential data. Concerns about thepossibility of sharing data with third parties, to gain fruitful insights,beset enterprise environments; value not only resides in data but also in theintellectual property of algorithms and models that offer analysis results.This impasse locks both the availability of high-performance computingresources in the ""as-a-service"" paradigm and the exchange of knowledge with thescientific community in a collaborative view. Privacy-preserving data scienceenables the use of private data and algorithms without putting at risk theirprivacy. Conventional encryption schemes are not able to work on encrypted datawithout decrypting them first. Homomorphic Encryption (HE) is a form ofencryption that allows the computation of encrypted data while preserving thefeatures and the format of the plaintext. Against the background of interestinguse cases for the Central Bank of Italy, this article focuses on how HE anddata science can be leveraged for the design and development ofprivacy-preserving enterprise applications. We propose a survey of mainHomomorphic Encryption techniques and recent advances in the conubium betweendata science and HE.",Michela Iezzi,2020-11-13T09:20:27Z,2020-11-13T09:20:27Z,"accepted, International Workshop on Privacy and Security of Big Data,
  IEEE International Conference on Big Data 2020",cs.CR,http://arxiv.org/pdf/2011.06820v1,eng,,,Computer Science
87,http://arxiv.org/abs/1803.04219v1,Data Science Methodology for Cybersecurity Projects,"Cyber-security solutions are traditionally static and signature-based. Thetraditional solutions along with the use of analytic models, machine learningand big data could be improved by automatically trigger mitigation or providerelevant awareness to control or limit consequences of threats. This kind ofintelligent solutions is covered in the context of Data Science forCyber-security. Data Science provides a significant role in cyber-security byutilising the power of data (and big data), high-performance computing and datamining (and machine learning) to protect users against cyber-crimes. For thispurpose, a successful data science project requires an effective methodology tocover all issues and provide adequate resources. In this paper, we areintroducing popular data science methodologies and will compare them inaccordance with cyber-security challenges. A comparison discussion has alsodelivered to explain methodologies strengths and weaknesses in case ofcyber-security projects.","Farhad Foroughi, Peter Luksch",2018-03-12T12:34:12Z,2018-03-12T12:34:12Z,,cs.CY,http://arxiv.org/pdf/1803.04219v1,eng,,,Computer Science
88,http://arxiv.org/abs/2004.11113v1,Human-Machine Collaboration for Democratizing Data Science,"Everybody wants to analyse their data, but only few posses the data scienceexpertise to to this. Motivated by this observation we introduce a novelframework and system \textsc{VisualSynth} for human-machine collaboration indata science.  It wants to democratize data science by allowing users to interact withstandard spreadsheet software in order to perform and automate various dataanalysis tasks ranging from data wrangling, data selection, clustering,constraint learning, predictive modeling and auto-completion.\textsc{VisualSynth} relies on the user providing colored sketches, i.e.,coloring parts of the spreadsheet, to partially specify data science tasks,which are then determined and executed using artificial intelligencetechniques.","Clément Gautrais, Yann Dauxais, Stefano Teso, Samuel Kolb, Gust Verbruggen, Luc De Raedt",2020-04-23T12:50:52Z,2020-04-23T12:50:52Z,26 pages,cs.AI,http://arxiv.org/pdf/2004.11113v1,eng,,,Medicine
89,http://arxiv.org/abs/2204.10174v1,Evolution and use of data science vocabulary. How much have we changed  in 13 years?,"Here I present an investigation on the evolution and use of vocabulary indata science in the last 13 years. Based on a rigorous statistical analysis, adatabase with 12,787 documents containing the words ""data science"" in thetitle, abstract or keywords is analyzed. It is proposed to classify theevolution of this discipline in three periods: emergence, growth and boom.Characteristic words and pioneering documents are identified for each period.By proposing the distinctive vocabulary and relevant topics of data science andclassified in time periods, these results add value to the scientific communityof this discipline.",Igor Barahona,2022-03-28T23:31:54Z,2022-03-28T23:31:54Z,"14 Pages, in Spanish language. 5 Figures",cs.DL,http://arxiv.org/pdf/2204.10174v1,eng,,,Physics and Astronomy
90,http://arxiv.org/abs/1908.05986v1,FAIR and Open Computer Science Research Software,"In computational science and in computer science, research software is acentral asset for research. Computational science is the application ofcomputer science and software engineering principles to solving scientificproblems, whereas computer science is the study of computer hardware andsoftware design.  The Open Science agenda holds that science advances faster when we can buildon existing results. Therefore, research software has to be reusable foradvancing science. Thus, we need proper research software engineering forobtaining reusable and sustainable research software. This way, softwareengineering methods may improve research in other disciplines. However,research in software engineering and computer science itself will also benefitfrom reuse when research software is involved.  For good scientific practice, the resulting research software should be openand adhere to the FAIR principles (findable, accessible, interoperable andrepeatable) to allow repeatability, reproducibility, and reuse. Compared toresearch data, research software should be both archived for reproducibilityand actively maintained for reusability. The FAIR data principles do notrequire openness, but research software should be open source software.Established open source software licenses provide sufficient licensing options,such that it should be the rare exception to keep research software closed.  We review and analyze the current state in this area in order to giverecommendations for making computer science research software FAIR and open. Weobserve that research software publishing practices in computer science and incomputational science show significant differences.","Wilhelm Hasselbring, Leslie Carr, Simon Hettrick, Heather Packer, Thanassis Tiropanis",2019-08-16T14:26:08Z,2019-08-16T14:26:08Z,22 pages,cs.SE,http://arxiv.org/pdf/1908.05986v1,eng,,,Social Sciences
91,http://arxiv.org/abs/1808.01091v1,DataDeps.jl: Repeatable Data Setup for Replicable Data Science,"We present DataDeps.jl: a julia package for the reproducible handling ofstatic datasets to enhance the repeatability of scripts used in the data andcomputational sciences. It is used to automate the data setup part of runningsoftware which accompanies a paper to replicate a result. This step is commonlydone manually, which expends time and allows for confusion. This functionalityis also useful for other packages which require data to function (e.g. atrained machine learning based model). DataDeps.jl simplifies extendingresearch software by automatically managing the dependencies and makes iteasier to run another author's code, thus enhancing the reproducibility of datascience research.","Lyndon White, Roberto Togneri, Wei Liu, Mohammed Bennamoun",2018-08-03T05:51:46Z,2018-08-03T05:51:46Z,Source code: https://github.com/oxinabox/DataDeps.jl/,cs.SE,http://arxiv.org/pdf/1808.01091v1,eng,,,Computer Science
92,http://arxiv.org/abs/1409.0753v1,How many citations are there in the Data Citation Index?,"Descriptive analysis on the citation distribution of the Thomson Reuters'Data Citation Index by publication type and four broad areas: Science,Engineering & Technology, Humanities & Arts and Social Sciences.","Daniel Torres-Salinas, Evaristo Jiménez-Contreras, Nicolas Robinson-García",2014-09-02T15:24:34Z,2014-09-02T15:24:34Z,"Presented at the STI Conference held in Leiden, 3-5 september 2014",cs.DL,http://arxiv.org/pdf/1409.0753v1,eng,,,Medicine
93,http://arxiv.org/abs/1707.07029v1,"Data, Science and Society",Reflections on the Concept of Data and its Implications for Science andSociety,Claudio Gutierrez,2017-07-21T19:34:44Z,2017-07-21T19:34:44Z,"Notes for a talk at LEARN Final Conference, Economic Commission for
  Latin America and the Caribbean (ECLAC), Senate House, University of London,
  London, May 5th., 2017",cs.DL,http://arxiv.org/pdf/1707.07029v1,eng,,,Physics and Astronomy
94,http://arxiv.org/abs/1712.07349v1,Data Science: A Three Ring Circus or a Big Tent?,"This is part of a collection of discussion pieces on David Donoho's paper 50Years of Data Science, appearing in Volume 26, Issue 4 of the Journal ofComputational and Graphical Statistics (2017).","Jennifer Bryan, Hadley Wickham",2017-12-20T07:41:45Z,2017-12-20T07:41:45Z,,stat.OT,http://arxiv.org/pdf/1712.07349v1,eng,,,Computer Science
95,http://arxiv.org/abs/2201.00247v1,Now is the time to build a national data ecosystem for materials science  and chemistry research data,"A call for coordinated action from government, academia, and industry.","E. M. Campo, S. Shankar, A. S. Szalay, R. J. Hanisch",2022-01-01T22:40:23Z,2022-01-01T22:40:23Z,,cond-mat.mtrl-sci,http://arxiv.org/pdf/2201.00247v1,eng,,,Social Sciences
96,http://arxiv.org/abs/2311.14683v1,Data Science for Social Good,"Data science has been described as the fourth paradigm for scientificdiscovery. The latest wave of data science research, pertaining to machinelearning and artificial intelligence (AI), is growing exponentially andgarnering millions of annual citations. However, this growth has beenaccompanied by a diminishing emphasis on social good challenges - our analysisreveals that the proportion of data science research focusing on social good isless than it has ever been. At the same time, the proliferation of machinelearning and generative AI have sparked debates about the socio-technicalprospects and challenges associated with data science for human flourishing,organizations, and society. Against this backdrop, we present a framework for""data science for social good"" (DSSG) research that considers the interplaybetween relevant data science research genres, social good challenges, anddifferent levels of socio-technical abstraction. We perform an analysis of theliterature to empirically demonstrate the paucity of work on DSSG ininformation systems (and other related disciplines) and highlight currentimpediments. We then use our proposed framework to introduce the articlesappearing in the special issue. We hope that this article and the special issuewill spur future DSSG research and help reverse the alarming trend across datascience research over the past 30-plus years in which social good challengesare garnering proportionately less attention with each passing day.","Ahmed Abbasi, Roger H. L. Chiang, Jennifer J. Xu",2023-11-02T15:40:20Z,2023-11-02T15:40:20Z,,cs.CY,http://arxiv.org/pdf/2311.14683v1,eng,,,Social Sciences
97,http://arxiv.org/abs/1604.02608v1,A Case for Data Commons: Towards Data Science as a Service,"As the amount of scientific data continues to grow at ever faster rates, theresearch community is increasingly in need of flexible computationalinfrastructure that can support the entirety of the data science lifecycle,including long-term data storage, data exploration and discovery services, andcompute capabilities to support data analysis and re-analysis, as new data areadded and as scientific pipelines are refined. We describe our experiencedeveloping data commons-- interoperable infrastructure that co-locates data,storage, and compute with common analysis tools--and present several casesstudies. Across these case studies, several common requirements emerge,including the need for persistent digital identifier and metadata services,APIs, data portability, pay for compute capabilities, and data peeringagreements between data commons. Though many challenges, includingsustainability and developing appropriate standards remain, interoperable datacommons bring us one step closer to effective Data Science as Service for thescientific research community.","Robert L. Grossman, Allison Heath, Mark Murphy, Maria Patterson, Walt Wells",2016-04-09T20:46:01Z,2016-04-09T20:46:01Z,,cs.CY,http://arxiv.org/pdf/1604.02608v1,eng,,,Social Sciences
98,http://arxiv.org/abs/1503.05570v1,A Data Science Course for Undergraduates: Thinking with Data,"Data science is an emerging interdisciplinary field that combines elements ofmathematics, statistics, computer science, and knowledge in a particularapplication domain for the purpose of extracting meaningful information fromthe increasingly sophisticated array of data available in many settings. Thesedata tend to be non-traditional, in the sense that they are often live, large,complex, and/or messy. A first course in statistics at the undergraduate leveltypically introduces students with a variety of techniques to analyze small,neat, and clean data sets. However, whether they pursue more formal training instatistics or not, many of these students will end up working with data that isconsiderably more complex, and will need facility with statistical computingtechniques. More importantly, these students require a framework for thinkingstructurally about data. We describe an undergraduate course in a liberal artsenvironment that provides students with the tools necessary to apply datascience. The course emphasizes modern, practical, and useful skills that coverthe full data analysis spectrum, from asking an interesting question toacquiring, managing, manipulating, processing, querying, analyzing, andvisualizing data, as well communicating findings in written, graphical, andoral forms.",Ben Baumer,2015-03-18T20:05:24Z,2015-03-18T20:05:24Z,21 pages total including supplementary materials,stat.OT,http://arxiv.org/pdf/1503.05570v1,eng,,,Social Sciences
99,http://arxiv.org/abs/1705.07747v1,What does it all mean? Capturing Semantics of Surgical Data and  Algorithms with Ontologies,"Every year approximately 234 million major surgeries are performed, leadingto plentiful, highly diverse data. This is accompanied by a matching number ofnovel algorithms for the surgical domain. To garner all benefits of surgicaldata science it is necessary to have an unambiguous, shared understanding ofalgorithms and data. This includes inputs and outputs of algorithms and thustheir function, but also the semantic content, i.e. meaning of data such aspatient parameters. We therefore propose the establishment of a new ontologyfor data and algorithms in surgical data science. Such an ontology can be usedto provide common data sets for the community, encouraging sharing of knowledgeand comparison of algorithms on common data. We hold that this is a necessaryfoundation towards new methods for applications such as semantic-based contentretrieval and similarity measures and that it is overall vital for the futureof surgical data science.","Darko Katić, Maria Maleshkova, Sandy Engelhardt, Ivo Wolf, Keno März, Lena Maier-Hein, Marco Nolden, Martin Wagner, Hannes Kenngott, Beat Peter Müller-Stich, Rüdiger Dillmann, Stefanie Speidel",2017-05-22T13:53:13Z,2017-05-22T13:53:13Z,"4 pages, 1 figure, Surgical Data Science Workshop, Heidelberg, June
  20th, 2016",cs.CY,http://arxiv.org/pdf/1705.07747v1,eng,,,Medicine
100,http://arxiv.org/abs/1809.00984v1,The materials data ecosystem: materials data science and its role in  data-driven materials discovery,"Since its launch in 2011, Materials Genome Initiative (MGI) has drawn theattention of researchers from across academia, government, and industryworldwide.As one of the three tools of MGI, the materials data, for the firsttime, emerged as an extremely significant approach in materials discovery. Datascience has been applied in different disciplines as an interdisciplinary fieldto extract knowledge from the data. The concept of materials data science wasutilized to demonstrate the data application in materials science. To exploreits potential as an active research branch in the big data age, a three-tiersystem was put forward to define the infrastructure of data classification,curation and knowledge extraction of materials data.","Hai-Qing Yin, Xue Jiang, Guo-Quan Liu, Sharon Elder, Bin Xu1, Qing-Jun Zheng, Xuan-Hui Qu",2018-08-29T06:53:06Z,2018-08-29T06:53:06Z,,cs.CY,http://arxiv.org/pdf/1809.00984v1,eng,,,Social Sciences
101,http://arxiv.org/abs/1506.05632v1,An Open Science Platform for the Next Generation of Data,"Imagine an online work environment where researchers have direct andimmediate access to myriad data sources and tools and data managementresources, useful throughout the research lifecycle. This is our vision for thenext generation of the Dataverse Network: an Open Science Platform (OSP). Forthe first time, researchers would be able to seamlessly access and createprimary and derived data from a variety of sources: prior research results,public data sets, harvested online data, physical instruments, private datacollections, and even data from other standalone repositories. Researcherscould recruit research participants and conduct research directly on the OSP,if desired, using readily available tools. Researchers could create private orshared workspaces to house data, access tools, and computation and couldpublish data directly on the platform or publish elsewhere with persistent,data citations on the OSP. This manuscript describes the details of an OpenScience Platform and its construction. Having an Open Science Platform willespecially impact the rate of new scientific discoveries and make scientificfindings more credible and accountable.","Latanya Sweeney, Merce Crosas",2015-06-18T11:31:55Z,2015-06-18T11:31:55Z,"32 pages, 8 figures",cs.CY,http://arxiv.org/pdf/1506.05632v1,eng,,,Computer Science
102,http://arxiv.org/abs/2302.11775v1,Don't Look at the Data! How Differential Privacy Reconfigures the  Practices of Data Science,"Across academia, government, and industry, data stewards are facingincreasing pressure to make datasets more openly accessible for researcherswhile also protecting the privacy of data subjects. Differential privacy (DP)is one promising way to offer privacy along with open access, but furtherinquiry is needed into the tensions between DP and data science. In this study,we conduct interviews with 19 data practitioners who are non-experts in DP asthey use a DP data analysis prototype to release privacy-preserving statisticsabout sensitive data, in order to understand perceptions, challenges, andopportunities around using DP. We find that while DP is promising for providingwider access to sensitive datasets, it also introduces challenges into everystage of the data science workflow. We identify ethics and governance questionsthat arise when socializing data scientists around new privacy constraints andoffer suggestions to better integrate DP and data science.","Jayshree Sarathy, Sophia Song, Audrey Haque, Tania Schlatter, Salil Vadhan",2023-02-23T04:28:14Z,2023-02-23T04:28:14Z,,cs.HC,http://arxiv.org/pdf/2302.11775v1,eng,,,Computer Science
103,http://arxiv.org/abs/2303.01378v1,A Vision for Semantically Enriched Data Science,"The recent efforts in automation of machine learning or data science hasachieved success in various tasks such as hyper-parameter optimization or modelselection. However, key areas such as utilizing domain knowledge and datasemantics are areas where we have seen little automation. Data Scientists havelong leveraged common sense reasoning and domain knowledge to understand andenrich data for building predictive models. In this paper we discuss importantshortcomings of current data science and machine learning solutions. We thenenvision how leveraging ""semantic"" understanding and reasoning on data incombination with novel tools for data science automation can help withconsistent and explainable data augmentation and transformation. Additionally,we discuss how semantics can assist data scientists in a new manner by helpingwith challenges related to trust, bias, and explainability in machine learning.Semantic annotation can also help better explore and organize large datasources.","Udayan Khurana, Kavitha Srinivas, Sainyam Galhotra, Horst Samulowitz",2023-03-02T16:03:12Z,2023-03-02T16:03:12Z,arXiv admin note: substantial text overlap with arXiv:2205.08018,cs.AI,http://arxiv.org/pdf/2303.01378v1,eng,,,Social Sciences
104,http://arxiv.org/abs/1808.08474v3,A Taxonomy on Big Data: Survey,"The Big Data is the most popular paradigm nowadays and it has almost nountouched area. For instance, science, engineering, economics, business, socialscience, and government. The Big Data are used to boost up the organizationperformance using massive amount of dataset. The Data are assets of theorganization, and these data gives revenue to the organizations. Therefore, theBig Data is spawning everywhere to enhance the organizations' revenue. Thus,many new technologies emerging based on Big Data. In this paper, we present thetaxonomy of Big Data. Besides, we present in-depth insight on the Big Dataparadigm.",Ripon Patgiri,2018-08-25T21:47:23Z,2019-11-25T17:43:46Z,"15 pages, 15 figures, 5 tables, and a survey paper",cs.DC,http://arxiv.org/pdf/1808.08474v3,eng,,,Computer Science
105,http://arxiv.org/abs/2202.01717v1,A User-Friendly Environment for Battery Data Science,"We report a user-friendly software environment for battery data science. Itis designed to streamline data management, data cleaning, and data analysis tohelp bridge the gap between the domain expertise of most battery scientists andthe tools needed as the field becomes increasingly data intensive. The softwaresolution suitable for ingesting battery test data from disparate sources. Byaggregating data in an intelligent way, users can streamline routine dataanalysis tasks and leverage Jupyter Notebook functionality to build advancedscripts and analytics, thereby making battery engineering teams moreproductive.","Robert Masse, Dan Ulery, Hardik Kamdar",2022-02-03T17:34:04Z,2022-02-03T17:34:04Z,,eess.SY,http://arxiv.org/pdf/2202.01717v1,eng,,,Computer Science
106,http://arxiv.org/abs/1508.02387v1,Indonesia embraces the Data Science,"The information era is the time when information is not only largelygenerated, but also vastly processed in order to extract and generated moreinformation. The complex nature of modern living is represented by the variouskind of data. Data can be in the forms of signals, images, texts, or manifoldsresembling the horizon of observation. The task of the emerging data sciencesare to extract information from the data, for people gain new insights of thecomplex world. The insights may came from the new way of the datarepresentation, be it a visualizations, mapping, or other. The insights mayalso come from the implementation of mathematical analysis and or computationalprocessing giving new insights of what the states of the nature represented bythe data. Both ways implement the methodologies reducing the dimensionality ofthe data. The relations between the two functions, representation and analysisare the heart of how information in data is transformed mathematically andcomputationally into new information. The paper discusses some practices, alongwith various data coming from the social life in Indonesia to gain new insightsabout Indonesia in the emerging data sciences. The data sciences in Indonesiahas made Indonesian Data Cartograms, Indonesian Celebrity Sentiment Mapping,Ethno-Clustering Maps, social media community detection, and a lot more tocome, become possible. All of these are depicted as the exemplifications on howData Science has become integral part of the technology bringing data closer topeople.",Hokky Situngkir,2015-08-10T19:45:48Z,2015-08-10T19:45:48Z,"Paper presented in South East Asian Mathematical Society (SEAMS) 7th
  Conference, 10 pages, 7 figures",cs.CY,http://arxiv.org/pdf/1508.02387v1,eng,,,Social Sciences
107,http://arxiv.org/abs/1811.02491v1,Mobile Data Science: Towards Understanding Data-Driven Intelligent  Mobile Applications,"Due to the popularity of smart mobile phones and context-aware technology,various contextual data relevant to users' diverse activities with mobilephones is available around us. This enables the study on mobile phone data andcontext-awareness in computing, for the purpose of building data-drivenintelligent mobile applications, not only on a single device but also in adistributed environment for the benefit of end users. Based on the availabilityof mobile phone data, and the usefulness of data-driven applications, in thispaper, we discuss about mobile data science that involves in collecting themobile phone data from various sources and building data-driven models usingmachine learning techniques, in order to make dynamic decisions intelligentlyin various day-to-day situations of the users. For this, we first discuss thefundamental concepts and the potentiality of mobile data science to buildintelligent applications. We also highlight the key elements and explainvarious key modules involving in the process of mobile data science. Thisarticle is the first in the field to draw a big picture, and thinking aboutmobile data science, and it's potentiality in developing various data-drivenintelligent mobile applications. We believe this study will help both theresearchers and application developers for building smart data-driven mobileapplications, to assist the end mobile phone users in their daily activities.",Iqbal H. Sarker,2018-10-15T20:19:46Z,2018-10-15T20:19:46Z,"Journal, 11 pages, Double Column",cs.CY,http://arxiv.org/pdf/1811.02491v1,eng,,,Computer Science
108,http://arxiv.org/abs/2208.03461v1,Data science in public health: building next generation capacity,"Rapidly evolving technology, data and analytic landscapes are permeating manyfields and professions. In public health, the need for data science skillsincluding data literacy is particularly prominent given both the potential ofnovel data types and analysis methods to fill gaps in existing public healthresearch and intervention practices, as well as the potential of such data ormethods to perpetuate or augment health disparities. Through a review of publichealth courses and programs at the top 10 U.S. and globally ranked schools ofpublic health, this article summarizes existing educational efforts in publichealth data science. These existing practices serve to inform efforts forbroadening such curricula to further schools and populations. Data scienceethics course offerings are also examined in context of assessing howpopulation health principles can be blended into training across levels of datainvolvement to augment the traditional core of public health curricula.Parallel findings from domestic and international 'outside the classroom'training programs are also synthesized to advance approaches for increasingdiversity in public health data science. Based on these program reviews andtheir synthesis, a four-point formula is distilled for furthering public healthdata science education efforts, toward development of a critical and inclusivemass of practitioners with fluency to leverage data to advance goals of publichealth and improve quality of life in the digital age.","Nicholas Mirin, Heather Mattie, Latifa Jackson, Zainab Samad, Rumi Chunara",2022-08-06T08:09:42Z,2022-08-06T08:09:42Z,,cs.CY,http://arxiv.org/pdf/2208.03461v1,eng,,,Social Sciences
109,http://arxiv.org/abs/1710.08728v1,Greater data science at baccalaureate institutions,"Donoho's JCGS (in press) paper is a spirited call to action forstatisticians, who he points out are losing ground in the field of data scienceby refusing to accept that data science is its own domain. (Or, at least, adomain that is becoming distinctly defined.) He calls on writings by JohnTukey, Bill Cleveland, and Leo Breiman, among others, to remind us thatstatisticians have been dealing with data science for years, and encouragesacceptance of the direction of the field while also ensuring that statistics istightly integrated.  As faculty at baccalaureate institutions (where the growth of undergraduatestatistics programs has been dramatic), we are keen to ensure statistics has aplace in data science and data science education. In his paper, Donoho isprimarily focused on graduate education. At our undergraduate institutions, weare considering many of the same questions.","Amelia McNamara, Nicholas J. Horton, Benjamin S. Baumer",2017-10-24T12:23:20Z,2017-10-24T12:23:20Z,"in press response to Donoho paper in Journal of Computational
  Graphics and Statistics",stat.OT,http://arxiv.org/pdf/1710.08728v1,eng,,,Social Sciences
110,http://arxiv.org/abs/2012.12144v1,"Integrating computing in the statistics and data science curriculum:  Creative structures, novel skills and habits, and ways to teach computational  thinking","Nolan and Temple Lang (2010) argued for the fundamental role of computing inthe statistics curriculum. In the intervening decade the statistics educationcommunity has acknowledged that computational skills are as important tostatistics and data science practice as mathematics. There remains a notablegap, however, between our intentions and our actions. In this special issue ofthe *Journal of Statistics and Data Science Education* we have assembled acollection of papers that (1) suggest creative structures to integratecomputing, (2) describe novel data science skills and habits, and (3) proposeways to teach computational thinking. We believe that it is critical for thecommunity to redouble our efforts to embrace sophisticated computing in thestatistics and data science curriculum. We hope that these papers provideuseful guidance for the community to move these efforts forward.","Nicholas J. Horton, Johanna S. Hardin",2020-12-22T16:28:18Z,2020-12-22T16:28:18Z,"In press, Journal of Statistics and Data Science Education",stat.OT,http://arxiv.org/pdf/2012.12144v1,eng,,,Social Sciences
111,http://arxiv.org/abs/2103.10489v1,Addressing Hate Speech with Data Science: An Overview from Computer  Science Perspective,"From a computer science perspective, addressing on-line hate speech is achallenging task that is attracting the attention of both industry (mainlysocial media platform owners) and academia. In this chapter, we provide anoverview of state-of-the-art data-science approaches - how they define hatespeech, which tasks they solve to mitigate the phenomenon, and how they addressthese tasks. We limit our investigation mostly to (semi-)automatic detection ofhate speech, which is the task that the majority of existing computer scienceworks focus on. Finally, we summarize the challenges and the open problems inthe current data-science research and the future directions in this field. Ouraim is to prepare an easily understandable report, capable to promote themultidisciplinary character of hate speech research. Researchers from otherdomains (e.g., psychology and sociology) can thus take advantage of theknowledge achieved in the computer science domain but also contribute back andhelp improve how computer science is addressing that urgent and sociallyrelevant issue which is the prevalence of hate speech in social media.","Ivan Srba, Gabriele Lenzini, Matus Pikuliak, Samuel Pecar",2021-03-18T19:19:44Z,2021-03-18T19:19:44Z,,cs.CY,http://arxiv.org/pdf/2103.10489v1,eng,,,Computer Science
112,http://arxiv.org/abs/1904.10423v2,A Data Ecosystem to Support Machine Learning in Materials Science,"Facilitating the application of machine learning to materials scienceproblems will require enhancing the data ecosystem to enable discovery andcollection of data from many sources, automated dissemination of new dataacross the ecosystem, and the connecting of data with materials-specificmachine learning models. Here, we present two projects, the Materials DataFacility (MDF) and the Data and Learning Hub for Science (DLHub), that addressthese needs. We use examples to show how MDF and DLHub capabilities can beleveraged to link data with machine learning models and how users can accessthose capabilities through web and programmatic interfaces.","Ben Blaiszik, Logan Ward, Marcus Schwarting, Jonathon Gaff, Ryan Chard, Daniel Pike, Kyle Chard, Ian Foster",2019-04-23T17:02:08Z,2019-07-21T01:37:46Z,"23 pages, 6 figures, submitted to MRS Communications special issue on
  AI in Materials Science",cond-mat.mtrl-sci,http://arxiv.org/pdf/1904.10423v2,eng,,,Computer Science
113,http://arxiv.org/abs/2111.13186v1,Federated Data Science to Break Down Silos [Vision],"Similar to Open Data initiatives, data science as a community has launchedinitiatives for sharing not only data but entire pipelines, derivatives,artifacts, etc. (Open Data Science). However, the few efforts that exist focuson the technical part on how to facilitate sharing, conversion, etc. Thisvision paper goes a step further and proposes KEK, an open federated datascience platform that does not only allow for sharing data science pipelinesand their (meta)data but also provides methods for efficient search and, in theideal case, even allows for combining and defining pipelines across platformsin a federated manner. In doing so, KEK addresses the so far neglectedchallenge of actually finding artifacts that are semantically related and thatcan be combined to achieve a certain goal.","Essam Mansour, Kavitha Srinivas, Katja Hose",2021-11-25T17:41:34Z,2021-11-25T17:41:34Z,Accepted at SIGMOD Record,cs.LG,http://arxiv.org/pdf/2111.13186v1,eng,,,Medicine
114,http://arxiv.org/abs/2205.11026v2,Three principles for modernizing an undergraduate regression analysis  course,"As data have become more prevalent in academia, industry, and daily life, itis imperative that undergraduate students are equipped with the skills neededto analyze data in the modern environment. In recent years there has been a lotof work innovating introductory statistics courses and developing introductorydata science courses; however, there has been less work beyond the firstcourse. This paper describes innovations to Regression Analysis taught at DukeUniversity, a course focused on application that serves a diverse undergraduatestudent population of statistics and data science majors along with non-majors.Three principles guiding the modernization of the course are presented withdetails about how these principles align with the necessary skills of practiceoutlined in recent statistics and data science curriculum guidelines. The paperincludes pedagogical strategies, motivated by the innovations in introductorycourses, that make it feasible to implement skills for the practice of modernstatistics and data science alongside fundamental statistical concepts. Thepaper concludes with the impact of these changes, challenges, and next stepsfor the course. Portions of in-class activities and assignments are included inthe paper, with full sample assignments and resources for finding data in thesupplemental materials.",Maria Tackett,2022-05-23T03:52:39Z,2023-01-03T18:02:03Z,Journal of Statistics and Data Science Education (2023),stat.OT,http://arxiv.org/pdf/2205.11026v2,eng,,,Social Sciences
115,http://arxiv.org/abs/2205.15686v2,The NOMAD Artificial-Intelligence Toolkit: Turning materials-science  data into knowledge and understanding,"We present the Novel-Materials-Discovery (NOMAD) Artificial-Intelligence (AI)Toolkit, a web-browser-based infrastructure for the interactive AI-basedanalysis of materials-science findable, accessible, interoperable, and reusable(FAIR) data. The AI Toolkit readily operates on the FAIR data stored in thecentral server of the NOMAD Archive, the largest database of materials-sciencedata worldwide, as well as locally stored, users' owned data. The NOMAD Oasis,a local, stand alone server can be also used to run the AI Toolkit. By usingJupyter notebooks that run in a web-browser, the NOMAD data can be queried andaccessed; data mining, machine learning, and other AI techniques can be thenapplied to analyse them. This infrastructure brings the concept ofreproducibility in materials science to the next level, by allowing researchersto share not only the data contributing to their scientific publications, butalso all the developed methods and analytics tools. Besides reproducingpublished results, users of the NOMAD AI toolkit can modify the Jupyternotebooks towards their own research work.","Luigi Sbailò, Ádám Fekete, Luca M. Ghiringhelli, Matthias Scheffler",2022-05-31T11:04:55Z,2022-11-09T10:30:24Z,"Accepted for publication on npj Computational Materials on November
  9, 2022",cond-mat.mtrl-sci,http://arxiv.org/pdf/2205.15686v2,eng,,,Medicine
116,http://arxiv.org/abs/1707.04826v1,Machine learning application in the life time of materials,"Materials design and development typically takes several decades from theinitial discovery to commercialization with the traditional trial and errordevelopment approach. With the accumulation of data from both experimental andcomputational results, data based machine learning becomes an emerging field inmaterials discovery, design and property prediction. This manuscript reviewsthe history of materials science as a disciplinary the most common machinelearning method used in materials science, and specifically how they are usedin materials discovery, design, synthesis and even failure detection andanalysis after materials are deployed in real application. Finally, thelimitations of machine learning for application in materials science andchallenges in this emerging field is discussed.",Xiaojiao Yu,2017-07-16T05:58:40Z,2017-07-16T05:58:40Z,"12 pages, 5 figures",cond-mat.mtrl-sci,http://arxiv.org/pdf/1707.04826v1,eng,,,Engineering
117,http://arxiv.org/abs/2202.01871v1,A Bibliometric Perspective of Social Science Scientific Communities of  Pakistan and India,"In this study, we use research publication data from the field of socialscience to identify collaboration networks among social science researchcommunities of India and Pakistan. We have used Scopus database to extractinformation of social science journals for both countries India and Pakistan.Study of this data is significant as both countries have common social issuesand many of common social values. Keywords analysis has been done to see commonresearch areas in both communities like poverty, education, the issue of genderetc. Despite having many of the common social issues, collaboration amongsocial science research communities of both countries is not strong.","Sami Ul-Haq, Saeed-Ul Hassan",2022-02-03T22:06:52Z,2022-02-03T22:06:52Z,"35 page, 8 Tables, 10 Figures",cs.DL,http://arxiv.org/pdf/2202.01871v1,eng,,,Medicine
118,http://arxiv.org/abs/2305.03797v1,Materials Informatics: An Algorithmic Design Rule,"Materials informatics, data-enabled investigation, is a ""fourth paradigm"" inmaterials science research after the conventional empirical approach,theoretical science, and computational research. Materials informatics has twoessential ingredients: fingerprinting materials proprieties and the theory ofstatistical inference and learning. We have researched the organicsemiconductor's enigmas through the materials informatics approach. By applyingdiverse neural network topologies, logical axiom, and inferencing informationscience, we have developed data-driven procedures for novel organicsemiconductor discovery for the semiconductor industry and knowledge extractionfor the materials science community. We have reviewed and corresponded withvarious algorithms for the neural network design topology for the materialsinformatics dataset.",Bhupesh Bishnoi,2023-05-05T18:55:32Z,2023-05-05T18:55:32Z,"59 pages, 24 figures",cond-mat.mtrl-sci,http://arxiv.org/pdf/2305.03797v1,eng,,,Engineering
119,http://arxiv.org/abs/2309.12959v1,Proceedings 7th Symposium on Working Formal Methods,"This volume contains the proceedings of the 7th Working Formal MethodsSymposium, which was held at the University of Bucharest, September 21-22,2023.","Horaţiu Cheval, Laurenţiu Leuştean, Andrei Sipoş",2023-09-22T15:57:54Z,2023-09-22T15:57:54Z,,cs.LO,http://arxiv.org/pdf/2309.12959v1,eng,,,Medicine
120,http://arxiv.org/abs/2312.00818v1,The perpetual motion machine of AI-generated data and the distraction of  ChatGPT-as-scientist,"Since ChatGPT works so well, are we on the cusp of solving science with AI?Is not AlphaFold2 suggestive that the potential of LLMs in biology and thesciences more broadly is limitless? Can we use AI itself to bridge the lack ofdata in the sciences in order to then train an AI? Herein we present adiscussion of these topics.",Jennifer Listgarten,2023-11-29T21:52:34Z,2023-11-29T21:52:34Z,,cs.LG,http://arxiv.org/pdf/2312.00818v1,eng,,,Medicine
121,http://arxiv.org/abs/1212.5596v1,"Data Life Cycle Labs, A New Concept to Support Data-Intensive Science","In many sciences the increasing amounts of data are reaching the limit ofestablished data handling and processing. With four large research centers ofthe German Helmholtz association the Large Scale Data Management and Analysis(LSDMA) project supports an initial set of scientific projects, initiatives andinstruments to organize and efficiently analyze the increasing amount of dataproduced in modern science. LSDMA bridges the gap between data production anddata analysis using a novel approach by combining specific community supportand generic, cross community development. In the Data Life Cycle Labs (DLCL)experts from the data domain work closely with scientific groups of selectedresearch domains in joint R&D where community-specific data life cycles areiteratively optimized, data and meta-data formats are defined and standardized,simple access and use is established as well as data and scientific insightsare preserved in long-term and open accessible archives.","Jos van Wezel, Achim Streit, Christopher Jung, Rainer Stotzka, Silke Halstenberg, Fabian Rigoll, Ariel Garcia, Andreas Heiss, Kilian Schwarz, Martin Gasthuber, André Giesler",2012-12-21T16:16:25Z,2012-12-21T16:16:25Z,"8 pages, project white paper",cs.DL,http://arxiv.org/pdf/1212.5596v1,eng,,,Medicine
122,http://arxiv.org/abs/2203.09006v1,The Data Airlock: infrastructure for restricted data informatics,"Data science collaboration is problematic when access to operational data ormodels from outside the data-holding organisation is prohibited, for a varietyof legal, security, ethical, or practical reasons. There are significant dataprivacy challenges when performing collaborative data science work against suchrestricted data. In this paper we describe a range of causes and risksassociated with restricted data along with the social, environmental, data, andcryptographic measures that may be used to mitigate such issues. We then showhow these are generally inadequate for restricted data contexts and introducethe 'Data Airlock' - secure infrastructure that facilitates 'eyes-off' datascience workloads. After describing our use-case we detail the architecture andimplementation of a first, single-organisation version of the Data Airlockinfrastructure. We conclude with outcomes and learning from thisimplementation, and outline requirements for a second, federated version.","Gregory Rolan, Janis Dalins, Campbell Wilson",2022-03-17T00:54:40Z,2022-03-17T00:54:40Z,"9 pages, 2 figures",cs.IR,http://arxiv.org/pdf/2203.09006v1,eng,,,Computer Science
123,http://arxiv.org/abs/1205.1125v1,Application Of Data Mining In Bioinformatics,This article highlights some of the basic concepts of bioinformatics and datamining. The major research areas of bioinformatics are highlighted. Theapplication of data mining in the domain of bioinformatics is explained. Italso highlights some of the current challenges and opportunities of data miningin bioinformatics.,Khalid Raza,2012-05-05T12:19:33Z,2012-05-05T12:19:33Z,,cs.CE,http://arxiv.org/pdf/1205.1125v1,eng,,,Computer Science
124,http://arxiv.org/abs/1402.4578v3,Growth rates of modern science: A bibliometric analysis based on the  number of publications and cited references,"Many studies in information science have looked at the growth of science. Inthis study, we re-examine the question of the growth of science. To do this we(i) use current data up to publication year 2012 and (ii) analyse it across alldisciplines and also separately for the natural sciences and for the medicaland health sciences. Furthermore, the data are analysed with an advancedstatistical technique - segmented regression analysis - which can identifyspecific segments with similar growth rates in the history of science. Thestudy is based on two different sets of bibliometric data: (1) The number ofpublications held as source items in the Web of Science (WoS, Thomson Reuters)per publication year and (2) the number of cited references in the publicationsof the source items per cited reference year. We have looked at the rate atwhich science has grown since the mid-1600s. In our analysis of citedreferences we identified three growth phases in the development of science,which each led to growth rates tripling in comparison with the previous phase:from less than 1% up to the middle of the 18th century, to 2 to 3% up to theperiod between the two world wars and 8 to 9% to 2012.","Lutz Bornmann, Ruediger Mutz",2014-02-19T08:00:26Z,2014-05-08T07:38:15Z,"Accepted for publication in the Journal of the Association for
  Information Science and Technology",cs.DL,http://arxiv.org/pdf/1402.4578v3,eng,,,Medicine
125,http://arxiv.org/abs/2012.07675v3,Growth rates of modern science: A latent piecewise growth curve approach  to model publication numbers from established and new literature databases,"Growth of science is a prevalent issue in science of science studies. Inrecent years, two new bibliographic databases have been introduced which can beused to study growth processes in science from centuries back: Dimensions fromDigital Science and Microsoft Academic. In this study, we used publication datafrom these new databases and added publication data from two establisheddatabases (Web of Science from Clarivate Analytics and Scopus from Elsevier) toinvestigate scientific growth processes from the beginning of the modernscience system until today. We estimated regression models that includedsimultaneously the publication counts from the four databases. The results ofthe unrestricted growth of science calculations show that the overall growthrate amounts to 4.10% with a doubling time of 17.3 years. As the comparison ofvarious segmented regression models in the current study revealed, the modelwith five segments fits the publication data best. We demonstrated that thesesegments with different growth rates can be interpreted very well, since theyare related to either phases of economic (e.g., industrialization) and / orpolitical developments (e.g., Second World War). In this study, we additionallyanalyzed scientific growth in two broad fields (Physical and Technical Sciencesas well as Life Sciences) and the relationship of scientific and economicgrowth in UK. The comparison between the two fields revealed only slightdifferences. The comparison of the British economic and scientific growth ratesshowed that the economic growth rate is slightly lower than the scientificgrowth rate.","Lutz Bornmann, Robin Haunschild, Ruediger Mutz",2020-12-14T16:25:01Z,2021-09-21T06:16:02Z,,cs.DL,http://arxiv.org/pdf/2012.07675v3,eng,,,Agricultural and Biological Sciences
126,http://arxiv.org/abs/2307.03241v1,The Mathematics of Mathematics: Using Mathematics and Data Science to  Analyze the Mathematical Sciences Community and Enhance Social Justice,"We present and discuss a curated selection of recent literature related tothe application of quantitative techniques, tools, and topics from mathematicsand data science that have been used to analyze the mathematical sciencescommunity. We engage in this project with a focus on including research thathighlights, documents, or quantifies (in)equities that exist in themathematical sciences, specifically, and STEM (science, technology,engineering, and mathematics) more broadly. We seek to enhance social justicein the mathematics and data science communities by providing numerous examplesof the ways in which the mathematical sciences fails to meet standards ofequity, equal opportunity and inclusion. We introduce the term ``mathematics ofMathematics"" for this project, explicitly building upon the growing,interdisciplinary field known as ``Science of Science"" to interrogate,investigate, and identify the nature of the mathematical sciences itself. Weaim to promote, provide, and posit sources of productive collaborations and weinvite interested researchers to contribute to this developing body of work.","Ron Buckmire, Joseph E. Hibdon, Jr., Drew Lewis, Omayra Ortega, José L. Pabón, Rachel Roca, Andrés R. Vindas-Meléndez",2023-07-06T18:09:28Z,2023-07-06T18:09:28Z,"18 pages, comments welcomed",math.HO,http://arxiv.org/pdf/2307.03241v1,eng,,,Computer Science
127,http://arxiv.org/abs/1907.10226v1,Movement science needs different pose tracking algorithms,"Over the last decade, computer science has made progress towards extractingbody pose from single camera photographs or videos. This promises to enablemovement science to detect disease, quantify movement performance, and take thescience out of the lab into the real world. However, current pose trackingalgorithms fall short of the needs of movement science; the types of movementdata that matter are poorly estimated. For instance, the metrics currently usedfor evaluating pose tracking algorithms use noisy hand-labeled ground truthdata and do not prioritize precision of relevant variables likethree-dimensional position, velocity, acceleration, and forces which arecrucial for movement science. Here, we introduce the scientific disciplinesthat use movement data, the types of data they need, and discuss the changesneeded to make pose tracking truly transformative for movement science.","Nidhi Seethapathi, Shaofei Wang, Rachit Saluja, Gunnar Blohm, Konrad P. Kording",2019-07-24T03:54:22Z,2019-07-24T03:54:22Z,"13 pages, 2 figures, 1 table",cs.CV,http://arxiv.org/pdf/1907.10226v1,eng,,,Medicine
128,http://arxiv.org/abs/2310.18079v1,Supporting Better Insights of Data Science Pipelines with Fine-grained  Provenance,"Successful data-driven science requires complex data engineering pipelines toclean, transform, and alter data in preparation for machine learning, androbust results can only be achieved when each step in the pipeline can bejustified, and its effect on the data explained. In this framework, our aim isto provide data scientists with facilities to gain an in-depth understanding ofhow each step in the pipeline affects the data, from the raw input to trainingsets ready to be used for learning. Starting from an extensible set of datapreparation operators commonly used within a data science setting, in this workwe present a provenance management infrastructure for generating, storing, andquerying very granular accounts of data transformations, at the level ofindividual elements within datasets whenever possible. Then, from the formaldefinition of a core set of data science preprocessing operators, we derive aprovenance semantics embodied by a collection of templates expressed in PROV, astandard model for data provenance. Using those templates as a reference, ourprovenance generation algorithm generalises to any operator with observableinput/output pairs. We provide a prototype implementation of anapplication-level provenance capture library to produce, in a semi-automaticway, complete provenance documents that account for the entire pipeline. Wereport on the ability of our implementations to capture provenance in real MLbenchmark pipelines and over TCP-DI synthetic data. We finally show how thecollected provenance can be used to answer a suite of provenance benchmarkqueries that underpin some common pipeline inspection questions, as expressedon the Data Science Stack Exchange.","Adriane Chapman, Luca Lauro, Paolo Missier, Riccardo Torlone",2023-10-27T12:00:22Z,2023-10-27T12:00:22Z,"37 pages, 27 figures, submitted to a journal",cs.DB,http://arxiv.org/pdf/2310.18079v1,eng,,,Medicine
129,http://arxiv.org/abs/2408.02246v2,AMIDER: A Multidisciplinary Research Database and Its Application to  Promote Open Science,"The AMIDER, Advanced Multidisciplinary Integrated-Database for Exploring newResearch, is a newly developed research data catalog to demonstrate an advanceddatabase application. AMIDER is characterized as a multidisciplinary databaseequipped with a user-friendly web application. Its catalog view displaysdiverse research data at once beyond any limitation of each individualdiscipline. Some useful functions, such as a selectable data download, dataformat conversion, and display of data visual information, are alsoimplemented. Further advanced functions, such as visualization of datasetmutual relationship, are also implemented as a preliminary trial. Thesecharacteristics and functions are expected to enhance the accessibility toindividual research data, even from non-expertized users, and be helpful forcollaborations among diverse scientific fields beyond individual disciplines.Multidisciplinary data management is also one of AMIDER's uniqueness, wherevarious metadata schemas can be mapped to a uniform metadata table, andstandardized and self-describing data formats are adopted. AMIDER website(https://amider.rois.ac.jp/) had been launched in April 2024. As of July 2024,over 15,000 metadata in various research fields of polar science have beenregistered in the database, and approximately 500 visitors are viewing thewebsite every day on average. Expansion of the database to furthermultidisciplinary scientific fields, not only polar science, is planned, andadvanced attempts, such as applying Natural Language Processing (NLP) tometadata, have also been considered.","Masayoshi Kozai, Yoshimasa Tanaka, Shuji Abe, Yasuyuki Minamiyama, Atsuki Shinbori, Akira Kadokura",2024-08-05T05:38:48Z,2024-11-24T02:31:45Z,"12 pages, 4 figures, submitted to Data Science Journal",cs.DB,http://arxiv.org/pdf/2408.02246v2,eng,,,Medicine
130,http://arxiv.org/abs/1812.10175v1,The iEnvironment Platform: Developing an Open Science Software Platform  for Integrated Environmental Monitoring and Modeling of Surface Water,"This paper describes the development of iEnvironment, an open sciencesoftware platform that supports monitoring and modeling of aspects of surfacewater. The platform supports science and engineering research, especially inthe context of the creation, sharing, analysis and maintenance of big and opendata. In this era of big data, iEnvironment facilitates access to open dataresources and research collaboration among science and research disciplinessupported by computer scientists and software developers.","Paulo Alencar, Donald Cowan, Doug Mulholland",2018-12-25T23:38:36Z,2018-12-25T23:38:36Z,,cs.SE,http://arxiv.org/pdf/1812.10175v1,eng,,,Engineering
131,http://arxiv.org/abs/2111.07881v4,"Quantum Computation, Data Science, and Bell games","I draw attention to statistical, probabilistic, computer science aspects ofthe highly related topics of the Bell game and of a possible future QuantumInternet.",Richard D. Gill,2021-11-11T10:35:32Z,2022-05-27T08:55:26Z,"Invited discussion of paper to appear very soon in Harvard Data
  Science Review by Yazhen Wang. Revision 1 - some typos corrected",quant-ph,http://arxiv.org/pdf/2111.07881v4,eng,,,Physics and Astronomy
132,http://arxiv.org/abs/2401.05398v1,GeoAI in Social Science,"GeoAI, or geospatial artificial intelligence, is an exciting new area thatleverages artificial intelligence (AI), geospatial big data, and massivecomputing power to solve problems with high automation and intelligence. Thispaper reviews the progress of AI in social science research, highlightingimportant advancements in using GeoAI to fill critical data and knowledge gaps.It also discusses the importance of breaking down data silos, acceleratingconvergence among GeoAI research methods, as well as moving GeoAI beyondgeospatial benefits.",Wenwen Li,2023-12-19T20:23:18Z,2023-12-19T20:23:18Z,"Artificial Intelligence; social science; deep learning; convergence;
  knowledge graph",cs.CY,http://arxiv.org/pdf/2401.05398v1,eng,,,Medicine
133,http://arxiv.org/abs/astro-ph/0501089v1,Can Astronomy Manage Its Data?,"Astronomy has a distinguished tradition of using technology to accelerate thequality and effectiveness of science, and data-intensive initiatives such asthe Virtual Observatory lead the way amongst other fields of science. However,astronomical data are not uniformly well-managed, and our current freedom tocreate open-access databases is threatened by those who would like all data tobe subject to strict Intellectual Property controls. We, like other fields ofscience, need to establish and agree on a set of guiding principles for themanagement of astronomical data.",Ray P Norris,2005-01-06T03:43:00Z,2005-01-06T03:43:00Z,,astro-ph,http://arxiv.org/pdf/astro-ph/0501089v1,eng,,,Medicine
134,http://arxiv.org/abs/1907.09333v1,Continuously Updated Data Analysis Systems,"When doing data science, it's important to know what you're building. Thispaper describes an idealized final product of a data science project, called aContinuously Updated Data-Analysis System (CUDAS). The CUDAS conceptsynthesizes ideas from a range of successful data science projects, such asNate Silver's FiveThirtyEight. A CUDAS can be built for any context, such asthe state of the economy, the state of the climate, and so on. To demonstrate,we build two CUDAS systems. The first provides continuously-updated ratings forsoccer players, based on the newly developed Augmented Adjusted Plus-Minusstatistic. The second creates a large dataset of synthetic ecosystems, which isused for agent-based modeling of infectious diseases.",Lee F. Richardson,2019-07-19T12:26:14Z,2019-07-19T12:26:14Z,,stat.OT,http://arxiv.org/pdf/1907.09333v1,eng,,,Computer Science
135,http://arxiv.org/abs/2006.16900v1,From Simple Features to Moving Features and Beyond?,"Mobility data science lacks common data structures and analytical functions.This position paper assesses the current status and open issues towards auniversal API for mobility data science. In particular, we look atstandardization efforts revolving around the OGC Moving Features standardwhich, so far, has not attracted much attention within the mobility datascience community. We discuss the hurdles any universal API for movement datahas to overcome and propose key steps of a roadmap that would provide thefoundation for the development of this API.","Anita Graser, Esteban Zimányi, Krishna Chaitanya Bommakanti",2020-06-26T08:02:41Z,2020-06-26T08:02:41Z,"6 pages, 4 figures, originally prepared for GIScience2020 (which was
  postponed to 2021)",cs.CY,http://arxiv.org/pdf/2006.16900v1,eng,,,Medicine
136,http://arxiv.org/abs/2403.10470v1,MADAS -- A Python framework for assessing similarity in  materials-science data,"Computational materials science produces large quantities of data, both interms of high-throughput calculations and individual studies. Extractingknowledge from this large and heterogeneous pool of data is challenging due tothe wide variety of computational methods and approximations, resulting insignificant veracity in the sheer amount of available data. Here, we presentMADAS, a Python framework for computing similarity relations between materialproperties. It can be used to automate the download of data from varioussources, compute descriptors and similarities between materials, analyze therelationship between materials through their properties, and can incorporate avariety of existing machine learning methods. We explain the design of thepackage and demonstrate its power with representative examples.","Martin Kuban, Santiago Rigamonti, Claudia Draxl",2024-03-15T17:02:28Z,2024-03-15T17:02:28Z,,cond-mat.mtrl-sci,http://arxiv.org/pdf/2403.10470v1,eng,,,Computer Science
137,http://arxiv.org/abs/1904.11907v1,Evaluating the Success of a Data Analysis,"A fundamental problem in the practice and teaching of data science is how toevaluate the quality of a given data analysis, which is different than theevaluation of the science or question underlying the data analysis. Previously,we defined a set of principles for describing data analyses that can be used tocreate a data analysis and to characterize the variation between data analyses.Here, we introduce a metric of quality evaluation that we call the success of adata analysis, which is different than other potential metrics such ascompleteness, validity, or honesty. We define a successful data analysis as thematching of principles between the analyst and the audience on which theanalysis is developed. In this paper, we propose a statistical model andgeneral framework for evaluating the success of a data analysis. We argue thatthis framework can be used as a guide for practicing data scientists andstudents in data science courses for how to build a successful data analysis.","Stephanie C. Hicks, Roger D. Peng",2019-04-26T15:48:56Z,2019-04-26T15:48:56Z,16 pages,stat.OT,http://arxiv.org/pdf/1904.11907v1,eng,,,Computer Science
138,http://arxiv.org/abs/1911.05288v1,Big Data Challenges of FAST,"We present the big-data challenges posed by the science operation of theFive-hundred-meter Aperture Spherical radio Telescope (FAST). Unlike the commonusage of the word `big-data', which tend to emphasize both quantity anddiversity, the main characteristics of FAST data stream is its single-sourcedata rate at more than 6 GB/s and the resulting data volume at about 20 PB peryear. We describe here the main culprit of such a high data rate and largevolume, namely pulsar search, and our solution.","Youling Yue, Di Li",2019-11-13T04:37:20Z,2019-11-13T04:37:20Z,"4 pages, 1 figure",astro-ph.IM,http://arxiv.org/pdf/1911.05288v1,eng,,,Computer Science
139,http://arxiv.org/abs/1709.01989v1,Artificial Intelligence and Data Science in the Automotive Industry,"Data science and machine learning are the key technologies when it comes tothe processes and products with automatic learning and optimization to be usedin the automotive industry of the future. This article defines the terms ""datascience"" (also referred to as ""data analytics"") and ""machine learning"" and howthey are related. In addition, it defines the term ""optimizing analytics"" andillustrates the role of automatic optimization as a key technology incombination with data analytics. It also uses examples to explain the way thatthese technologies are currently being used in the automotive industry on thebasis of the major subprocesses in the automotive value chain (development,procurement; logistics, production, marketing, sales and after-sales, connectedcustomer). Since the industry is just starting to explore the broad range ofpotential uses for these technologies, visionary application examples are usedto illustrate the revolutionary possibilities that they offer. Finally, thearticle demonstrates how these technologies can make the automotive industrymore efficient and enhance its customer focus throughout all its operations andactivities, extending from the product and its development process to thecustomers and their connection to the product.","Martin Hofmann, Florian Neukart, Thomas Bäck",2017-09-06T20:38:00Z,2017-09-06T20:38:00Z,"22 pages, 4 figures",cs.AI,http://arxiv.org/pdf/1709.01989v1,eng,,,Social Sciences
140,http://arxiv.org/abs/2002.07069v1,The Big Three: A Methodology to Increase Data Science ROI by Answering  the Questions Companies Care About,"Companies may be achieving only a third of the value they could be gettingfrom data science in industry applications. In this paper, we propose amethodology for categorizing and answering 'The Big Three' questions (what isgoing on, what is causing it, and what actions can I take that will optimizewhat I care about) using data science. The applications of data science seem tobe nearly endless in today's modern landscape, with each company jockeying forposition in the new data and insights economy. Yet, data scientists seem to besolely focused on using classification, regression, and clustering methods toanswer the question 'what is going on'. Answering questions about why thingsare happening or how to take optimal actions to improve metrics are relegatedto niche fields of research and generally neglected in industry data scienceanalysis. We survey technical methods to answer these other importantquestions, describe areas in which some of these methods are being applied, andprovide a practical example of how to apply our methodology and selectedmethods to a real business use case.",Daniel K. Griffin,2020-02-12T21:25:56Z,2020-02-12T21:25:56Z,,cs.LG,http://arxiv.org/pdf/2002.07069v1,eng,,,Social Sciences
141,http://arxiv.org/abs/2301.03421v1,A review of clustering models in educational data science towards  fairness-aware learning,"Ensuring fairness is essential for every education system. Machine learningis increasingly supporting the education system and educational data science(EDS) domain, from decision support to educational activities and learninganalytics. However, the machine learning-based decisions can be biased becausethe algorithms may generate the results based on students' protected attributessuch as race or gender. Clustering is an important machine learning techniqueto explore student data in order to support the decision-maker, as well assupport educational activities, such as group assignments. Therefore, ensuringhigh-quality clustering models along with satisfying fairness constraints areimportant requirements. This chapter comprehensively surveys clustering modelsand their fairness in EDS. We especially focus on investigating the fairclustering models applied in educational activities. These models are believedto be practical tools for analyzing students' data and ensuring fairness inEDS.","Tai Le Quy, Gunnar Friege, Eirini Ntoutsi",2023-01-09T15:18:51Z,2023-01-09T15:18:51Z,"This is a preprint of the following chapter: Tai Le Quy, Gunnar
  Friege, Eirini Ntoutsi, A review of clustering models in educational data
  science towards fair-ness-aware learning, published in Educational Data
  Science: Essentials, Ap-proaches, and Tendencies, edited by Alejandro
  Pe\~na-Ayala , 2023, Springer. https://link.springer.com/book/9789819900251",cs.LG,http://arxiv.org/pdf/2301.03421v1,eng,,,Social Sciences
142,http://arxiv.org/abs/2401.04454v1,Character comes from practice: longitudinal practice-based ethics  training in data science,"In this chapter, we propose a non-traditional RCR training in data sciencethat is grounded into a virtue theory framework. First, we delineate theapproach in more theoretical detail, by discussing how the goal of RCR trainingis to foster the cultivation of certain moral abilities. We specify the natureof these abilities: while the ideal is the cultivation of virtues, the limitedspace allowed by RCR modules can only facilitate the cultivation of superficialabilities or proto-virtues, which help students to familiarize with moral andpolitical issues in the data science environment. Third, we operationalize ourapproach by stressing that (proto-)virtue acquisition (like skill acquisition)occurs through the technical and social tasks of daily data science activities,where these repetitive tasks provide the opportunities to develop(proto-)virtue capacity and to support the development of ethically robust datasystems. Finally, we discuss a concrete example of how this approach has beenimplemented. In particular, we describe how this method is applied to teachdata ethics to students participating in the CODATA-RDA Data Science SummerSchools.","Louise Bezuidenhout, Emanuele Ratti",2024-01-09T09:37:44Z,2024-01-09T09:37:44Z,,cs.CY,http://arxiv.org/pdf/2401.04454v1,eng,,,Social Sciences
143,http://arxiv.org/abs/1601.00323v1,The Design of a Community Science Cloud: The Open Science Data Cloud  Perspective,"In this paper we describe the design, and implementation of the Open ScienceData Cloud, or OSDC. The goal of the OSDC is to provide petabyte-scale datacloud infrastructure and related services for scientists working with largequantities of data. Currently, the OSDC consists of more than 2000 cores and 2PB of storage distributed across four data centers connected by 10G networks.We discuss some of the lessons learned during the past three years of operationand describe the software stacks used in the OSDC. We also describe some of theresearch projects in biology, the earth sciences, and social sciences enabledby the OSDC.","Robert L. Grossman, Matthew Greenway, Allison P. Heath, Ray Powell, Rafael D. Suarez, Walt Wells, Kevin White, Malcolm Atkinson, Iraklis Klampanos, Heidi L. Alvarez, Christine Harvey, Joe J. Mambretti",2016-01-03T19:06:43Z,2016-01-03T19:06:43Z,"12 pages, 3 figures",cs.CE,http://arxiv.org/pdf/1601.00323v1,eng,,,Social Sciences
144,http://arxiv.org/abs/1803.03598v1,Merging the Astrophysics and Planetary Science Information Systems,"Conceptually exoplanet research has one foot in the discipline ofAstrophysics and the other foot in Planetary Science. Research strategies forexoplanets will require efficient access to data and information from bothrealms. Astrophysics has a sophisticated, well integrated, distributedinformation system with archives and data centers which are interlinked withthe technical literature via the Astrophysics Data System (ADS). Theinformation system for Planetary Science does not have a central componentlinking the literature with the observational and theoretical data. Here wepropose that the Committee on an Exoplanet Science Strategy recommend that thislinkage be built, with the ADS playing the role in Planetary Science which italready plays in Astrophysics. This will require additional resources for theADS, and the Planetary Data System (PDS), as well as other internationalcollaborators","Michael J. Kurtz, Alberto Accomazzi, Edwin A. Henneken",2018-03-09T17:05:18Z,2018-03-09T17:05:18Z,"Whitepaper submitted to the Committee on an Exoplanet Science
  Strategy",astro-ph.IM,http://arxiv.org/pdf/1803.03598v1,eng,,,Social Sciences
145,http://arxiv.org/abs/2008.00315v1,A fresh look at introductory data science,"The proliferation of vast quantities of available datasets that are large andcomplex in nature has challenged universities to keep up with the demand forgraduates trained in both the statistical and the computational set of skillsrequired to effectively plan, acquire, manage, analyze, and communicate thefindings of such data. To keep up with this demand, attracting students earlyon to data science as well as providing them a solid foray into the fieldbecomes increasingly important. We present a case study of an introductoryundergraduate course in data science that is designed to address these needs.Offered at Duke University, this course has no pre-requisites and serves a wideaudience of aspiring statistics and data science majors as well as humanities,social sciences, and natural sciences students. We discuss the unique set ofchallenges posed by offering such a course and in light of these challenges, wepresent a detailed discussion into the pedagogical design elements, content,structure, computational infrastructure, and the assessment methodology of thecourse. We also offer a repository containing all teaching materials that areopen-source, along with supplemental materials and the R code for reproducingthe figures found in the paper.","Mine Çetinkaya-Rundel, Victoria Ellison",2020-08-01T18:39:34Z,2020-08-01T18:39:34Z,,stat.OT,http://arxiv.org/pdf/2008.00315v1,eng,,,Social Sciences
146,http://arxiv.org/abs/2102.01892v1,A few statistical principles for data science,"In any other circumstance, it might make sense to define the extent of theterrain (Data Science) first, and then locate and describe the landmarks(Principles). But this data revolution we are experiencing defies a cadastralsurvey. Areas are continually being annexed into Data Science. For example,biometrics was traditionally statistics for agriculture in all its forms butnow, in Data Science, it means the study of characteristics that can be used toidentify an individual. Examples of non-intrusive measurements include height,weight, fingerprints, retina scan, voice, photograph/video (facial landmarksand facial expressions), and gait. A multivariate analysis of such data wouldbe a complex project for a statistician, but a software engineer might appearto have no trouble with it at all. In any applied-statistics project, thestatistician worries about uncertainty and quantifies it by modelling data asrealisations generated from a probability space. Another approach touncertainty quantification is to find similar data sets, and then use thevariability of results between these data sets to capture the uncertainty. Bothapproaches allow 'error bars' to be put on estimates obtained from the originaldata set, although the interpretations are different. A third approach, thatconcentrates on giving a single answer and gives up on uncertaintyquantification, could be considered as Data Engineering, although it has stakeda claim in the Data Science terrain. This article presents a few (actuallynine) statistical principles for data scientists that have helped me, andcontinue to help me, when I work on complex interdisciplinary projects.",Noel Cressie,2021-02-03T06:28:03Z,2021-02-03T06:28:03Z,"19 pages; written for a special issue (festschrift) of the Australian
  and New Zealand Journal of Statistics",stat.OT,http://arxiv.org/pdf/2102.01892v1,eng,,,Computer Science
147,http://arxiv.org/abs/1008.1188v1,Data visualization in political and social sciences,"The basic objective of data visualization is to provide an efficientgraphical display for summarizing and reasoning about quantitative information.During the last decades, political science has accumulated a large corpus ofvarious kinds of data such as comprehensive factbooks and atlases,characterizing all or most of existing states by multiple and objectivelyassessed numerical indicators within certain time lapse. As a consequence,there exists a continuous trend for political science to gradually become amore quantitative scientific field and to use quantitative information in theanalysis and reasoning. It is believed that any objective analysis in politicalscience must be multidimensional and combine various sources of quantitativeinformation; however, human capabilities for perception of large massifs ofnumerical information are limited. Hence, methods and approaches forvisualization of quantitative and qualitative data (and, especiallymultivariate data) is an extremely important topic. Data visualizationapproaches can be classified into several groups, starting from creatinginformative charts and diagrams (statistical graphics and infographics) andending with advanced statistical methods for visualizing multidimensionaltables containing both quantitative and qualitative information. In thisarticle we provide a short review of existing methods of data visualizationmethods with applications in political and social science.",Andrei Zinovyev,2010-08-06T13:29:11Z,2010-08-06T13:29:11Z,"To appear as a ""Data Visualization"" entry in SAGE ""International
  Encyclopedia of Political Science"" by Badie, B., Berg-Schlosser, D., Morlino,
  L. A. (Eds.) in 2011",cs.GR,http://arxiv.org/pdf/1008.1188v1,eng,,,Social Sciences
148,http://arxiv.org/abs/2403.08971v1,Designing a Data Science simulation with MERITS: A Primer,"Simulations play a crucial role in the modern scientific process. Yet despite(or due to) their ubiquity, the Data Science community shares neither acomprehensive definition for a ""high-quality"" study nor a consolidated guide todesigning one. Inspired by the Predictability-Computability-Stability (PCS)framework for 'veridical' Data Science, we propose six MERITS that a DataScience simulation should satisfy. Modularity and Efficiency support theComputability of a study, encouraging clean and flexible implementation.Realism and Stability address the conceptualization of the research problem:How well does a study Predict reality, such that its conclusions generalize tonew data/contexts? Finally, Intuitiveness and Transparency encourage goodcommunication and trustworthiness of study design and results. Drawing ananalogy between simulation and cooking, we moreover offer (a) a conceptualframework for thinking about the anatomy of a simulation 'recipe'; (b) abaker's dozen in guidelines to aid the Data Science practitioner in designingone; and (c) a case study deconstructing a simulation through the lens of ourframework to demonstrate its practical utility. By contributing this ""PCSprimer"" for high-quality Data Science simulation, we seek to distill and enrichthe best practices of simulation across disciplines into a cohesive recipe fortrustworthy, veridical Data Science.","Corrine F Elliott, James Duncan, Tiffany M Tang, Merle Behr, Karl Kumbier, Bin Yu",2024-03-13T21:32:14Z,2024-03-13T21:32:14Z,"26 pages (main text); 1 figure; 2 tables; *Authors contributed
  equally to this manuscript; **Authors contributed equally to this manuscript",stat.CO,http://arxiv.org/pdf/2403.08971v1,eng,,,Physics and Astronomy
149,http://arxiv.org/abs/2402.03313v1,The Globalization of Science: The Increasing Power of Individual  Scientists,"National science systems have become embedded in global science and countriesdo everything they can to harness global knowledge to national economic needs.However, accessing and using the riches of global knowledge can occur onlythrough scientists. Consequently, the research power of nations relies on theresearch power of individual scientists. Their capacity to collaborateinternationally and to tap into the global networked science is key. Theconstantly evolving, bottom-up, autonomous, self-regulating, and self-focusednature of global science requires deeper understanding; and the best way tounderstand its dynamics is to understand what drives academic scientists intheir work. The idea that science remains a state-driven rather thancuriosity-driven is difficult to sustain. In empirical terms, we describe theglobalization of science using selected publication, collaboration, andcitation data from 2000-2020. The globalization of science implies twodifferent processes in two different system types: the growth of science in theWestern world is almost entirely attributable to internationally co-authoredpublications; its growth in the developing world, in contrast, is driven byboth internationally co-authored and domestic publications. Global networkscience opens incredible opportunities to new arrivals - countries as well asinstitutions and research teams. The global system is embedded in the rulescreated by scientists themselves and maintained as a self-organizing system andnation-states have another major level to consider in their science policies:the global level. Globalization of science provides more agency, autonomy,collegiality, and self-regulation to scientists embedded in national sciencestructures and involved in global networks.",Marek Kwiek,2023-12-09T12:12:51Z,2023-12-09T12:12:51Z,34 pages,physics.soc-ph,http://arxiv.org/pdf/2402.03313v1,eng,,,Social Sciences
150,http://arxiv.org/abs/2310.08511v1,HoneyBee: Progressive Instruction Finetuning of Large Language Models  for Materials Science,"We propose an instruction-based process for trustworthy data curation inmaterials science (MatSci-Instruct), which we then apply to finetune aLLaMa-based language model targeted for materials science (HoneyBee).MatSci-Instruct helps alleviate the scarcity of relevant, high-qualitymaterials science textual data available in the open literature, and HoneyBeeis the first billion-parameter language model specialized to materials science.In MatSci-Instruct we improve the trustworthiness of generated data byprompting multiple commercially available large language models for generationwith an Instructor module (e.g. Chat-GPT) and verification from an independentVerifier module (e.g. Claude). Using MatSci-Instruct, we construct a dataset ofmultiple tasks and measure the quality of our dataset along multipledimensions, including accuracy against known facts, relevance to materialsscience, as well as completeness and reasonableness of the data. Moreover, weiteratively generate more targeted instructions and instruction-data in afinetuning-evaluation-feedback loop leading to progressively better performancefor our finetuned HoneyBee models. Our evaluation on the MatSci-NLP benchmarkshows HoneyBee's outperformance of existing language models on materialsscience tasks and iterative improvement in successive stages ofinstruction-data refinement. We study the quality of HoneyBee's languagemodeling through automatic evaluation and analyze case studies to furtherunderstand the model's capabilities and limitations. Our code and relevantdatasets are publicly available at\url{https://github.com/BangLab-UdeM-Mila/NLP4MatSci-HoneyBee}.","Yu Song, Santiago Miret, Huan Zhang, Bang Liu",2023-10-12T17:06:19Z,2023-10-12T17:06:19Z,,cs.CL,http://arxiv.org/pdf/2310.08511v1,eng,,,Social Sciences
151,http://arxiv.org/abs/1501.01149v1,Experimental Research Data Quality In Materials Science,"In materials sciences, a large amount of research data is generated through abroad spectrum of different experiments. As of today, experimental researchdata including meta-data in materials science is often stored decentralized bythe researcher(s) conducting the experiments without generally acceptedstandards on what and how to store data. The conducted research and experimentsoften involve a considerable investment from public funding agencies thatdesire the results to be made available in order to increase their impact. Inorder to achieve the goal of citable and (openly) accessible materials scienceexperimental research data in the future, not only an adequate infrastructureneeds to be established but the question of how to measure the quality of theexperimental research data also to be addressed. In this publication, theauthors identify requirements and challenges towards a systematic methodologyto measure experimental research data quality prior to publication and derivedifferent approaches on that basis. These methods are critically discussed andassessed by their contribution and limitations towards the set goals.Concluding, a combination of selected methods is presented as a systematic,functional and practical quality measurement and assurance approach forexperimental research data in materials science with the goal of supporting theaccessibility and dissemination of existing data sets.","Thorsten Wuest, Rainer Tinscher, Robert Porzel, Klaus-Dieter Thoben",2015-01-06T11:29:22Z,2015-01-06T11:29:22Z,,cs.DB,http://arxiv.org/pdf/1501.01149v1,eng,,,Social Sciences
152,http://arxiv.org/abs/1703.06450v1,"Building a Disciplinary, World-Wide Data Infrastructure","Sharing scientific data, with the objective of making it fully discoverable,accessible, assessable, intelligible, usable, and interoperable, requires workat the disciplinary level to define in particular how the data should beformatted and described. Each discipline has its own organization and historyas a starting point, and this paper explores the way a range of disciplines,namely materials science, crystallography, astronomy, earth sciences,humanities and linguistics get organized at the international level to tacklethis question. In each case, the disciplinary culture with respect to datasharing, science drivers, organization and lessons learnt are brieflydescribed, as well as the elements of the specific data infrastructure whichare or could be shared with others. Commonalities and differences are assessed.Common key elements for success are identified: data sharing should be sciencedriven; defining the disciplinary part of the interdisciplinary standards ismandatory but challenging; sharing of applications should accompany datasharing. Incentives such as journal and funding agency requirements are alsosimilar. For all, it also appears that social aspects are more challenging thantechnological ones. Governance is more diverse, and linked to the disciplineorganization. CODATA, the RDA and the WDS can facilitate the establishment ofdisciplinary interoperability frameworks. Being problem-driven is also a keyfactor of success for building bridges to enable interdisciplinary research.","Françoise Genova, Christophe Arviset, Bridget M. Almas, Laura Bartolo, Daan Broeder, Emily Law, Brian McMahon",2017-03-19T14:51:17Z,2017-03-19T14:51:17Z,"Proceedings of the session ""Building a disciplinary, world-wide data
  infrastructure"" of SciDataCon 2016, held in Denver, CO, USA, 12-14 September
  2016, to be published in ICSU CODATA Data Science Journal in 2017",astro-ph.IM,http://arxiv.org/pdf/1703.06450v1,eng,,,Medicine
153,http://arxiv.org/abs/1905.06875v1,A Clinical Approach to Training Effective Data Scientists,"Like medicine, psychology, or education, data science is fundamentally anapplied discipline, with most students who receive advanced degrees in thefield going on to work on practical problems. Unlike these disciplines,however, data science education remains heavily focused on theory and methods,and practical coursework typically revolves around cleaned or simplified datasets that have little analog in professional applications. We believe that theenvironment in which new data scientists are trained should more accuratelyreflect that in which they will eventually practice and propose here a datascience master's degree program that takes inspiration from the residency modelused in medicine. Students in the suggested program would spend three yearsworking on a practical problem with an industry, government, or nonprofitpartner, supplemented with coursework in data science methods and theory. Wealso discuss how this program can also be implemented in shorter formats toaugment existing professional masters programs in different disciplines. Thisapproach to learning by doing is designed to fill gaps in our current approachto data science education and ensure that students develop the skills they needto practice data science in a professional context and under the manyconstraints imposed by that context.","Kit T Rodolfa, Adolfo De Unanue, Matt Gee, Rayid Ghani",2019-05-15T02:36:28Z,2019-05-15T02:36:28Z,"18 pages, 3 figures, 2 tables",cs.CY,http://arxiv.org/pdf/1905.06875v1,eng,,,Social Sciences
154,http://arxiv.org/abs/2108.02558v1,JITA4DS: Disaggregated execution of Data Science Pipelines between the  Edge and the Data Centre,"This paper targets the execution of data science (DS) pipelines supported bydata processing, transmission and sharing across several resources executinggreedy processes. Current data science pipelines environments provide variousinfrastructure services with computing resources such as general-purposeprocessors (GPP), Graphics Processing Units (GPUs), Field Programmable GateArrays (FPGAs) and Tensor Processing Unit (TPU) coupled with platform andsoftware services to design, run and maintain DS pipelines. These one-fits-allsolutions impose the complete externalization of data pipeline tasks. However,some tasks can be executed in the edge, and the backend can provide just intime resources to ensure ad-hoc and elastic execution environments.  This paper introduces an innovative composable ""Just in Time Architecture""for configuring DCs for Data Science Pipelines (JITA-4DS) and associatedresource management techniques. JITA-4DS is a cross-layer management systemthat is aware of both the application characteristics and the underlyinginfrastructures to break the barriers between applications,middleware/operating system, and hardware layers. Vertical integration of theselayers is needed for building a customizable Virtual Data Center (VDC) to meetthe dynamically changing data science pipelines' requirements such asperformance, availability, and energy consumption. Accordingly, the paper showsan experimental simulation devoted to run data science workloads and determinethe best strategies for scheduling the allocation of resources implemented byJITA-4DS.","Genoveva Vargas-Solar, Ali Akoglu, Md Sahil Hassan",2021-08-05T12:24:43Z,2021-08-05T12:24:43Z,"This paper has been submitted to a Journal JWE special number. arXiv
  admin note: substantial text overlap with arXiv:2103.07978",cs.DC,http://arxiv.org/pdf/2108.02558v1,eng,,,Computer Science
155,http://arxiv.org/abs/2307.10803v2,"Spatial-Temporal Data Mining for Ocean Science: Data, Methodologies, and  Opportunities","With the rapid amassing of spatial-temporal (ST) ocean data, manyspatial-temporal data mining (STDM) studies have been conducted to addressvarious oceanic issues, including climate forecasting and disaster warning.Compared with typical ST data (e.g., traffic data), ST ocean data is morecomplicated but with unique characteristics, e.g., diverse regionality and highsparsity. These characteristics make it difficult to design and train STDMmodels on ST ocean data. To the best of our knowledge, a comprehensive surveyof existing studies remains missing in the literature, which hinders not onlycomputer scientists from identifying the research issues in ocean data miningbut also ocean scientists to apply advanced STDM techniques. In this paper, weprovide a comprehensive survey of existing STDM studies for ocean science.Concretely, we first review the widely-used ST ocean datasets and highlighttheir unique characteristics. Then, typical ST ocean data quality enhancementtechniques are explored. Next, we classify existing STDM studies in oceanscience into four types of tasks, i.e., prediction, event detection, patternmining, and anomaly detection, and elaborate on the techniques for these tasks.Finally, promising research opportunities are discussed. This survey can helpscientists from both computer science and ocean science better understand thefundamental concepts, key techniques, and open challenges of STDM for oceanscience.","Hanchen Yang, Wengen Li, Shuyu Wang, Hui Li, Jihong Guan, Shuigeng Zhou, Jiannong Cao",2023-07-20T12:12:05Z,2023-08-03T05:41:37Z,,cs.LG,http://arxiv.org/pdf/2307.10803v2,eng,,,Computer Science
156,http://arxiv.org/abs/1501.06285v2,Analyzing data citation practices using the Data Citation Index,"We present an analysis of data citation practices based on the Data CitationIndex from Thomson Reuters. This database launched in 2012 aims to link datasets and data studies with citations received from the other citation indexes.The DCI harvests citations to research data from papers indexed in the Web ofScience. It relies on the information provided by the data repository as datacitation practices are inconsistent or inexistent in many cases. The findingsof this study show that data citation practices are far from common in mostresearch fields. Some differences have been reported on the way researcherscite data: while in the areas of Science and Engineering and Technology datasets were the most cited, in Social Sciences and Arts and Humanities datastudies play a greater role. A total of 88.1 percent of the records havereceived no citation, but some repositories show very low uncitedness rates.Although data citation practices are rare in most fields, they have expanded indisciplines such as crystallography and genomics. We conclude by emphasizingthe role that the DCI could play in encouraging the consistent, standardizedcitation of research data; a role that would enhance their value as a means offollowing the research process from data collection to publication.","Nicolas Robinson-Garcia, Evaristo Jiménez-Contreras, Daniel Torres-Salinas",2015-01-26T08:36:18Z,2015-05-19T10:57:46Z,"Paper accepted for publication in the Journal of the Association for
  Information Science and Technology. v2 revises style on text, title and
  abstract",cs.DL,http://arxiv.org/pdf/1501.06285v2,eng,,,Medicine
157,http://arxiv.org/abs/2112.01830v1,Table2Vec: Automated Universal Representation Learning to Encode  All-round Data DNA for Benchmarkable and Explainable Enterprise Data Science,"Enterprise data typically involves multiple heterogeneous data sources andexternal data that respectively record business activities, transactions,customer demographics, status, behaviors, interactions and communications withthe enterprise, and the consumption and feedback of its products, services,production, marketing, operations, and management, etc. A critical challenge inenterprise data science is to enable an effective whole-of-enterprise dataunderstanding and data-driven discovery and decision-making on all-roundenterprise DNA. We introduce a neural encoder Table2Vec for automated universalrepresentation learning of entities such as customers from all-round enterpriseDNA with automated data characteristics analysis and data quality augmentation.The learned universal representations serve as representative and benchmarkableenterprise data genomes and can be used for enterprise-wide and domain-specificlearning tasks. Table2Vec integrates automated universal representationlearning on low-quality enterprise data and downstream learning tasks. Weillustrate Table2Vec in characterizing all-round customer data DNA in anenterprise on complex heterogeneous multi-relational big tables to builduniversal customer vector representations. The learned universal representationof each customer is all-round, representative and benchmarkable to support bothenterprise-wide and domain-specific learning goals and tasks in enterprise datascience. Table2Vec significantly outperforms the existing shallow, boosting anddeep learning methods typically used for enterprise analytics. We furtherdiscuss the research opportunities, directions and applications of automateduniversal enterprise representation and learning and the learned enterprisedata DNA for automated, all-purpose, whole-of-enterprise and ethical machinelearning and data science.","Longbing Cao, Chengzhang Zhu",2021-12-03T10:39:25Z,2021-12-03T10:39:25Z,"24 pages, 16 figures, 1 table",cs.LG,http://arxiv.org/pdf/2112.01830v1,eng,,,Social Sciences
158,http://arxiv.org/abs/1401.3269v1,Teaching precursors to data science in introductory and second courses  in statistics,"Statistics students need to develop the capacity to make sense of thestaggering amount of information collected in our increasingly data-centeredworld. Data science is an important part of modern statistics, but ourintroductory and second statistics courses often neglect this fact. This paperdiscusses ways to provide a practical foundation for students to learn to""compute with data"" as defined by Nolan and Temple Lang (2010), as well asdevelop ""data habits of mind"" (Finzer, 2013). We describe how introductory andsecond courses can integrate two key precursors to data science: the use ofreproducible analysis tools and access to large databases. By introducingstudents to commonplace tools for data management, visualization, andreproducible analysis in data science and applying these to real-worldscenarios, we prepare them to think statistically in the era of big data.","Nicholas J Horton, Benjamin S Baumer, Hadley Wickham",2014-01-14T17:43:11Z,2014-01-14T17:43:11Z,,stat.CO,http://arxiv.org/pdf/1401.3269v1,eng,,,Social Sciences
159,http://arxiv.org/abs/2405.18232v2,Guidelines and Best Practices to Share Deidentified Data and Code,"In 2022, the Journal of Statistics and Data Science Education (JSDSE)instituted augmented requirements for authors to post deidentified data andcode underlying their papers. These changes were prompted by an increased focuson reproducibility and open science (NASEM 2019). A recent review of dataavailability practices noted that ""such policies help increase thereproducibility of the published literature, as well as make a larger body ofdata available for reuse and re-analysis"" (PLOS ONE, 2024). JSDSE valuesaccessibility as it endeavors to share knowledge that can improve educationalapproaches to teaching statistics and data science. Because institution,environment, and students differ across readers of the journal, it isespecially important to facilitate the transfer of a journal article's findingsto new contexts. This process may require digging into more of the details,including the deidentified data and code. Our goal is to provide our readersand authors with a review of why the requirements for code and data sharingwere instituted, summarize ongoing trends and developments in open science,discuss options for data and code sharing, and share advice for authors.","Nicholas J. Horton, Sara Stoudt",2024-05-28T14:40:51Z,2024-07-08T11:45:33Z,,stat.OT,http://arxiv.org/pdf/2405.18232v2,eng,,,Medicine
160,http://arxiv.org/abs/1905.08289v1,Citizen Science: An Information Quality Research Frontier,"The rapid proliferation of online content producing and sharing technologiesresulted in an explosion of user-generated content (UGC), which now extends toscientific data. Citizen science, in which ordinary people contributeinformation for scientific research, epitomizes UGC. Citizen science projectsare typically open to everyone, engage diverse audiences, and challengeordinary people to produce data of highest quality to be usable in science.This also makes citizen science a very exciting area to study both traditionaland innovative approaches to information quality management. With this paper weposition citizen science as a leading information quality research frontier. Wealso show how citizen science opens a unique opportunity for the informationsystems community to contribute to a broad range of disciplines in natural andsocial sciences and humanities.","Roman Lukyanenko, Andrea Wiggins, Holly K. Rosser",2019-05-20T18:39:57Z,2019-05-20T18:39:57Z,,cs.CY,http://arxiv.org/pdf/1905.08289v1,eng,,,Social Sciences
161,http://arxiv.org/abs/1602.08666v1,Epistemic Impact on Group Problem Solving for Different Science Majors,"Implementation of cognitive apprenticeship in an introductory physics labgroup problem solving exercise may be mitigated by epistemic views towardphysics of non-physics science majors. Quantitative pre-post data of the ForceConcept Inventory (FCI) and Colorado Learning Attitudes About Science Survey(CLASS) of 39 students of a first-semester algebra-based introductory physicscourse, while describing typical results for a traditional-format courseoverall (g = +0.14), suggest differences in epistemic views between healthscience majors and life science majors which may correlate with differences inpre-post conceptual understanding. Audiovisual data of student lab groupsworking on a context-rich problem and students' written reflections describedeach group's typical dynamics and invoked epistemic games. We examined theeffects of framework-based orientation (favored by biology majors) andperformance-based orientation (favored by computer science, chemistry, andhealth science majors) on pre-post attitude survey performance. We alsoinvestigated possible correlations of these orientations with individualquantitative survey results, and with qualitative audiovisual data of labgroups' choice of epistemic games.","Andrew J. Mason, Charles A. Bertram",2016-02-28T04:27:44Z,2016-02-28T04:27:44Z,"7 pages, 3 tables, 1 figure",physics.ed-ph,http://arxiv.org/pdf/1602.08666v1,eng,,,Social Sciences
162,http://arxiv.org/abs/2203.10718v1,Prediction Algorithm for Heat Demand of Science and Technology Topics  Based on Time Convolution Network,"Thanks to the rapid development of deep learning, big data analysistechnology is not only widely used in the field of natural language processing,but also more mature in the field of numerical prediction. It is of greatsignificance for the subject heat prediction and analysis of science andtechnology demand data. How to apply theme features to accurately predict thetheme heat of science and technology demand is the core to solve this problem.In this paper, a prediction method of subject heat of science and technologydemand based on time convolution network (TCN) is proposed to obtain thesubject feature representation of science and technology demand. Time seriesprediction is carried out based on TCN network and self attention mechanism,which increases the accuracy of subject heat prediction of science andtechnology demand data Experiments show that the prediction accuracy of thisalgorithm is better than other time series prediction methods on the realscience and technology demand datasets.","Cui Haiyan, Li Yawen, Xu Xin",2022-03-21T03:30:05Z,2022-03-21T03:30:05Z,,cs.IR,http://arxiv.org/pdf/2203.10718v1,eng,,,Computer Science
163,http://arxiv.org/abs/2304.06782v1,Using multilevel modeling to evaluate science literacy and technology  course of the Indonesian non-science students,Science literacy is being fostered by science education community includingthe Indonesian education system. Science literacy and technology course hasbeen designed and implemented to strengthen the national initiative empoweringscientifically literate Indonesian society. This paper is intended to evaluateto what degree this course can be performed by non-science undergraduatestudents (N = 160) considering the nested structure of students' department andfaculty setting. Multilevel modeling thus was employed to conduct the analysisdealing with this nature. The first level analysis involved students'performance and affective attribute measured using demonstrated scienceliteracy assessment (SLA-D) and motivational beliefs (SLA-MB) respectively. Thesubsequent level analysis comprised demographic factors gathered frominstitutional record. Findings demonstrated that the impact of demographicfactor to the students' performance on science literacy was not substantial.Different setting of students' department and faculty level drove theassociation between affective factor and learning process toward scienceliteracy course substantially. Multilevel approach has controlled the equitablestudent assessment within the nature of students' data structure. This papersuggests many implications to open ideas regarding educational data analysisand to examine the effectiveness of science literacy course for the higherinstitution specifically for non-science majors.,"Bayu Setiaji, Purwoko Haryadi Santoso, Khafidh Nur Aziz, Heri Retnawati, Moh Khairudin",2023-04-13T19:06:24Z,2023-04-13T19:06:24Z,"36 pages, 3 figures, 4 tables, submitted to Jurnal Pendidikan IPA
  Indonesia",physics.ed-ph,http://arxiv.org/pdf/2304.06782v1,eng,,,Social Sciences
164,http://arxiv.org/abs/2409.10537v1,Practical Challenges of Progressive Data Science in Healthcare,"The healthcare system collects extensive data, encompassing patientadministrative information, clinical measurements, and home-monitored healthmetrics. To support informed decision-making in patient care and treatmentmanagement, it is essential to review and analyze these diverse data sources.Data visualization is a promising solution to navigate healthcare datasets,uncover hidden patterns, and derive actionable insights. However, the processof creating interactive data visualization can be rather challenging due to thesize and complexity of these datasets. Progressive data science offers apotential solution, enabling interaction with intermediate results during dataexploration. In this paper, we reflect on our experiences with three healthdata visualization projects employing a progressive data science approach.  We explore the practical implications and challenges faced at various stages,including data selection, pre-processing, data mining, transformation, andinterpretation and evaluation. We highlighted unique challenges andopportunities for three projects, including visualizing surgical outcomes,tracking patient bed transfers, and integrating patient-generated datavisualizations into the healthcare setting.  We identified the following challenges: inconsistent data collectionpractices, the complexity of adapting to varying data completeness levels, andthe need to modify designs for real-world deployment. Our findings underscorethe need for careful consideration of using a progressive data science approachwhen designing visualizations for healthcare settings.","Faisal Zaki Roshan, Abhishek Ahuja, Fateme Rajabiyazdi",2024-08-31T15:00:23Z,2024-08-31T15:00:23Z,4 pages,cs.HC,http://arxiv.org/pdf/2409.10537v1,eng,,,Medicine
165,http://arxiv.org/abs/1612.08544v2,Theory-guided Data Science: A New Paradigm for Scientific Discovery from  Data,"Data science models, although successful in a number of commercial domains,have had limited applicability in scientific problems involving complexphysical phenomena. Theory-guided data science (TGDS) is an emerging paradigmthat aims to leverage the wealth of scientific knowledge for improving theeffectiveness of data science models in enabling scientific discovery. Theoverarching vision of TGDS is to introduce scientific consistency as anessential component for learning generalizable models. Further, by producingscientifically interpretable models, TGDS aims to advance our scientificunderstanding by discovering novel domain insights. Indeed, the paradigm ofTGDS has started to gain prominence in a number of scientific disciplines suchas turbulence modeling, material discovery, quantum chemistry, bio-medicalscience, bio-marker discovery, climate science, and hydrology. In this paper,we formally conceptualize the paradigm of TGDS and present a taxonomy ofresearch themes in TGDS. We describe several approaches for integrating domainknowledge in different research themes using illustrative examples fromdifferent disciplines. We also highlight some of the promising avenues of novelresearch for realizing the full potential of theory-guided data science.","Anuj Karpatne, Gowtham Atluri, James Faghmous, Michael Steinbach, Arindam Banerjee, Auroop Ganguly, Shashi Shekhar, Nagiza Samatova, Vipin Kumar",2016-12-27T09:14:16Z,2017-11-13T17:42:12Z,,cs.LG,http://arxiv.org/pdf/1612.08544v2,eng,,,Medicine
166,http://arxiv.org/abs/1901.02547v1,Problem Formulation and Fairness,"Formulating data science problems is an uncertain and difficult process. Itrequires various forms of discretionary work to translate high-level objectivesor strategic goals into tractable problems, necessitating, among other things,the identification of appropriate target variables and proxies. While thesechoices are rarely self-evident, normative assessments of data science projectsoften take them for granted, even though different translations can raiseprofoundly different ethical concerns. Whether we consider a data scienceproject fair often has as much to do with the formulation of the problem as anyproperty of the resulting model. Building on six months of ethnographicfieldwork with a corporate data science team---and channeling ideas fromsociology and history of science, critical data studies, and early writing onknowledge discovery in databases---we describe the complex set of actors andactivities involved in problem formulation. Our research demonstrates that thespecification and operationalization of the problem are always negotiated andelastic, and rarely worked out with explicit normative considerations in mind.In so doing, we show that careful accounts of everyday data science work canhelp us better understand how and why data science problems are posed incertain ways---and why specific formulations prevail in practice, even in theface of what might seem like normatively preferable alternatives. We concludeby discussing the implications of our findings, arguing that effectivenormative interventions will require attending to the practical work of problemformulation.","Samir Passi, Solon Barocas",2019-01-08T22:56:45Z,2019-01-08T22:56:45Z,"Conference on Fairness, Accountability, and Transparency (FAT* '19),
  January 29-31, 2019, Atlanta, GA, USA",cs.CY,http://arxiv.org/pdf/1901.02547v1,eng,,,Social Sciences
167,http://arxiv.org/abs/1904.00237v2,A decentralized method for making sensor measurements tamper-proof to  support open science applications,"Open science has become a synonym for modern, digital and inclusive science.Inclusion does not stop at open access. Inclusion also requires transparencythrough open datasets and the right and ability to take part in the knowledgecreation process. This implies new challenges for digital libraries. Citizensshould be able to contribute data in a curatable form to advance science. Atthe same time, this data should be verifiable and attributable to its owner.Our research project focusses on securing and attributing incoming data streamsfrom sensors. Our contribution is twofold. First, we analyze the promises ofopen science measurement data and point out how Blockchain technology changedthe circumstances for data measurement in science projects using sensors.Second, we present an open hardware project capable of securing the integrityof data directly from the source using cryptographic methods. By usinginexpensive modular components and open source software, we lower the barrierfor participation in open science projects. We show how time series ofmeasurement values using sensors, e.g., temperature, current, and vibrationmeasurements, can be verifiably and immutably stored. The approach we proposeenables time series data to be stored in a tamper-proof manner and securelytimestamped on a blockchain to prevent any subsequent modification.","Patrick Wortner, Moritz Schubotz, Corinna Breitinger, Stephan Leible, Bela Gipp",2019-03-30T15:49:58Z,2019-04-02T09:32:16Z,,cs.CY,http://arxiv.org/pdf/1904.00237v2,eng,,,Social Sciences
168,http://arxiv.org/abs/2302.11453v1,Requirements analysis for HPC\&HTC infrastructures integration in ESCAPE  Science Analysis Platform,"ESCAPE (European Science Cluster of Astronomy and Particle physics ESFRIresearch infrastructures) is a project to set up a cluster of ESFRI (EuropeanStrategy Forum on Research Infrastructures) facilities for astronomy,astroparticle and particle physics to face the challenges emerging through themodern multi-disciplinary data driven science. One of the main goal of ESCAPEis the building of ESAP (ESFRI Science Analysis Platform), a science platformfor the analysis of open access data available through the EOSC (European OpenScience Cloud) environment. ESAP will allow EOSC researchers to identify andstage existing data collections for analysis, share data, share and runscientific workflows. For many of the concerned ESFRIs and RIs, the data scalesinvolved require significant computational resources (storage and compute) tosupport processing and analysis. The EOSC-ESFRI science platform therefore mustimplement appropriate interfaces to an underlying HPC (High PerformanceComputing) or HTC (High Throughput Computing) infrastructure to take advantageof it. This poster describes the analysis done to identify the mainrequirements for the implementation of the interfaces enabling the ESAP dataaccess and computation resources integration in HPC and HTC computationinfrastructures in terms of authentication and authorization policies, datamanagement, workflow deployment and run.","S. Bertocco, D. Goz, S. A. Russo, M. Moliaro, G. Taffoni",2023-02-22T15:40:14Z,2023-02-22T15:40:14Z,Will appear in Proceedings ADASSXXX ASP Conference Series,astro-ph.IM,http://arxiv.org/pdf/2302.11453v1,eng,,,Social Sciences
169,http://arxiv.org/abs/2008.03256v1,Opening practice: supporting Reproducibility and Critical spatial data  science,"This paper reflects on a number of trends towards a more open andreproducible approach to geographic and spatial data science over recent years.In particular it considers trends towards Big Data, and the impacts this ishaving on spatial data analysis and modelling. It identifies a turn in academiatowards coding as a core analytic tool, and away from proprietary softwaretools offering 'black boxes' where the internal workings of the analysis arenot revealed. It is argued that this closed form software is problematic, andconsiders a number of ways in which issues identified in spatial data analysis(such as the MAUP) could be overlooked when working with closed tools, leadingto problems of interpretation and possibly inappropriate actions and policiesbased on these. In addition, this paper and considers the role thatreproducible and open spatial science may play in such an approach, taking intoaccount the issues raised. It highlights the dangers of failing to account forthe geographical properties of data, now that all data are spatial (they arecollected somewhere), the problems of a desire for n=all observations in datascience and it identifies the need for a critical approach. This is one inwhich openness, transparency, sharing and reproducibility provide a mantra fordefensible and robust spatial data science.","Chris Brunsdon, Alexis Comber",2020-07-20T07:50:08Z,2020-07-20T07:50:08Z,"19 pages, 1 figure",stat.OT,http://arxiv.org/pdf/2008.03256v1,eng,,,Social Sciences
170,http://arxiv.org/abs/2009.09795v2,Biases in Data Science Lifecycle,"In recent years, data science has become an indispensable part of oursociety. Over time, we have become reliant on this technology because of itsopportunity to gain value and new insights from data in any field - business,socializing, research and society. At the same time, it raises questions abouthow justified we are in placing our trust in these technologies. There is arisk that such powers may lead to biased, inappropriate or unintended actions.Therefore, ethical considerations which might occur as the result of datascience practices should be carefully considered and these potential problemsshould be identified during the data science lifecycle and mitigated ifpossible. However, a typical data scientist has not enough knowledge foridentifying these challenges and it is not always possible to include an ethicsexpert during data science production. The aim of this study is to provide apractical guideline to data scientists and increase their awareness. In thiswork, we reviewed different sources of biases and grouped them under differentstages of the data science lifecycle. The work is still under progress. The aimof early publishing is to collect community feedback and improve the curatedknowledge base for bias types and solutions.","Dinh-An Ho, Oya Beyan",2020-09-10T13:41:48Z,2020-10-27T12:31:24Z,"22 pages, 1 Figure, 1 Table arXiv admin note: text overlap with
  arXiv:1901.10002, arXiv:1810.01943 by other authors",cs.CY,http://arxiv.org/pdf/2009.09795v2,eng,,,Medicine
171,http://arxiv.org/abs/2305.13576v1,Approach to Data Science with Multiscale Information Theory,"Data Science is a multidisciplinary field that plays a crucial role inextracting valuable insights and knowledge from large and intricate datasets.Within the realm of Data Science, two fundamental components are InformationTheory (IT) and Statistical Mechanics (SM), which provide a theoreticalframework for understanding dataset properties. IT enables efficient storageand transmission of information, while SM focuses on the behavior of systemscomprising numerous interacting components. In the context of data science, SMallows us to model complex interactions among variables within a dataset. Byleveraging these tools, data scientists can gain a profound understanding ofdata properties, leading to the development of advanced models and algorithmsfor analysis and interpretation. Consequently, data science has the potentialto drive accurate predictions and enhance decision-making across variousdomains, including finance, marketing, healthcare, and scientific research.  In this paper, we apply this data science framework to a large and intricatequantum mechanical system composed of particles. Our research demonstrates thatthe dynamic and probabilistic nature of such systems can be effectivelyaddressed using a Multiscale Entropic Dynamics (MED) approach, derived from theBoltzmann methods of SM. Through the MED approach, we can describe the system'sdynamics by formulating a general form of the Nonlinear Schr\""odinger equationand how it can be applied to various systems with particles andquasi-particles, such as electrons, plasmons, polarons, and solitons. Byemploying this innovative approach, we pave the way for a deeper understandingof quantum mechanical systems and their behaviors within complex materials.","Shahid Nawaz, Muhammad Saleem, F. V. Kusmartsev, Dalaver H. Anjum",2023-05-23T01:08:50Z,2023-05-23T01:08:50Z,12 pages,physics.data-an,http://arxiv.org/pdf/2305.13576v1,eng,,,Social Sciences
172,http://arxiv.org/abs/cs/0502008v1,Scientific Data Management in the Coming Decade,This is a thought piece on data-intensive science requirements for databasesand science centers. It argues that peta-scale datasets will be housed byscience centers that provide substantial storage and processing for scientistswho access the data via smart notebooks. Next-generation science instrumentsand simulations will generate these peta-scale datasets. The need to publishand share data and the need for generic analysis and visualization tools willfinally create a convergence on common metadata standards. Database systemswill be judged by their support of these metadata standards and by theirability to manage and access peta-scale datasets. The proceduralstream-of-bytes-file-centric approach to data analysis is both too cumbersomeand too serial for such large datasets. Non-procedural query and analysis ofschematized self-describing data is both easier to use and allows much moreparallelism.,"Jim Gray, David T. Liu, Maria Nieto-Santisteban, Alexander S. Szalay, David DeWitt, Gerd Heber",2005-02-02T03:15:42Z,2005-02-02T03:15:42Z,,cs.DB,http://arxiv.org/pdf/cs/0502008v1,eng,,,Medicine
173,http://arxiv.org/abs/1202.3952v1,Check Your Data Freedom: A Taxonomy to Assess Life Science Database  Openness,"Molecular biology data are subject to terms of use that vary widely betweendatabases and curating institutions. This research presents a taxonomy ofcontractual and technical restrictions applicable to databases in life science.It builds upon research led by Science Commons demonstrating why open data andthe freedom to integrate facilitate innovation and how this openness can beachieved. The taxonomy describes technical and legal restrictions applicable tolife science databases, and its metadata have been used to assess terms of useof databases hosted by Life Science Resource Name (LSRN) Schema. While a fewpublic domain policies are standardized, most terms of use are not harmonized,difficult to understand and impose controls that prevent others fromeffectively reusing data. Identifying a small number of restrictions allows oneto quickly appreciate which databases are open. A checklist for data opennessis proposed in order to assist database curators who wish to make their datamore open to make sure they do so.",Melanie Dulong De Rosnay,2012-02-17T16:26:09Z,2012-02-17T16:26:09Z,,q-bio.QM,http://arxiv.org/pdf/1202.3952v1,eng,,,Medicine
174,http://arxiv.org/abs/1503.06201v1,Data Science as a New Frontier for Design,"The purpose of this paper is to contribute to the challenge of transferringknow-how, theories and methods from design research to the design processes ininformation science and technologies. More specifically, we shall consider adomain, namely data-science, that is becoming rapidly a globally investedresearch and development axis with strong imperatives for innovation given thedata deluge we are currently facing. We argue that, in order to rise to thedata-related challenges that the society is facing, data-science initiativesshould ensure a renewal of traditional research methodologies that are stilllargely based on trial-error processes depending on the talent and insights ofa single (or a restricted group of) researchers. It is our claim that designtheories and methods can provide, at least to some extent, the much-neededframework. We will use a worldwide data-science challenge organized to study atechnical problem in physics, namely the detection of Higgs boson, as a usecase to demonstrate some of the ways in which design theory and methods canhelp in analyzing and shaping the innovation dynamics in such projects.","Akin Osman, Kazakçi Mines",2015-03-20T19:31:09Z,2015-03-20T19:31:09Z,"International Conference on Engineering Design, Jul 2015, Milan,
  Italy",cs.AI,http://arxiv.org/pdf/1503.06201v1,eng,,,Physics and Astronomy
175,http://arxiv.org/abs/1604.07397v1,Teaching Data Science,"We describe an introductory data science course, entitled Introduction toData Science, offered at the University of Illinois at Urbana-Champaign. Thecourse introduced general programming concepts by using the Python programminglanguage with an emphasis on data preparation, processing, and presentation.The course had no prerequisites, and students were not expected to have anyprogramming experience. This introductory course was designed to cover a widerange of topics, from the nature of data, to storage, to visualization, toprobability and statistical analysis, to cloud and high performance computing,without becoming overly focused on any one subject. We conclude this articlewith a discussion of lessons learned and our plans to develop new data sciencecourses.","Robert J. Brunner, Edward J. Kim",2016-04-25T18:26:51Z,2016-04-25T18:26:51Z,"10 pages, 4 figures, International Conference on Computational
  Science (ICCS 2016)",stat.OT,http://arxiv.org/pdf/1604.07397v1,eng,,,Social Sciences
176,http://arxiv.org/abs/2101.05638v1,La Serena School for Data Science: multidisciplinary hands-on education  in the era of big data,"La Serena School for Data Science is a multidisciplinary program with sixeditions so far and a constant format: during 10-14 days, a group of $\sim$30students (15 from the US, 15 from Chile and 1-3 from Caribbean countries) and$\sim$9 faculty gather in La Serena (Chile) to complete an intensive program inData Science with emphasis in applications to astronomy and bio-sciences.  The students attend theoretical and hands-on sessions, and, since early on,they work in multidisciplinary groups with their ""mentors"" (from the faculty)on real data science problems. The SOC and LOC of the school have developedstudent selection guidelines to maximize diversity.  The program is very successful as proven by the high over-subscription rate(factor 5-8) and the plethora of positive testimony, not only from alumni, butalso from current and former faculty that keep in contact with them.","A. Bayo, M. J. Graham, D. Norman, M. Cerda, G. Damke, A. Zenteno, C. Ibarlucea",2021-01-13T12:24:49Z,2021-01-13T12:24:49Z,"2 pages, IAU Symposium No. 367, Education and Heritage in the Era of
  Big Data in Astronomy",physics.ed-ph,http://arxiv.org/pdf/2101.05638v1,eng,,,Social Sciences
177,http://arxiv.org/abs/2105.05699v2,Automating Data Science: Prospects and Challenges,"Given the complexity of typical data science projects and the associateddemand for human expertise, automation has the potential to transform the datascience process.  Key insights:  * Automation in data science aims to facilitate and transform the work ofdata scientists, not to replace them.  * Important parts of data science are already being automated, especially inthe modeling stages, where techniques such as automated machine learning(AutoML) are gaining traction.  * Other aspects are harder to automate, not only because of technologicalchallenges, but because open-ended and context-dependent tasks require humaninteraction.","Tijl De Bie, Luc De Raedt, José Hernández-Orallo, Holger H. Hoos, Padhraic Smyth, Christopher K. I. Williams",2021-05-12T14:34:35Z,2022-02-28T15:45:49Z,"19 pages, 3 figures. v1 accepted for publication (April 2021) in
  Communications of the ACM",cs.DB,http://arxiv.org/pdf/2105.05699v2,eng,,,Social Sciences
178,http://arxiv.org/abs/2209.02375v1,Understanding and Reducing Crater Counting Errors in Citizen Science  Data and the Need for Standardisation,"Citizen science has become a popular tool for preliminary data processingtasks, such as identifying and counting Lunar impact craters in modernhigh-resolution imagery. However, use of such data requires that citizenscience products are understandable and reliable. Contamination and missingdata can reduce the usefulness of datasets so it is important that such effectsare quantified. This paper presents a method, based upon a newly developedquantitative pattern recognition system (Linear Poisson Models) for estimatinglevels of contamination within MoonZoo citizen science crater data. Evidencewill show that it is possible to remove the effects of contamination, withreference to some agreed upon ground truth, resulting in estimated cratercounts which are highly repeatable. However, it will also be shown thatcorrecting for missing data is currently more difficult to achieve. Thetechniques are tested on MoonZoo citizen science crater annotations from theApollo 17 site and also undergraduate and expert results from the same region.","P. D. Tar, N. A. Thacker",2022-09-06T10:54:08Z,2022-09-06T10:54:08Z,,cs.CV,http://arxiv.org/pdf/2209.02375v1,eng,,,Computer Science
179,http://arxiv.org/abs/2301.13761v3,Foundations and Scoping of Data Science,"There has been an increasing recognition of the value of data and ofdata-based decision making. As a consequence, the development of data scienceas a field of study has intensified in recent years. However, there is nosystematic and comprehensive treatment and understanding of data science. Thisarticle describes a systematic and end-to-end framing of the field based on aninclusive definition. It identifies the core components making up the datascience ecosystem, presents its lifecycle modeling the development process, andargues its interdisciplinarity.",M. Tamer Özsu,2023-01-31T16:54:33Z,2024-01-04T14:33:06Z,"This is an extended version of the original submission. The original
  has now been published by Communications of ACM, Volume 66, Number 7, pages
  106-116, 2023. The original version was only 10 pages and the new version is
  100 pages; the original had a restricted number of references (42) while the
  longer one is much more complete with over 150 references",cs.OH,http://arxiv.org/pdf/2301.13761v3,eng,,,Medicine
180,http://arxiv.org/abs/2311.07126v1,How to Do Machine Learning with Small Data? -- A Review from an  Industrial Perspective,"Artificial intelligence experienced a technological breakthrough in science,industry, and everyday life in the recent few decades. The advancements can becredited to the ever-increasing availability and miniaturization ofcomputational resources that resulted in exponential data growth. However,because of the insufficient amount of data in some cases, employing machinelearning in solving complex tasks is not straightforward or even possible. As aresult, machine learning with small data experiences rising importance in datascience and application in several fields. The authors focus on interpretingthe general term of ""small data"" and their engineering and industrialapplication role. They give a brief overview of the most important industrialapplications of machine learning and small data. Small data is defined in termsof various characteristics compared to big data, and a machine learningformalism was introduced. Five critical challenges of machine learning withsmall data in industrial applications are presented: unlabeled data, imbalanceddata, missing data, insufficient data, and rare events. Based on thosedefinitions, an overview of the considerations in domain representation anddata acquisition is given along with a taxonomy of machine learning approachesin the context of small data.","Ivan Kraljevski, Yong Chul Ju, Dmitrij Ivanov, Constanze Tschöpe, Matthias Wolff",2023-11-13T07:39:13Z,2023-11-13T07:39:13Z,,cs.LG,http://arxiv.org/pdf/2311.07126v1,eng,,,Computer Science
181,http://arxiv.org/abs/1103.1977v1,Development of Computer Science Disciplines - A Social Network Analysis  Approach,"In contrast to many other scientific disciplines, computer science considersconference publications. Conferences have the advantage of providing fastpublication of papers and of bringing researchers together to present anddiscuss the paper with peers. Previous work on knowledge mapping focused on themap of all sciences or a particular domain based on ISI published JCR (JournalCitation Report). Although this data covers most of important journals, itlacks computer science conference and workshop proceedings. That results in animprecise and incomplete analysis of the computer science knowledge. This paperpresents an analysis on the computer science knowledge network constructed fromall types of publications, aiming at providing a complete view of computerscience research. Based on the combination of two important digital libraries(DBLP and CiteSeerX), we study the knowledge network created atjournal/conference level using citation linkage, to identify the development ofsub-disciplines. We investigate the collaborative and citation behavior ofjournals/conferences by analyzing the properties of their co-authorship andcitation subgraphs. The paper draws several important conclusions. First,conferences constitute social structures that shape the computer scienceknowledge. Second, computer science is becoming more interdisciplinary. Third,experts are the key success factor for sustainability of journals/conferences.","Manh Cuong Pham, Ralf Klamma, Matthias Jarke",2011-03-10T09:51:19Z,2011-03-10T09:51:19Z,,cs.DL,http://arxiv.org/pdf/1103.1977v1,eng,,,Social Sciences
182,http://arxiv.org/abs/2212.04853v1,Open Science in Lattice Gauge Theory community,"Open science aims to make scientific research processes, tools and resultsaccessible to all scientific communities, creating trust in science andenabling digital competences to be realized in research, leading to increasedinnovation. It provides standard and transparent pathways to conductingresearch and fosters best practices for collecting, analysing, preserving,sharing and reusing data, software, workflows and other outputs throughcollaborative networks. Open Science appears to be becoming the norm with itsapplications spanning throughout the whole research cycle of a project. Theimportance of making Open Science a reality is nowadays reflected in fundingpolicies, research infrastructure and politics. In these proceedings we presentthe basic Open Science principles explaining briefly best practices formaterialising Open Science. Subsequently, we present the results of thelandscaping survey of Open Science in the Lattice Gauge Theories community.Finally, we provide directions in which the Lattice Gauge Theory communitycould move in order to enhance Openness and FAIRness (Findability,Accessibility, Interoperability, Reusability) in Science.","Andreas Athenodorou, Ed Bennett, Julian Lenz, Elli Papadopoullou",2022-12-09T13:46:20Z,2022-12-09T13:46:20Z,"10 pages, 7 figures, Proceedings of the 39th International Symposium
  on Lattice Field Theory (Lattice2022), 8-13 August, 2022, Bonn, Germany",hep-lat,http://arxiv.org/pdf/2212.04853v1,eng,,,Social Sciences
183,http://arxiv.org/abs/1007.5377v1,Browsing the sky through the ASI Science Data Centre Data Explorer Tool,"We present here the Data Explorer tool developed at the ASI Science DataCenter (ASDC). This tool is designed to provide an efficient and user-friendlyway to display information residing in several catalogs stored in the ASDCservers, to cross-correlate this information and to download/analyze data viaour scientific tools and/or external services. Our database includes GRBcatalogs (such as Swift and Beppo-SAX), which can be queried through the DataExplorer. The GRB fields can be viewed in multiwavelength and the data can beanalyzed or retrieved.","V. D'Elia, M. Capalbi, F. Verrecchia, B. Gendre, P. Giommi",2010-07-30T06:27:50Z,2010-07-30T06:27:50Z,"3 pages, 2 .ps figures, to appear in ""Deciphering the Ancient
  Universe with GRBs"" conference proceedings",astro-ph.IM,http://arxiv.org/pdf/1007.5377v1,eng,,,Computer Science
184,http://arxiv.org/abs/1605.08846v1,"A Human-Centered Approach to Data Privacy : Political Economy, Power,  and Collective Data Subjects","Researchers find weaknesses in current strategies for protecting privacy inlarge datasets. Many anonymized datasets are reidentifiable, and norms foroffering data subjects notice and consent over emphasize individualresponsibility. Based on fieldwork with data managers in the City of Seattle, Iidentify ways that these conventional approaches break down in practice.Drawing on work from theorists in sociocultural anthropology, I propose that aHuman Centered Data Science move beyond concepts like dataset identifiabilityand sensitivity toward a broader ontology of who is implicated by a dataset,and new ways of anticipating how data can be combined and used.",Meg Young,2016-05-28T04:57:13Z,2016-05-28T04:57:13Z,"This is a workshop paper accepted to the Human-Centered Data Science
  Workshop at the Computer Supported Collaborative Work Conference in 2016",cs.CY,http://arxiv.org/pdf/1605.08846v1,eng,,,Medicine
185,http://arxiv.org/abs/1707.06937v4,Searching Data: A Review of Observational Data Retrieval Practices in  Selected Disciplines,A cross-disciplinary examination of the user behaviours involved in seekingand evaluating data is surprisingly absent from the research data discussion.This review explores the data retrieval literature to identify commonalities inhow users search for and evaluate observational research data. Two analyticalframeworks rooted in information retrieval and science technology studies areused to identify key similarities in practices as a first step towarddeveloping a model describing data retrieval.,"Kathleen Gregory, Paul Groth, Helena Cousijn, Andrea Scharnhorst, Sally Wyatt",2017-07-21T15:36:10Z,2020-03-12T09:07:40Z,,cs.DL,http://arxiv.org/pdf/1707.06937v4,eng,,,Medicine
186,http://arxiv.org/abs/2008.12372v1,Data-driven Computational Social Science: A Survey,"Social science concerns issues on individuals, relationships, and the wholesociety. The complexity of research topics in social science makes it theamalgamation of multiple disciplines, such as economics, political science, andsociology, etc. For centuries, scientists have conducted many studies tounderstand the mechanisms of the society. However, due to the limitations oftraditional research methods, there exist many critical social issues to beexplored. To solve those issues, computational social science emerges due tothe rapid advancements of computation technologies and the profound studies onsocial science. With the aids of the advanced research techniques, variouskinds of data from diverse areas can be acquired nowadays, and they can help uslook into social problems with a new eye. As a result, utilizing various datato reveal issues derived from computational social science area has attractedmore and more attentions. In this paper, to the best of our knowledge, wepresent a survey on data-driven computational social science for the first timewhich primarily focuses on reviewing application domains involving humandynamics. The state-of-the-art research on human dynamics is reviewed fromthree aspects: individuals, relationships, and collectives. Specifically, theresearch methodologies used to address research challenges in aforementionedapplication domains are summarized. In addition, some important open challengeswith respect to both emerging research topics and research methods arediscussed.","Jun Zhang, Wei Wang, Feng Xia, Yu-Ru Lin, Hanghang Tong",2020-08-10T09:28:36Z,2020-08-10T09:28:36Z,"28 pages, 8 figures",cs.SI,http://arxiv.org/pdf/2008.12372v1,eng,,,Social Sciences
187,http://arxiv.org/abs/2301.12031v1,Context Matters: A Strategy to Pre-train Language Model for Science  Education,"This study aims at improving the performance of scoring student responses inscience education automatically. BERT-based language models have shownsignificant superiority over traditional NLP models in various language-relatedtasks. However, science writing of students, including argumentation andexplanation, is domain-specific. In addition, the language used by students isdifferent from the language in journals and Wikipedia, which are trainingsources of BERT and its existing variants. All these suggest that adomain-specific model pre-trained using science education data may improvemodel performance. However, the ideal type of data to contextualize pre-trainedlanguage model and improve the performance in automatically scoring studentwritten responses remains unclear. Therefore, we employ different data in thisstudy to contextualize both BERT and SciBERT models and compare theirperformance on automatic scoring of assessment tasks for scientificargumentation. We use three datasets to pre-train the model: 1) journalarticles in science education, 2) a large dataset of students' writtenresponses (sample size over 50,000), and 3) a small dataset of students'written responses of scientific argumentation tasks. Our experimental resultsshow that in-domain training corpora constructed from science questions andresponses improve language model performance on a wide variety of downstreamtasks. Our study confirms the effectiveness of continual pre-training ondomain-specific data in the education domain and demonstrates a generalizablestrategy for automating science education tasks with high accuracy. We plan torelease our data and SciEdBERT models for public use and community engagement.","Zhengliang Liu, Xinyu He, Lei Liu, Tianming Liu, Xiaoming Zhai",2023-01-27T23:50:16Z,2023-01-27T23:50:16Z,,cs.AI,http://arxiv.org/pdf/2301.12031v1,eng,,,Social Sciences
188,http://arxiv.org/abs/gr-qc/0602019v1,The Testbed for LISA Analysis Project,"The Testbed for LISA Analysis (TLA) Project aims to facilitate thedevelopment, validation and comparison of different methods for LISA sciencedata analysis, by the broad LISA Science Community, to meet the specialchallenges that LISA poses. It includes a well-defined Simulated LISA DataProduct (SLDP), which provides a clean interface between the communities thathave developed to model and to analyze the LISA science data stream; aweb-based clearinghouse (at <http://tla.gravity.psu.edu>) providing SLDPsoftware libraries, relevant software, papers and other documentation, and arepository for SLDP data sets; a set of mailing lists for communication betweenand among LISA simulators and LISA science analysts; a problem tracking systemfor SLDP support; and a program of workshops to allow the burgeoning LISAscience community to further refine the SLDP definition, define specific LISAscience analysis challenges, and report their results. This note describes theTLA Project, the resources it provides immediately, its future plans, andinvites the participation of the broader community in the furtherance of itsgoals.","Lee Samuel Finn, Matthew J. Benacquista, Shane L. Larson, Louis J. Rubbo",2006-02-05T22:37:25Z,2006-02-05T22:37:25Z,"5 pages, no figures",gr-qc,http://arxiv.org/pdf/gr-qc/0602019v1,eng,,,Medicine
189,http://arxiv.org/abs/2009.12210v1,Emergence of complex data from simple local rules in a network game,"As one of the main subjects of investigation in data science, network sciencehas been demonstrated a wide range of applications to real-world networksanalysis and modeling. For example, the pervasive presence of structural ortopological characteristics, such as the small-world phenomenon,small-diameter, scale-free properties, or fat-tailed degree distribution wereone of the underlying pillars fostering the study of complex networks. Relatingthese phenomena with other emergent properties in complex systems became asubject of central importance. By introducing new implications on the interfacebetween data science and complex systems science with the purpose of tacklingsome of these issues, in this article we present a model for a network gameplayed by complex networks in which nodes are computable systems. Inparticular, we present and discuss how some network topological properties andsimple local communication rules are able to generate a phase transition withrespect to the emergence of incompressible data.","Felipe S. Abrahão, Klaus Wehmuth, Artur Ziviani",2020-09-23T19:43:27Z,2020-09-23T19:43:27Z,arXiv admin note: text overlap with arXiv:1708.09149,cs.LO,http://arxiv.org/pdf/2009.12210v1,eng,,,Mathematics
190,http://arxiv.org/abs/2104.12545v3,Agile (data) science: a (draft) manifesto,"Science has a data management problem, as well as a project managementproblem. While industrial-grade data science teams have embraced the agilemindset, and adopted or created all kind of tools to create reproducibleworkflows, academia-based science is still (mostly) mired in a mindset that isfocused on a single final product (a paper), without focusing on incrementalimprovement, on any specific problem or customer, or, paying any attentionreproducibility. In this report we argue towards the adoption of the agilemindset and agile data science tools in academia, to make a more responsible,and over all, reproducible science.","Juan Julián Merelo-Guervós, Mario García-Valdez",2021-04-09T12:18:46Z,2022-07-04T12:00:31Z,,cs.CY,http://arxiv.org/pdf/2104.12545v3,eng,,,Computer Science
191,http://arxiv.org/abs/astro-ph/0701361v1,How to Make the Dream Come True: The Astronomers' Data Manifesto,"Astronomy is one of the most data-intensive of the sciences. Data technologyis accelerating the quality and effectiveness of its research, and the rate ofastronomical discovery is higher than ever. As a result, many view astronomy asbeing in a 'Golden Age', and projects such as the Virtual Observatory areamongst the most ambitious data projects in any field of science. But thesepowerful tools will be impotent unless the data on which they operate are ofmatching quality. Astronomy, like other fields of science, therefore needs toestablish and agree on a set of guiding principles for the management ofastronomical data. To focus this process, we are constructing a 'datamanifesto', which proposes guidelines to maximise the rate andcost-effectiveness of scientific discovery.",Ray P Norris,2007-01-12T03:28:11Z,2007-01-12T03:28:11Z,"Submitted to Data Science Journal Presented at CODATA, Beijing,
  October 2006",astro-ph,http://arxiv.org/pdf/astro-ph/0701361v1,eng,,,Social Sciences
192,http://arxiv.org/abs/1701.09045v1,Big Data Technology Accelerate Genomics Precision Medicine,"During genomics life science research, the data volume of whole genomics andlife science algorithm is going bigger and bigger, which is calculated as TB,PB or EB etc. The key problem will be how to store and analyze the data withoptimized way. This paper demonstrates how Intel Big Data Technology andArchitecture help to facilitate and accelerate the genomics life scienceresearch in data store and utilization. Intel defines high performanceGenomicsDB for variant call data query and Lustre filesystem with HierarchalStorage Management for genomics data store. Based on these great technology,Intel defines genomics knowledge share and exchange architecture, which islanded and validated in BGI China and Shanghai Children Hospital with verypositive feedback. And these big data technology can definitely be scaled tomuch more genomics life science partners in the world.",Hao Li,2017-01-29T14:21:52Z,2017-01-29T14:21:52Z,,cs.DB,http://arxiv.org/pdf/1701.09045v1,eng,,,Computer Science
193,http://arxiv.org/abs/2003.07681v1,The Data Science Fire Next Time: Innovative strategies for mentoring in  data science,"As data mining research and applications continue to expand in to a varietyof fields such as medicine, finance, security, etc., the need for talented anddiverse individuals is clearly felt. This is particularly the case as Big Datainitiatives have taken off in the federal, private and academic sectors,providing a wealth of opportunities, nationally and internationally. TheBroadening Participation in Data Mining (BPDM) workshop was created more than 7years ago with the goal of fostering mentorship, guidance, and connections forminority and underrepresented groups in the data science and machine learningcommunity, while also enriching technical aptitude and exposure for a group oftalented students. To date it has impacted the lives of more than 330underrepresented trainees in data science. We provide a venue to connecttalented students with innovative researchers in industry, academia,professional societies, and government. Our mission is to facilitatemeaningful, lasting relationships between BPDM participants to ultimatelyincrease diversity in data mining. This most recent workshop took place atHoward University in Washington, DC in February 2019. Here we report on thementoring strategies that we undertook at the 2019 BPDM and how those werereceived.","Latifa Jackson, Heriberto Acosta Maestre",2020-03-01T03:40:38Z,2020-03-01T03:40:38Z,,physics.ed-ph,http://arxiv.org/pdf/2003.07681v1,eng,,,Social Sciences
194,http://arxiv.org/abs/1801.00371v2,Data Science vs. Statistics: Two Cultures?,"Data science is the business of learning from data, which is traditionallythe business of statistics. Data science, however, is often understood as abroader, task-driven and computationally-oriented version of statistics. Boththe term data science and the broader idea it conveys have origins instatistics and are a reaction to a narrower view of data analysis. Expandingupon the views of a number of statisticians, this paper encourages a big-tentview of data analysis. We examine how evolving approaches to modern dataanalysis relate to the existing discipline of statistics (e.g. exploratoryanalysis, machine learning, reproducibility, computation, communication and therole of theory). Finally, we discuss what these trends mean for the future ofstatistics by highlighting promising directions for communication, educationand research.","Iain Carmichael, J. S. Marron",2017-12-31T23:00:24Z,2018-05-01T02:55:32Z,,stat.OT,http://arxiv.org/pdf/1801.00371v2,eng,,,Computer Science
195,http://arxiv.org/abs/2402.17168v1,Benchmarking Data Science Agents,"In the era of data-driven decision-making, the complexity of data analysisnecessitates advanced expertise and tools of data science, presentingsignificant challenges even for specialists. Large Language Models (LLMs) haveemerged as promising aids as data science agents, assisting humans in dataanalysis and processing. Yet their practical efficacy remains constrained bythe varied demands of real-world applications and complicated analyticalprocess. In this paper, we introduce DSEval -- a novel evaluation paradigm, aswell as a series of innovative benchmarks tailored for assessing theperformance of these agents throughout the entire data science lifecycle.Incorporating a novel bootstrapped annotation method, we streamline datasetpreparation, improve the evaluation coverage, and expand benchmarkingcomprehensiveness. Our findings uncover prevalent obstacles and providecritical insights to inform future advancements in the field.","Yuge Zhang, Qiyang Jiang, Xingyu Han, Nan Chen, Yuqing Yang, Kan Ren",2024-02-27T03:03:06Z,2024-02-27T03:03:06Z,"Source code and data are available at
  https://github.com/MetaCopilot/dseval",cs.AI,http://arxiv.org/pdf/2402.17168v1,eng,,,Computer Science
196,http://arxiv.org/abs/2408.17244v2,Categorical data clustering: 25 years beyond K-modes,"The clustering of categorical data is a common and important task in computerscience, offering profound implications across a spectrum of applications.Unlike purely numerical data, categorical data often lack inherent ordering asin nominal data, or have varying levels of order as in ordinal data, thusrequiring specialized methodologies for efficient organization and analysis.This review provides a comprehensive synthesis of categorical data clusteringin the past twenty-five years, starting from the introduction of K-modes. Itelucidates the pivotal role of categorical data clustering in diverse fieldssuch as health sciences, natural sciences, social sciences, education,engineering and economics. Practical comparisons are conducted for algorithmshaving public implementations, highlighting distinguishing clusteringmethodologies and revealing the performance of recent algorithms on severalbenchmark categorical datasets. Finally, challenges and opportunities in thefield are discussed.","Tai Dinh, Wong Hauchi, Philippe Fournier-Viger, Daniil Lisik, Minh-Quyet Ha, Hieu-Chi Dam, Van-Nam Huynh",2024-08-30T12:36:00Z,2024-09-09T13:51:49Z,,cs.LG,http://arxiv.org/pdf/2408.17244v2,eng,,,Medicine
197,http://arxiv.org/abs/1705.00351v2,Nonparametric Cusum Charts for Angular Data with Applications in Health  Science and Astrophysics,"This paper develops non-parametric rotation invariant CUSUMs suited to thedetection of changes in the mean direction as well as changes in theconcentration parameter of angular data. The properties of the CUSUMs areillustrated by theoretical calculations, Monte Carlo simulation and applicationto sequentially observed angular data from health science and astrophysics.","F. Lombard, Douglas M. Hawkins, Cornelis Potgieter",2017-04-30T17:58:02Z,2018-06-07T15:32:33Z,,stat.ME,http://arxiv.org/pdf/1705.00351v2,eng,,,Medicine
198,http://arxiv.org/abs/2308.08004v1,The Mastery Rubric for Statistics and Data Science: promoting coherence  and consistency in data science education and training,"Consensus based publications of both competencies and undergraduatecurriculum guidance documents targeting data science instruction for highereducation have recently been published. Recommendations for curriculum featuresfrom diverse sources may not result in consistent training across programs. AMastery Rubric was developed that prioritizes the promotion and documentationof formal growth as well as the development of independence needed for the 13requisite knowledge, skills, and abilities for professional practice instatistics and data science, SDS. The Mastery Rubric, MR, driven curriculum canemphasize computation, statistics, or a third discipline in which the otherwould be deployed or, all three can be featured. The MR SDS supports each ofthese program structures while promoting consistency with international,consensus based, curricular recommendations for statistics and data science,and allows 'statistics', 'data science', and 'statistics and data science'curricula to consistently educate students with a focus on increasing learnersindependence. The Mastery Rubric construct integrates findings from thelearning sciences, cognitive and educational psychology, to support teachersand students through the learning enterprise. The MR SDS will support highereducation as well as the interests of business, government, and academic workforce development, bringing a consistent framework to address challenges thatexist for a domain that is claimed to be both an independent discipline andpart of other disciplines, including computer science, engineering, andstatistics. The MR-SDS can be used for development or revision of an evaluablecurriculum that will reliably support the preparation of early e.g.,undergraduate degree programs, middle e.g., upskilling and training programs,and late e.g., doctoral level training practitioners.","Rochelle E. Tractenberg, Donna LaLonde, Suzanne Thornton",2023-08-15T19:36:52Z,2023-08-15T19:36:52Z,"40 pages; 2 Tables; 4 Figures. Presented at the Symposium on Data
  Science & Statistics (SDSS) 2023",stat.OT,http://arxiv.org/pdf/2308.08004v1,eng,,,Medicine
199,http://arxiv.org/abs/2208.03865v1,A Python-based tool for constructing observables from the DSN's  closed-loop archival tracking data files,"Radio science data collected from NASA's Deep Space Networks (DSNs) are madeavailable in various formats through NASA's Planetary Data System (PDS). Themajority of these data are packed in complex formats, making them inaccessibleto users without specialized knowledge. In this paper, we present aPython-based tool that can preprocess the closed-loop archival tracking datafiles (ATDFs), produce Doppler and range observables, and write them in anASCII table along with ancillary information. ATDFs are primitive closed-loopradio science products with limited available documentation. Early in the2000s, DSN deprecated ATDF and replaced it with the Tracking and NavigationService Data Files (TNF) to keep up with the evolution of the radio sciencesystem. Most data processing software (e.g., orbit determination software)cannot use them directly, thus limiting the utilization of these data. As such,the vast majority of historical closed-loop radio science data have not yetbeen processed with modern software and with our improved understanding of thesolar system. The preprocessing tool presented in this paper makes it possibleto revisit such historical data using modern techniques and software to conductcrucial radio science experiments.",Ashok Kumar Verma,2022-08-08T01:44:33Z,2022-08-08T01:44:33Z,Accepted for publication in the SoftwareX journal,astro-ph.IM,http://arxiv.org/pdf/2208.03865v1,eng,,,Medicine
200,http://arxiv.org/abs/1712.00544v2,Conducting Highly Principled Data Science: A Statistician's Job and Joy,"Highly Principled Data Science insists on methodologies that are: (1)scientifically justified, (2) statistically principled, and (3) computationallyefficient. An astrostatistics collaboration, together with some reminiscences,illustrates the increased roles statisticians can and should play to ensurethis trio, and to advance the science of data along the way.",Xiao-Li Meng,2017-12-02T04:13:17Z,2017-12-05T11:52:17Z,"To appear in the special issue on ""The Role of Statistics in the Era
  of Big Data"" in Statistics and Probability Letters (2018)",stat.OT,http://arxiv.org/pdf/1712.00544v2,eng,,,Physics and Astronomy
201,http://arxiv.org/abs/1909.08544v1,Distance Geometry and Data Science,"Data are often represented as graphs. Many common tasks in data science arebased on distances between entities. While some data science methodologiesnatively take graphs as their input, there are many more that take their inputin vectorial form. In this survey we discuss the fundamental problem of mappinggraphs to vectors, and its relation with mathematical programming. We discussapplications, solution methods, dimensional reduction techniques and some oftheir limits. We then present an application of some of these ideas to neuralnetworks, showing that distance geometry techniques can give competitiveperformance with respect to more traditional graph-to-vector mappings.",Leo Liberti,2019-09-18T16:11:33Z,2019-09-18T16:11:33Z,"This invited survey will appear in the journal TOP
  <https://link.springer.com/journal/11750>, in 2020 issue 2",cs.LG,http://arxiv.org/pdf/1909.08544v1,eng,,,Physics and Astronomy
202,http://arxiv.org/abs/2102.09391v3,Interleaving Computational and Inferential Thinking: Data Science for  Undergraduates at Berkeley,"The undergraduate data science curriculum at the University of California,Berkeley is anchored in five new courses that emphasize computational thinking,inferential thinking, and working on real-world problems. We believe thatinterleaving these elements within our core courses is essential to preparingstudents to engage in data-driven inquiry at the scale that contemporaryscientific and industrial applications demand. This new curriculum is alreadyreshaping the undergraduate experience at Berkeley, where these courses havebecome some of the most popular on campus and have led to a surging interest ina new undergraduate major and minor program in data science.","Ani Adhikari, John DeNero, Michael I. Jordan",2021-02-13T22:51:24Z,2021-03-17T04:05:45Z,,cs.CY,http://arxiv.org/pdf/2102.09391v3,eng,,,Social Sciences
203,http://arxiv.org/abs/2007.04095v1,Data science and the art of modelling,"Datacentric enthusiasm is growing strong across a variety of domains. Whilstdata science asks unquestionably exciting scientific questions, we argue thatits contributions should not be extrapolated from the scientific context inwhich they originate. In particular we suggest that the simple-minded idea tothe effect that data can be seen as a replacement for scientific modelling isnot tenable. By recalling some well-known examples from dynamical systems weconclude that data science performs at its best when coupled with the subtleart of modelling.","Hykel Hosni, Angelo Vulpiani",2020-06-27T15:04:07Z,2020-06-27T15:04:07Z,arXiv admin note: text overlap with arXiv:1810.10446,physics.soc-ph,http://arxiv.org/pdf/2007.04095v1,eng,,,Social Sciences
204,http://arxiv.org/abs/2105.09213v2,Representative Methods of Computational Socioeconomics,"The increasing data availability and imported analyzing tools from computerscience and physical science have sharply changed traditional methodologies ofsocial sciences, leading to a new branch named computational socioeconomicsthat studies various phenomena in socioeconomic development by usingquantitative methods based on large-scale real-world data. Sited on recentpublications, this Perspective will introduce three representative methods: (i)natural data analyses, (ii) large-scale online experiments, and (iii)integration of big data and surveys. This Perspective ends up with in-depthdiscussion on the limitations and challenges of the above-mentioned emergingmethods.",Tao Zhou,2021-05-19T15:45:55Z,2021-07-30T02:40:56Z,"7 pages, without figures or tables",physics.soc-ph,http://arxiv.org/pdf/2105.09213v2,eng,,,Engineering
205,http://arxiv.org/abs/2109.03541v1,Three fundamental problems in risk modeling on big data: an information  theory view,"Since Claude Shannon founded Information Theory, information theory haswidely fostered other scientific fields, such as statistics, artificialintelligence, biology, behavioral science, neuroscience, economics, andfinance. Unfortunately, actuarial science has hardly benefited from informationtheory. So far, only one actuarial paper on information theory can be searchedby academic search engines. Undoubtedly, information and risk, both asUncertainty, are constrained by entropy law. Today's insurance big data erameans more data and more information. It is unacceptable for risk managementand actuarial science to ignore information theory. Therefore, this paper aimsto exploit information theory to discover the performance limits of insurancebig data systems and seek guidance for risk modeling and the development ofactuarial pricing systems.",Jiamin Yu,2021-09-08T10:58:06Z,2021-09-08T10:58:06Z,"6 pages, 7 figures",q-fin.RM,http://arxiv.org/pdf/2109.03541v1,eng,,,Computer Science
206,http://arxiv.org/abs/2212.05179v1,"The problem of the relationship qualitative data, quantitative data in  general statistics","The disjunction between nature and science is studied, together with the needto modify the conception of natural science vs artificial science, related tothe perspective of objectivity and subjectivity, to end with the explanation ofthe process of polarization of methodologies and the relationship between mixeddata, as a possibility of unification of qualitative and quantitative data,through relationships and correlations.",Jhon Jairo Mosquera Rodas,2022-12-10T02:07:16Z,2022-12-10T02:07:16Z,"10 pages, 5 digits, Scientific article on general statistics",physics.soc-ph,http://arxiv.org/pdf/2212.05179v1,eng,,,Medicine
207,http://arxiv.org/abs/2307.08461v3,Towards eXplainable AI for Mobility Data Science,"This paper presents our ongoing work towards XAI for Mobility Data Scienceapplications, focusing on explainable models that can learn from densetrajectory data, such as GPS tracks of vehicles and vessels using temporalgraph neural networks (GNNs) and counterfactuals. We review the existing GeoXAIstudies, argue the need for comprehensible explanations with human-centeredapproaches, and outline a research path toward XAI for Mobility Data Science.","Anahid Jalali, Anita Graser, Clemens Heistracher",2023-07-17T13:06:33Z,2023-09-07T06:50:38Z,4 pages,cs.AI,http://arxiv.org/pdf/2307.08461v3,eng,,,Computer Science
208,http://arxiv.org/abs/2108.06001v1,HPTMT Parallel Operators for High Performance Data Science & Data  Engineering,"Data-intensive applications are becoming commonplace in all sciencedisciplines. They are comprised of a rich set of sub-domains such as dataengineering, deep learning, and machine learning. These applications are builtaround efficient data abstractions and operators that suit the applications ofdifferent domains. Often lack of a clear definition of data structures andoperators in the field has led to other implementations that do not work welltogether. The HPTMT architecture that we proposed recently, identifies a set ofdata structures, operators, and an execution model for creating rich dataapplications that links all aspects of data engineering and data sciencetogether efficiently. This paper elaborates and illustrates this architectureusing an end-to-end application with deep learning and data engineering partsworking together.","Vibhatha Abeykoon, Supun Kamburugamuve, Chathura Widanage, Niranda Perera, Ahmet Uyar, Thejaka Amila Kanewala, Gregor von Laszewski, Geoffrey Fox",2021-08-13T00:05:43Z,2021-08-13T00:05:43Z,,cs.DC,http://arxiv.org/pdf/2108.06001v1,eng,,,Computer Science
209,http://arxiv.org/abs/2112.00833v3,AWESOME: Empowering Scalable Data Science on Social Media Data with an  Optimized Tri-Store Data System,"Modern data science applications increasingly use heterogeneous data sourcesand analytics. This has led to growing interest in polystore systems,especially analytical polystores. In this work, we focus on emerging multi-datamodel analytics workloads over social media data that fluidly straddlerelational, graph, and text analytics. Instead of a generic polystore, we builda ""tri-store"" system that is more aware of the underlying data models to betteroptimize execution to improve scalability and runtime efficiency. We name oursystem AWESOME (Analytics WorkbEnch for SOcial MEdia). It features a powerfuldomain-specific language named ADIL. ADIL builds on top of underlying queryengines (e.g., SQL and Cypher) and features native data types for succinctlyspecifying cross-engine queries and NLP operations, as well as automaticin-memory and query optimizations. Using real-world tri-model analyticalworkloads and datasets, we empirically demonstrate the functionalities ofAWESOME for scalable data science over social media data and evaluate itsefficiency.","Xiuwen Zheng, Subhasis Dasgupta, Arun Kumar, Amarnath Gupta",2021-12-01T21:24:42Z,2022-07-16T00:50:12Z,,cs.DB,http://arxiv.org/pdf/2112.00833v3,eng,,,Social Sciences
210,http://arxiv.org/abs/2208.07910v1,"When, Where, and How to Open Data: A Personal Perspective","This is a personal perspective on data sharing in the context of public datareleases suitable for generic analysis. These open data can be a powerful toolfor expanding the science of high energy physics, but care must be taken inwhen, where, and how they are utilized. I argue that data preservation evenwithin collaborations needs additional support in order to maximize our sciencepotential. Additionally, it should also be easier for non-collaboration membersto engage with collaborations. Finally, I advocate that we recognize a new typeof high energy physicist: the 'data physicist', who would be optimally suitedto analyze open data as well as develop and deploy new advanced data sciencetools so that we can use our precious data to their fullest potential.  This document has been coordinated with a white paper on open datacommissioned by the American Physical Society's (APS) Division of Particles andField (DPS) Community Planning Exercise ('Snowmass') Theory Frontier [1] andrelevant also for the Computational Frontier.",Benjamin Nachman,2022-08-16T18:53:29Z,2022-08-16T18:53:29Z,"11 pages, 2 figures, contribution to Snowmass 2021",hep-ph,http://arxiv.org/pdf/2208.07910v1,eng,,,Social Sciences
211,http://arxiv.org/abs/2401.14816v1,Unleashing Data Journalism's Potential: COVID-19 as Catalyst for  Newsroom Transformation,"In the context of journalism, the COVID-19 pandemic brought unprecedentedchallenges, necessitating rapid adaptations in newsrooms. Data journalismemerged as a pivotal approach for effectively conveying complex information tothe public. Here, we show the profound impact of COVID-19 on data journalism,revealing a surge in data-driven publications and heightened collaborationbetween data and science journalists. Employing a quantitative methodology,including negative binomial regression and Relational hyperevent models (RHEM),on byline data of articles co-authored by data journalists, we comprehensivelyanalyze data journalism outputs, authorship trends, and collaboration networksto address five key research questions.  The findings reveal a significant increase in data journalistic pieces duringand after the pandemic, in particular with a rise in publications withinscientific departments. Collaborative efforts among data and sciencejournalists intensified, evident through increased authorship and co-authorshiptrends. Prior common authorship experiences somewhat influenced the likelihoodof future co-authorships, underscoring the importance of building collaborativecommunities of practice.  These quantitative insights provide an understanding of the transformationalrole of data journalism during COVID-19, contributing to the growing body ofliterature in computational communication science and journalism practice.","Benedict Witzenberger, Jürgen Pfeffer",2024-01-26T12:39:54Z,2024-01-26T12:39:54Z,"22 pages, 3 figures, 3 tables",cs.SI,http://arxiv.org/pdf/2401.14816v1,eng,,,Social Sciences
212,http://arxiv.org/abs/2302.08477v1,How and Why do Researchers Reference Data? A Study of Rhetorical  Features and Functions of Data References in Academic Articles,"Data reuse is a common practice in the social sciences. While published dataplay an essential role in the production of social science research, they arenot consistently cited, which makes it difficult to assess their full scholarlyimpact and give credit to the original data producers. Furthermore, it can bechallenging to understand researchers' motivations for referencing data. Likereferences to academic literature, data references perform various rhetoricalfunctions, such as paying homage, signaling disagreement, or drawingcomparisons. This paper studies how and why researchers reference socialscience data in their academic writing. We develop a typology to modelrelationships between the entities that anchor data references, along withtheir features (access, actions, locations, styles, types) and functions(critique, describe, illustrate, interact, legitimize). We illustrate the useof the typology by coding multidisciplinary research articles (n=30)referencing social science data archived at the Inter-university Consortium forPolitical and Social Research (ICPSR). We show how our typology capturesresearchers' interactions with data and purposes for referencing data. Ourtypology provides a systematic way to document and analyze researchers'narratives about data use, extending our ability to give credit to data thatsupport research.","Sara Lafia, Andrea Thomer, Elizabeth Moss, David Bleckley, Libby Hemphill",2023-02-16T18:35:31Z,2023-02-16T18:35:31Z,"35 pages, 2 appendices, 1 table",cs.DL,http://arxiv.org/pdf/2302.08477v1,eng,,,Computer Science
213,http://arxiv.org/abs/2311.16712v1,Onedata4Sci: Life science data management solution based on Onedata,"Life-science experimental methods generate vast and ever-increasing volumesof data, which provide highly valuable research resources. However, managementof these data is nontrivial and applicable software solutions are currentlysubject to intensive development. The solutions mainly fall into one of the twogroups: general data management systems (e.g. Onedata, iRODS, B2SHARE, CERNBox)or very specialised data management solutions (e.g. solutions for biomolecularsimulation data, biological imaging data, genomic data).  To bridge this gap between them, we provide Onedata4Sci, a prototype datamanagement solution, which is focused on the management of life science dataand covers four key steps of the data life cycle, i.e. data acquisition, useraccess, computational processing and archiving. Onedata4Sci is based on theOnedata data management system. It is written in Python, fully containerised,with the support for processing the stored data in Kubernetes. Theapplicability of Onedata4Sci is shown in three distinct use cases -- plantimaging data, cellular imaging data, and cryo-electron microscopy data. Despitethe use cases covering very different types of data and user patterns,Onedata4Sci demonstrated an ability to successfully handle all theseconditions. Complete source codes of Onedata4Sci are available on GitHub(https://github.com/CERIT-SC/onedata4sci), and its documentation and manual forinstallation are also provided.","Tomáš Svoboda, Tomáš Raček, Josef Handl, Jozef Sabo, Adrián Rošinec, Łukasz Opioła, Wojciech Jesionek, Milan Ešner, Markéta Pernisová, Natallia Madzia Valasevich, Aleš Křenek, Radka Svobodová",2023-11-28T11:52:35Z,2023-11-28T11:52:35Z,,q-bio.QM,http://arxiv.org/pdf/2311.16712v1,eng,,,Computer Science
214,http://arxiv.org/abs/2311.03292v4,Data Science from 1963 to 2012,"Consensus on the definition of data science remains low despite thewidespread establishment of academic programs in the field and continued demandfor data scientists in industry. Definitions range from rebranded statistics todata-driven science to the science of data to simply the application of machinelearning to so-called big data to solve real-world problems. Current efforts totrace the history of the field in order to clarify its definition, such asDonoho's ""50 Years of Data Science"" (Donoho 2017), tend to focus on a shortperiod when a small group of statisticians adopted the term in an unsuccessfulattempt to rebrand their field in the face of the overshadowing effects ofcomputational statistics and data mining. Using textual evidence from primarysources, this essay traces the history of the term to the 1960s, when it wasfirst used by the US Air Force in a surprisingly similar way to its currentusage, to 2012, the year that Harvard Business Review published the enormouslyinfluential article ""Data Scientist: The Sexiest Job of the 21st Century""(Davenport and Patil 2012) and the American Statistical Associationacknowledged a profound disconnect between statistics and data science(Rodriguez 2012). Among the themes that emerge from this review are (1) thelong-standing opposition between data analysts and data miners that continuesto animate the field, (2) an established definition of the term as the practiceof managing and processing scientific data that has been occluded by recentusage, and (3) the phenomenon of data impedance -- the disproportion betweensurplus data, indexed by phrases like data deluge and big data, and thelimitations of computational machinery and methods to process them. Thispersistent condition appears to have motivated the use of the term and thefield itself since its beginnings.",Rafael C. Alvarado,2023-11-06T17:35:35Z,2024-10-22T17:57:48Z,48 pages,cs.GL,http://arxiv.org/pdf/2311.03292v4,eng,,,Physics and Astronomy
215,http://arxiv.org/abs/1212.2071v1,A Data Warehouse Design for a Typical University Information System,"Presently, large enterprises rely on database systems to manage their dataand information. These databases are useful for conducting daily businesstransactions. However, the tight competition in the marketplace has led to theconcept of data mining in which data are analyzed to derive effective businessstrategies and discover better ways in carrying out business. In order toperform data mining, regular databases must be converted into what so calledinformational databases also known as data warehouse. This paper presents adesign model for building data warehouse for a typical university informationsystem. It is based on transforming an operational database into aninformational warehouse useful for decision makers to conduct data analysis,predication, and forecasting. The proposed model is based on four stages ofdata migration: Data extraction, data cleansing, data transforming, and dataindexing and loading. The complete system is implemented under MS Access 2010and is meant to serve as a repository of data for data mining operations.",Youssef Bassil,2012-12-10T14:09:03Z,2012-12-10T14:09:03Z,"LACSC - Lebanese Association for Computational Sciences,
  http://www.lacsc.org",cs.DB,http://arxiv.org/pdf/1212.2071v1,eng,,,Computer Science
216,http://arxiv.org/abs/2311.12848v1,Lightweight Knowledge Representations for Automating Data Analysis,"The principal goal of data science is to derive meaningful information fromdata. To do this, data scientists develop a space of analytic possibilities andfrom it reach their information goals by using their knowledge of the domain,the available data, the operations that can be performed on those data, thealgorithms/models that are fed the data, and how all of these facetsinterweave. In this work, we take the first steps towards automating a keyaspect of the data science pipeline: data analysis. We present an extensibletaxonomy of data analytic operations that scopes across domains and data, aswell as a method for codifying domain-specific knowledge that links thisanalytics taxonomy to actual data. We validate the functionality of ouranalytics taxonomy by implementing a system that leverages it, alongside domainlabelings for 8 distinct domains, to automatically generate a space ofanswerable questions and associated analytic plans. In this way, we produceinformation spaces over data that enable complex analyses and search over thisdata and pave the way for fully automated data analysis.","Marko Sterbentz, Cameron Barrie, Donna Hooshmand, Shubham Shahi, Abhratanu Dutta, Harper Pack, Andong Li Zhao, Andrew Paley, Alexander Einarsson, Kristian Hammond",2023-10-15T06:44:45Z,2023-10-15T06:44:45Z,,cs.DB,http://arxiv.org/pdf/2311.12848v1,eng,,,Medicine
217,http://arxiv.org/abs/1612.04037v1,Proceedings 11th Doctoral Workshop on Mathematical and Engineering  Methods in Computer Science,"MEMICS provides a forum for doctoral students interested in applications ofmathematical and engineering methods in computer science. Besides a richtechnical programme (including invited talks, regular papers, andpresentations), MEMICS also offers friendly social activities and excitingopportunities for meeting like-minded people. MEMICS submissions traditionallycover all areas of computer science (such as parallel and distributedcomputing, computer networks, modern hardware and its design, non-traditionalcomputing architectures, information systems and databases, multimedia andgraphics, verification and testing, computer security, as well as all relatedareas of theoretical computer science).","Jan Bouda, Lukáš Holík, Jan Kofroň, Jan Strejček, Adam Rambousek",2016-12-13T05:47:19Z,2016-12-13T05:47:19Z,,cs.LO,http://arxiv.org/pdf/1612.04037v1,eng,,,Computer Science
218,http://arxiv.org/abs/2411.14579v1,Functional Array Programming in an Extended Pi-Calculus,"We study the data-parallel language BUTF, inspired by the Futhark languagefor array programming. We give a translation of BUTF into a version of thepi-calculus with broadcasting and labeled names. The translation is bothcomplete and sound. Moreover, we propose a cost model by annotating translatedBUTF processes. This is used for a complexity analysis of the translation.","Hans Hüttel, Lars Jensen, Chris Oliver Paulsen, Julian Teule",2024-11-21T20:46:23Z,2024-11-21T20:46:23Z,"In Proceedings EXPRESS/SOS 2024, arXiv:2411.13318",cs.PL,http://arxiv.org/pdf/2411.14579v1,eng,,,Medicine
219,http://arxiv.org/abs/2104.06527v1,Jupyter-Enabled Astrophysical Analysis for Researchers and Students,"The advent of increasingly large and complex datasets has fundamentallyaltered the way that scientists conduct astronomy research. The need to workclosely to the data has motivated the creation of online science platforms,which include a suite of software tools and services, therefore going beyonddata storage and data access. We present two example applications of Jupyter asa part of astrophysical science platforms for professional researchers andstudents. First, the Astro Data Lab is developed and operated by NOIRLab with amission to serve the astronomy community with now over 1500 registered users.Second, the Dark Energy Spectroscopic Instrument science platform serves itsgeographically distributed team comprising about 900 collaborators from over 90institutions. We describe the main uses of Jupyter and the interfaces thatneeded to be created to embed it within science platform ecosystems. We usethese examples to illustrate the broader concept of empowering researchers andproviding them with access to not only large datasets but also cutting-edgesoftware, tools, and data services without requiring any local installation,which can be relevant for a wide range of disciplines. Future advances mayinvolve science platform networks, and tools for simultaneously developingJupyter notebooks to facilitate collaborations.","Stéphanie Juneau, Knut A. G. Olsen, Robert Nikutta, Alice Jacques, Stephen Bailey",2021-04-13T21:57:23Z,2021-04-13T21:57:23Z,"13 pages, 4 figures. Accepted version. See Computing in Science and
  Engineering for the final published version: Jupyter-Enabled Astrophysical
  Analysis Using Data-Proximate Computing Platforms",astro-ph.IM,http://arxiv.org/pdf/2104.06527v1,eng,,,Social Sciences
220,http://arxiv.org/abs/1404.4140v1,Journey from Data Mining to Web Mining to Big Data,This paper describes the journey of big data starting from data mining to webmining to big data. It discusses each of this method in brief and also providestheir applications. It states the importance of mining big data today usingfast and novel approaches.,Richa Gupta,2014-04-16T05:20:28Z,2014-04-16T05:20:28Z,3 pages,cs.OH,http://arxiv.org/pdf/1404.4140v1,eng,,,Computer Science
221,http://arxiv.org/abs/2202.05163v2,"Machine Learning and Data Science: Foundations, Concepts, Algorithms,  and Tools","Today, data is a fuel for businesses to gain important insights and improvetheir performance. There is no industry in the world today that does not usedata. But who will get this insight? Who processes all the raw data? Everythingis done by a data analyst or a data scientist.",Milad Vazan,2022-02-03T08:30:02Z,2022-02-15T05:45:50Z,in Persian language,cs.LG,http://arxiv.org/pdf/2202.05163v2,eng,,,Social Sciences
222,http://arxiv.org/abs/2410.11562v1,Functional Data Analysis on Wearable Sensor Data: A Systematic Review,"Wearable devices and sensors have recently become a popular way to collectdata, especially in the health sciences. The use of sensors allows patients tobe monitored over a period of time with a high observation frequency. Due tothe continuous-on-time structure of the data, novel statistical methods arerecommended for the analysis of sensor data. One of the popular approaches inthe analysis of wearable sensor data is functional data analysis. The mainobjective of this paper is to review functional data analysis methods appliedto wearable device data according to the type of sensor. In addition, weintroduce several freely available software packages and open databases ofwearable device data to facilitate access to sensor data in different fields.","Nihan Acar-Denizli, Pedro Delicado",2024-10-15T12:51:11Z,2024-10-15T12:51:11Z,,stat.ME,http://arxiv.org/pdf/2410.11562v1,eng,,,Medicine
223,http://arxiv.org/abs/cs/0502011v1,Where the Rubber Meets the Sky: Bridging the Gap between Databases and  Science,"Scientists in all domains face a data avalanche - both from betterinstruments and from improved simulations. We believe that computer sciencetools and computer scientists are in a position to help all the sciences bybuilding tools and developing techniques to manage, analyze, and visualizepeta-scale scientific information. This article is summarizes our experiencesover the last seven years trying to bridge the gap between database technologyand the needs of the astronomy community in building the World-Wide Telescope.","Jim Gray, Alexander S. Szalay",2005-02-02T04:40:55Z,2005-02-02T04:40:55Z,,cs.DB,http://arxiv.org/pdf/cs/0502011v1,eng,,,Medicine
224,http://arxiv.org/abs/gr-qc/0303117v1,Gravitational Wave Detectors: A report from LIGO-land,"At the time of this conference, in June 2002, The LIGO Science Collaborationwas getting ready to perform its first Science Run, where data will be takenwith all three LIGO detectors. We describe here the status of the LIGOdetectors as of February 2003, their performance during the ``Engineering Run''E7 (Dec 28'01-Jan 14'02) and subsequent Science Runs in 2002/3. We alsodescribe ongoing efforts on data analysis for setting upper limits of differentgravitational wave sources.",Gabriela Gonzalez,2003-03-31T20:35:40Z,2003-03-31T20:35:40Z,"8 pages, 2 figures, to appear in Proceedings of NEB-X, tenth Greek
  relativity meeting",gr-qc,http://arxiv.org/pdf/gr-qc/0303117v1,eng,,,Medicine
225,http://arxiv.org/abs/1912.12591v1,SKA shakes hands with Summit,"Recently, a full-scale data processing workflow of the Square Kilometre Array(SKA) Phase 1 was successfully executed on the world's fastest supercomputerSummit, proving that scientists have the expertise, software tools andcomputing resources to process the SKA data. The SKA-Summit experiment showsthe importance of multidisciplinary cooperation between astronomy, computerscience and others communities. The SKA science cannot be achieved without thejoint efforts of talents from multiple fields.","Ruonan Wang, Andreas Wicenec, Tao An",2019-12-29T06:39:16Z,2019-12-29T06:39:16Z,Published in Science Bulletin,astro-ph.IM,http://arxiv.org/pdf/1912.12591v1,eng,,,Computer Science
226,http://arxiv.org/abs/2209.11605v1,The ESO Science Archive,"The ESO Science Archive is the collection and access point of the datagenerated at ESO's La Silla Paranal Observatory, both raw and processed. It isa major contributor to ESO's science output, being used in about 4 out of 10refereed articles with ESO data. In this paper, which is presented on behalf ofthe operations and development teams, we review its contents, policies, usinterfaces and impact.","Martino Romaniello, the ESO Science Archive operations, development team",2022-09-23T14:18:48Z,2022-09-23T14:18:48Z,SPIE Astronomical Telescopes + Instrumentation 2022,astro-ph.IM,http://arxiv.org/pdf/2209.11605v1,eng,,,Social Sciences
227,http://arxiv.org/abs/2210.13526v1,"Computational Inference in Cognitive Science: Operational, Societal and  Ethical Considerations","Emerging research frontiers and computational advances have graduallytransformed cognitive science into a multidisciplinary and data-driven field.As a result, there is a proliferation of cognitive theories investigated andinterpreted from different academic lens and in different levels ofabstraction. We formulate this applied aspect of this challenge as thecomputational cognitive inference, and describe the major routes ofcomputational approaches. To balance the potential optimism alongside the speedand scale of the data-driven era of cognitive science, we propose to inspectthis trend in more empirical terms by identifying the operational challenges,societal impacts and ethical guidelines in conducting research and interpretingresults from the computational inference in cognitive science.",Baihan Lin,2022-10-24T18:27:27Z,2022-10-24T18:27:27Z,,q-bio.NC,http://arxiv.org/pdf/2210.13526v1,eng,,,Physics and Astronomy
228,http://arxiv.org/abs/2311.10833v1,Generative AI has lowered the barriers to computational social sciences,"Generative artificial intelligence (AI) has revolutionized the field ofcomputational social science, unleashing new possibilities for analyzingmultimodal data, especially for scholars who may not have extensive programmingexpertise. This breakthrough carries profound implications for the realm ofsocial sciences. Firstly, generative AI can significantly enhance theproductivity of social scientists by automating the generation, annotation, anddebugging of code. Secondly, it empowers researchers to delve intosophisticated data analysis through the innovative use of prompt engineering.Lastly, the educational sphere of computational social science stands tobenefit immensely from these tools, given their exceptional ability to annotateand elucidate complex codes for learners, thereby simplifying the learningprocess and making the technology more accessible.",Yongjun Zhang,2023-11-17T19:24:39Z,2023-11-17T19:24:39Z,,cs.HC,http://arxiv.org/pdf/2311.10833v1,eng,,,Social Sciences
229,http://arxiv.org/abs/2011.08498v1,Political Partisanship and Anti-Science Attitudes in Online Discussions  about Covid-19,"The novel coronavirus pandemic continues to ravage communities across the US.Opinion surveys identified importance of political ideology in shapingperceptions of the pandemic and compliance with preventive measures. Here, weuse social media data to study complexity of polarization. We analyze a largedataset of tweets related to the pandemic collected between January and May of2020, and develop methods to classify the ideological alignment of users alongthe moderacy (hardline vs moderate), political (liberal vs conservative) andscience (anti-science vs pro-science) dimensions. While polarization along thescience and political dimensions are correlated, politically moderate users aremore likely to be aligned with the pro-science views, and politically hardlineusers with anti-science views. Contrary to expectations, we do not find thatpolarization grows over time; instead, we see increasing activity by moderatepro-science users. We also show that anti-science conservatives tend to tweetfrom the Southern US, while anti-science moderates from the Western states. Ourfindings shed light on the multi-dimensional nature of polarization, and thefeasibility of tracking polarized opinions about the pandemic across time andspace through social media data.","Ashwin Rao, Fred Morstatter, Minda Hu, Emily Chen, Keith Burghardt, Emilio Ferrara, Kristina Lerman",2020-11-17T08:22:20Z,2020-11-17T08:22:20Z,"10 pages, 5 figures",cs.SI,http://arxiv.org/pdf/2011.08498v1,eng,,,Medicine
230,http://arxiv.org/abs/2012.02650v1,"Getting Ready for LISA: The Data, Support and Preparation Needed to  Maximize US Participation in Space-Based Gravitational Wave Science","The NASA LISA Study Team was tasked to study how NASA might support USscientists to participate and maximize the science return from the LaserInterferometer Space Antenna (LISA) mission. LISA is gravitational waveobservatory led by ESA with NASA as a junior partner, and is scheduled tolaunch in 2034. Among our findings: LISA science productivity is greatlyenhanced by a full-featured US science center and an open access data model. Asother major missions have demonstrated, a science center acts as both a locusand an amplifier of research innovation, data analysis, user support, usertraining and user interaction. In its most basic function, a US Science Centercould facilitate entry into LISA science by hosting a Data Processing Centerand a portal for the US community to access LISA data products. However, anenhanced LISA Science Center could: support one of the parallel independentprocessing pipelines required for data product validation; stimulate the highlevel of research on data analysis that LISA demands; support users unfamiliarwith a novel observatory; facilitate astrophysics and fundamental research;provide an interface into the subtleties of the instrument to validateextraordinary discoveries; train new users; and expand the research communitythrough guest investigator, postdoc and student programs. Establishing a USLISA Science Center well before launch can have a beneficial impact on theparticipation of the broader astronomical community by providing training,hosting topical workshops, disseminating mock catalogs, software pipelines, anddocumentation. Past experience indicates that successful science centers areestablished several years before launch; this early adoption model may beespecially relevant for a pioneering mission like LISA.","Kelly Holley-Bockelmann, :, Jillian Bellovary, Peter Bender, Emanuele Berti, Warren Brown, Robert Caldwell, Neil Cornish, Jeremy Darling, Matthew Digman, Mike Eracleous, Kayhan Gultekin, Zoltan Haiman, Kelly Holley-Bockelmann, Joey Key, Shane Larson, Xin Liu, Sean McWilliams, Priyamvada Natarajan, David Shoemaker, Deirdre Shoemaker, Krista Lynne Smith, Marcelle Soares-Santos, Robin Stebbins",2020-12-04T15:15:14Z,2020-12-04T15:15:14Z,"93 pages with a lovely cover page thanks to Bernard Kelly and
  Elizabeth Ferrara",astro-ph.IM,http://arxiv.org/pdf/2012.02650v1,eng,,,Computer Science
231,http://arxiv.org/abs/2006.12630v1,An extensive analysis of the presence of altmetric data for Web of  Science publications across subject fields and research topics,"Sufficient data presence is one of the key preconditions for applying metricsin practice. Based on both Altmetric.com data and Mendeley data collected up to2019, this paper presents a state-of-the-art analysis of the presence of 12kinds of altmetric events for nearly 12.3 million Web of Science publicationspublished between 2012 and 2018. Results show that even though an upward trendof data presence can be observed over time, except for Mendeley readers andTwitter mentions, the overall presence of most altmetric data is still low. Themajority of altmetric events go to publications in the fields of Biomedical andHealth Sciences, Social Sciences and Humanities, and Life and Earth Sciences.As to research topics, the level of attention received by research topicsvaries across altmetric data, and specific altmetric data show differentpreferences for research topics, on the basis of which a framework foridentifying hot research topics is proposed and applied to detect researchtopics with higher levels of attention garnered on certain altmetric datasource. Twitter mentions and policy document citations were selected as twoexamples to identify hot research topics of interest of Twitter users andpolicy-makers, respectively, shedding light on the potential of altmetric datain monitoring research trends of specific social attention.","Zhichao Fang, Rodrigo Costas, Wencan Tian, Xianwen Wang, Paul Wouters",2020-06-22T21:33:35Z,2020-06-22T21:33:35Z,,cs.DL,http://arxiv.org/pdf/2006.12630v1,eng,,,Medicine
232,http://arxiv.org/abs/2211.09259v2,The Missing Indicator Method: From Low to High Dimensions,"Missing data is common in applied data science, particularly for tabular datasets found in healthcare, social sciences, and natural sciences. Mostsupervised learning methods only work on complete data, thus requiringpreprocessing such as missing value imputation to work on incomplete data sets.However, imputation alone does not encode useful information about the missingvalues themselves. For data sets with informative missing patterns, the MissingIndicator Method (MIM), which adds indicator variables to indicate the missingpattern, can be used in conjunction with imputation to improve modelperformance. While commonly used in data science, MIM is surprisinglyunderstudied from an empirical and especially theoretical perspective. In thispaper, we show empirically and theoretically that MIM improves performance forinformative missing values, and we prove that MIM does not hurt linear modelsasymptotically for uninformative missing values. Additionally, we find that forhigh-dimensional data sets with many uninformative indicators, MIM can inducemodel overfitting and thus test performance. To address this issue, weintroduce Selective MIM (SMIM), a novel MIM extension that adds missingindicators only for features that have informative missing patterns. We showempirically that SMIM performs at least as well as MIM in general, and improvesMIM for high-dimensional data. Lastly, to demonstrate the utility of MIM onreal-world data science tasks, we demonstrate the effectiveness of MIM and SMIMon clinical tasks generated from the MIMIC-III database of electronic healthrecords.","Mike Van Ness, Tomas M. Bosschieter, Roberto Halpin-Gregorio, Madeleine Udell",2022-11-16T23:10:45Z,2023-02-04T02:44:05Z,,cs.LG,http://arxiv.org/pdf/2211.09259v2,eng,,,Computer Science
233,http://arxiv.org/abs/2410.20424v3,AutoKaggle: A Multi-Agent Framework for Autonomous Data Science  Competitions,"Data science tasks involving tabular data present complex challenges thatrequire sophisticated problem-solving approaches. We propose AutoKaggle, apowerful and user-centric framework that assists data scientists in completingdaily data pipelines through a collaborative multi-agent system. AutoKaggleimplements an iterative development process that combines code execution,debugging, and comprehensive unit testing to ensure code correctness and logicconsistency. The framework offers highly customizable workflows, allowing usersto intervene at each phase, thus integrating automated intelligence with humanexpertise. Our universal data science toolkit, comprising validated functionsfor data cleaning, feature engineering, and modeling, forms the foundation ofthis solution, enhancing productivity by streamlining common tasks. We selected8 Kaggle competitions to simulate data processing workflows in real-worldapplication scenarios. Evaluation results demonstrate that AutoKaggle achievesa validation submission rate of 0.85 and a comprehensive score of 0.82 intypical data science pipelines, fully proving its effectiveness andpracticality in handling complex data science tasks.","Ziming Li, Qianbo Zang, David Ma, Jiawei Guo, Tuney Zheng, Minghao Liu, Xinyao Niu, Yue Wang, Jian Yang, Jiaheng Liu, Wanjun Zhong, Wangchunshu Zhou, Wenhao Huang, Ge Zhang",2024-10-27T12:44:25Z,2024-11-05T19:46:38Z,"44 pages, 10 figures",cs.AI,http://arxiv.org/pdf/2410.20424v3,eng,,,Computer Science
234,http://arxiv.org/abs/1811.08272v1,Science Pipelines for the Square Kilometre Array,"The Square Kilometre Array (SKA) will be both the largest radio telescopeever constructed and the largest Big Data project in the known Universe. Thefirst phase of the project will generate on the order of 5 zettabytes of dataper year. A critical task for the SKA will be its ability to process data forscience, which will need to be conducted by science pipelines. Together withpolarization data from the LOFAR Multifrequency Snapshot Sky Survey (MSSS), wehave been developing a realistic SKA-like science pipeline that can handle thelarge data volumes generated by LOFAR at 150 MHz. The pipeline uses task-basedparallelism to image, detect sources, and perform Faraday Tomography across theentire LOFAR sky. The project thereby provides a unique opportunity tocontribute to the technological development of the SKA telescope, whilesimultaneously enabling cutting-edge scientific results. In this paper, weprovide an update on current efforts to develop a science pipeline that canenable tight constraints on the magnetised large-scale structure of theUniverse.","Jamie Farnes, Ben Mort, Fred Dulwich, Stef Salvini, Wes Armour",2018-11-20T14:39:10Z,2018-11-20T14:39:10Z,"Published in Galaxies, as part of a Special Issue on The Power of
  Faraday Tomography",astro-ph.IM,http://arxiv.org/pdf/1811.08272v1,eng,,,Medicine
235,http://arxiv.org/abs/1910.14436v1,How can AI Automate End-to-End Data Science?,"Data science is labor-intensive and human experts are scarce but heavilyinvolved in every aspect of it. This makes data science time consuming andrestricted to experts with the resulting quality heavily dependent on theirexperience and skills. To make data science more accessible and scalable, weneed its democratization. Automated Data Science (AutoDS) is aimed towards thatgoal and is emerging as an important research and business topic. We introduceand define the AutoDS challenge, followed by a proposal of a general AutoDSframework that covers existing approaches but also provides guidance for thedevelopment of new methods. We categorize and review the existing literaturefrom multiple aspects of the problem setup and employed techniques. Then weprovide several views on how AI could succeed in automating end-to-end AutoDS.We hope this survey can serve as insightful guideline for the AutoDS field andprovide inspiration for future research.","Charu Aggarwal, Djallel Bouneffouf, Horst Samulowitz, Beat Buesser, Thanh Hoang, Udayan Khurana, Sijia Liu, Tejaswini Pedapati, Parikshit Ram, Ambrish Rawat, Martin Wistuba, Alexander Gray",2019-10-22T12:54:48Z,2019-10-22T12:54:48Z,,cs.AI,http://arxiv.org/pdf/1910.14436v1,eng,,,Medicine
236,http://arxiv.org/abs/2305.06213v1,"Motivation, inclusivity, and realism should drive data science education","Data science education provides tremendous opportunities but remainsinaccessible to many communities. Increasing the accessibility of data scienceto these communities not only benefits the individuals entering data science,but also increases the field's innovation and potential impact as a whole.Education is the most scalable solution to meet these needs, but many datascience educators lack formal training in education. Our group has lededucation efforts for a variety of audiences: from professional scientists tohigh school students to lay audiences. These experiences have helped form ourteaching philosophy which we have summarized into three main ideals: 1)motivation, 2) inclusivity, and 3) realism. To put these ideals better intopractice, we also aim to iteratively update our teaching approaches andcurriculum as we find ways to better reach these ideals. In this manuscript wediscuss these ideals as well practical ideas for how to implement thesephilosophies in the classroom.","Candace Savonen, Carrie Wright, Ava M. Hoffman, Elizabeth M. Humphries, Katherine E. L. Cox, Frederick J. Tan, Jeffrey T. Leek",2023-05-09T17:46:41Z,2023-05-09T17:46:41Z,This has been submitted to F1000 and is under review (as of 5/9/23),cs.CY,http://arxiv.org/pdf/2305.06213v1,eng,,,Social Sciences
237,http://arxiv.org/abs/2309.10894v3,A Novel Gradient Methodology with Economical Objective Function  Evaluations for Data Science Applications,"Gradient methods are experiencing a growth in methodological and theoreticaldevelopments owing to the challenges posed by optimization problems arising indata science. However, such gradient methods face diverging optimality gaps orexploding objective evaluations when applied to optimization problems withrealistic properties for data science applications. In this work, we addressthis gap by developing a generic methodology that economically uses objectivefunction evaluations in a problem-driven manner to prevent optimality gapdivergence and avoid explosions in objective evaluations. Our methodologyallows for a variety of step size routines and search direction strategies.Furthermore, we develop a particular, novel step size selection methodologythat is well-suited to our framework. We show that our specific procedure ishighly competitive with standard optimization methods on CUTEst test problems.We then show our specific procedure is highly favorable relative to standardoptimization methods on a particularly tough data science problem: learning theparameters in a generalized estimating equation model. Thus, we provide a novelgradient methodology that is better suited to optimization problems from thisimportant class of data science applications.","Christian Varner, Vivak Patel",2023-09-19T19:36:24Z,2024-04-16T14:11:25Z,"24 pages, 7 figures, 3 tables, 3 algorithms",math.OC,http://arxiv.org/pdf/2309.10894v3,eng,,,Computer Science
238,http://arxiv.org/abs/1904.07989v2,COMBIgor: data analysis package for combinatorial materials science,"Combinatorial experiments involve synthesis of sample libraries with lateralcomposition gradients requiring spatially-resolved characterization ofstructure and properties. Due to maturation of combinatorial methods and theirsuccessful application in many fields, the modern combinatorial laboratoryproduces diverse and complex data sets requiring advanced analysis andvisualization techniques. In order to utilize these large data sets to uncovernew knowledge, the combinatorial scientist must engage in data science. Fordata science tasks, most laboratories adopt common-purpose data management andvisualization software. However, processing and cross-correlating data fromvarious measurement tools is no small task for such generic programs. Here wedescribe COMBIgor, a purpose-built open-source software package written in thecommercial Igor Pro environment, designed to offer a systematic approach toloading, storing, processing, and visualizing combinatorial data sets. Itincludes (1) methods for loading and storing data sets from combinatoriallibraries, (2) routines for streamlined data processing, and (3) data analysisand visualization features to construct figures. Most importantly, COMBIgor isdesigned to be easily customized by a laboratory, group, or individual in orderto integrate additional instruments and data-processing algorithms. Utilizingthe capabilities of COMBIgor can significantly reduce the burden of datamanagement on the combinatorial scientist.","Kevin R. Talley, Sage R. Bauers, Celeste L. Melamed, Meagan C. Papac, Karen Heinselman, Imran Khan, Dennice M. Roberts, Valerie Jacobson, Allison Mis, Geoff L. Brennecka, John D. Perkins, Andriy Zakutayev",2019-04-16T21:16:17Z,2019-04-30T19:15:31Z,,cond-mat.mtrl-sci,http://arxiv.org/pdf/1904.07989v2,eng,,,Computer Science
239,http://arxiv.org/abs/1406.2015v1,MOOCdb: Developing Standards and Systems to Support MOOC Data Science,"We present a shared data model for enabling data science in Massive OpenOnline Courses (MOOCs). The model captures students interactions with theonline platform. The data model is platform agnostic and is based on some basiccore actions that students take on an online learning platform. Studentsusually interact with the platform in four different modes: Observing,Submitting, Collaborating and giving feedback. In observing mode students aresimply browsing the online platform, watching videos, reading material, readingbook or watching forums. In submitting mode, students submit information to theplatform. This includes submissions towards quizzes, homeworks, or anyassessment modules. In collaborating mode students interact with other studentsor instructors on forums, collaboratively editing wiki or chatting on googlehangout or other hangout venues. With this basic definitions of activities, anda data model to store events pertaining to these activities, we then create acommon terminology to map Coursera and edX data into this shared data model.This shared data model called MOOCdb becomes the foundation for a number ofcollaborative frameworks that enable progress in data science without the needto share the data.","Kalyan Veeramachaneni, Sherif Halawa, Franck Dernoncourt, Una-May O'Reilly, Colin Taylor, Chuong Do",2014-06-08T19:19:45Z,2014-06-08T19:19:45Z,,cs.IR,http://arxiv.org/pdf/1406.2015v1,eng,,,Social Sciences
240,http://arxiv.org/abs/2209.15390v1,Deploying a sharded MongoDB cluster as a queued job on a shared HPC  architecture,"Data stores are the foundation on which data science, in all its variations,is built upon. They provide a queryable interface to structured andunstructured data. Data science often starts by leveraging these query featuresto perform initial data preparation. However, most data stores are designed torun continuously to service disparate user requests with little or no downtime.Many HPC architectures process user requests by job queue scheduler andmaintain a shard filesystem to store a jobs persistent data. We deploy aMongoDB sharded cluster with a run script that is designed to run a datascience workload concurrently. As our test piece, we run data ingest and dataqueries to measure the performance with different configurations on the BlueWaters supper computer.","Aaron Saxton, Stephen Squaire",2022-09-06T17:07:12Z,2022-09-06T17:07:12Z,,cs.DC,http://arxiv.org/pdf/2209.15390v1,eng,,,Medicine
241,http://arxiv.org/abs/cond-mat/0305112v1,Analysis and modeling of science collaboration networks,"We analyze a science collaboration network, i.e. a network whose nodes arescientists with edges connecting them for each paper published together.Furthermore we develop a model for the simulation of discontiguous small-worldnetworks that shows good coherence with the empirical data.",Felix Putsch,2003-05-06T15:04:12Z,2003-05-06T15:04:12Z,10 pages including 6 figures,cond-mat.stat-mech,http://arxiv.org/pdf/cond-mat/0305112v1,eng,,,Engineering
242,http://arxiv.org/abs/gr-qc/0310049v1,Binary Neutron Star Inspiral Search in LIGO S1,"We describe the search for gravitational waves from inspiraling neutron starbinary systems, using data from the first Scientific Run of the LIGO ScienceCollaboration.",Gabriela González,2003-10-08T17:55:51Z,2003-10-08T17:55:51Z,,gr-qc,http://arxiv.org/pdf/gr-qc/0310049v1,eng,,,Engineering
243,http://arxiv.org/abs/solv-int/9804001v1,On lump instability of Davey--Stewartson II equation,We show that lumps (solitons) of the Davey--Stewartson II equation fail undersmall perturbations of initial data.,"R. R. Gadyl'shin, O. M. Kiselev",1998-03-31T16:49:37Z,1998-03-31T16:49:37Z,"Amstex, 9 pages",solv-int,http://arxiv.org/pdf/solv-int/9804001v1,eng,,,Biochemistry
244,http://arxiv.org/abs/solv-int/9912011v1,Liouville equation under perturbation,Small perturbation of the Liouville equation under smooth initial data isconsidered. Asymptotic solution which is available for a long time interval isconstructed by the two scale method.,L. A. Kalyakin,1999-12-16T16:05:14Z,1999-12-16T16:05:14Z,5 pages,solv-int,http://arxiv.org/pdf/solv-int/9912011v1,eng,,,Medicine
245,http://arxiv.org/abs/1108.3466v1,Rejoinder,"Rejoinder of ""Calibrated Bayes, for Statistics in General, and Missing Datain Particular"" by R. Little [arXiv:1108.1917]",Roderick Little,2011-08-17T12:30:30Z,2011-08-17T12:30:30Z,"Published in at http://dx.doi.org/10.1214/10-STS318REJ the
  Statistical Science (http://www.imstat.org/sts/) by the Institute of
  Mathematical Statistics (http://www.imstat.org)",stat.ME,http://arxiv.org/pdf/1108.3466v1,eng,,,Medicine
246,http://arxiv.org/abs/1805.06516v1,Dependence upon initial conditions,This article discusses dependence on initial conditions in natural and socialsciences with focus on physical science. The main focus is on the newlydiscovered rough dependence on initial data.,Y. Charles Li,2018-05-16T20:37:31Z,2018-05-16T20:37:31Z,,nlin.CD,http://arxiv.org/pdf/1805.06516v1,eng,,,Social Sciences
247,http://arxiv.org/abs/2301.05554v1,Synergies Between Operations Research and Quantum Information Science,This article highlights synergies between quantum information science (QIS)and operations research for QIS-curious operations researchers (andvice-versa).,Ojas Parekh,2023-01-11T22:57:01Z,2023-01-11T22:57:01Z,"12 pages; published as a ""Challenge Paper"" in the INFORMS Journal on
  Computing",quant-ph,http://arxiv.org/pdf/2301.05554v1,eng,,,Social Sciences
248,http://arxiv.org/abs/astro-ph/0008307v1,Science User Scenarios for a Virtual Observatory Design Reference  Mission: Science Requirements for Data Mining,"The knowledge discovery potential of the new large astronomical databases isvast. When these are used in conjunction with the rich legacy data archives,the opportunities for scientific discovery multiply rapidly. A VirtualObservatory (VO) framework will enable transparent and efficient access,search, retrieval, and visualization of data across multiple data repositories,which are generally heterogeneous and distributed. Aspects of data mining thatapply to a variety of science user scenarios with a VO are reviewed. Thedevelopment of a VO should address the data mining needs of variousastronomical research constituencies. By way of example, two user scenarios arepresented which invoke applications and linkages of data across the catalog andimage domains in order to address specific astrophysics research problems.These illustrate a subset of the desired capabilities and power of the VO, andas such they represent potential components of a VO Design Reference Mission.",Kirk D. Borne,2000-08-19T17:54:01Z,2000-08-19T17:54:01Z,"4 pages. Paper to appear in the proceedings of the June 2000 ""Virtual
  Observatories of the Future"" conference at Caltech, edited by R. J. Brunner,
  S. G. Djorgovski, & A. Szalay. (For figures and demos related to sample user
  scenarios, see
  http://adc.gsfc.nasa.gov/adc/adc_science/adc-science-scenario-papers.html .)",astro-ph,http://arxiv.org/pdf/astro-ph/0008307v1,eng,,,Computer Science
249,http://arxiv.org/abs/1311.0562v2,LP Mixed Data Science : Outline of Theory,"This article presents the theoretical foundation of a new frontier ofresearch-`LP Mixed Data Science'-that simultaneously extends and integrates thepractice of traditional and novel statistical methods for nonparametricexploratory data modeling, and is applicable to the teaching and training ofstatistics.  Statistics journals have great difficulty accepting papers unlike thosepreviously published. For statisticians with new big ideas a practical strategyis to publish them in many small applied studies which enables one to providereferences to work of others. This essay outlines the many concepts, newtheory, and important algorithms of our new culture of statistical sciencecalled LP MIXED DATA SCIENCE. It provides comprehensive solutions to problemsof data analysis and nonparametric modeling of many variables that arecontinuous or discrete, which does not yet have a large literature. It developsa new modeling approach to nonparametric estimation of the multivariate copuladensity. We discuss the theory which we believe is very elegant (and canprovide a framework for United Statistical Algorithms, for traditional SmallData methods and Big Data methods).","Emanuel Parzen, Subhadeep Mukhopadhyay",2013-11-04T01:56:04Z,2013-11-06T13:44:49Z,,math.ST,http://arxiv.org/pdf/1311.0562v2,eng,,,Computer Science
250,http://arxiv.org/abs/1810.04606v2,Building an Ontology for the Domain of Plant Science using Protégé,"Due to the rapid development of technology, large amounts of heterogeneousdata generated every day. Biological data is also growing in terms of thequantity and quality of data considerably. Despite the attempts for building auniform platform to handle data management in Plant Science, researchers arefacing the challenge of not only accessing and integrating data stored inheterogeneous data sources but also representing the implicit and explicitdomain knowledge based on the available plant genomic and phenomic data.Ontologies provide a framework for describing the structures and vocabulariesto support the semantics of information and facilitate automated reasoning andknowledge discovery. In this paper, we focus on building an ontology forArabidopsis Thaliana in Plant Science domain. The aim of this study is toprovide a conceptual model of Arabidopsis Thaliana as a reference plant forbotany and other plant sciences, including concepts and their relationships.","Sara Hosseinzadeh Kassani, Peyman Hosseinzadeh Kassani",2018-10-10T16:02:55Z,2018-10-11T04:08:03Z,,cs.IR,http://arxiv.org/pdf/1810.04606v2,eng,,,Computer Science
251,http://arxiv.org/abs/1907.07744v5,"Plasma-MDS, a metadata schema for plasma science with examples from  plasma technology","A metadata schema, named Plasma-MDS, is introduced to support research datamanagement in plasma science. Plasma-MDS is suitable to facilitate thepublication of research data following the FAIR principles in domain-specificrepositories and with this the reuse of research data for data driven plasmascience. In accordance with common features in plasma science and technology,the metadata schema bases on the concept to separately describe the sourcegenerating the plasma, the medium in which the plasma is operated in, thetarget the plasma is acting on, and the diagnostics used for investigation ofthe process under consideration. These four basic schema elements aresupplemented by a schema element with various attributes for description of theresources, i.e. the digital data obtained by the applied diagnostic procedures.The metadata schema is first applied for the annotation of datasets publishedin INPTDAT -- the interdisciplinary data platform for plasma technology.","Steffen Franke, Lucian Paulet, Jan Schäfer, Deborah O'Connell, Markus M. Becker",2019-07-17T20:20:08Z,2020-12-18T22:19:44Z,"15 pages, 1 figure, 10 tables",physics.plasm-ph,http://arxiv.org/pdf/1907.07744v5,eng,,,Medicine
252,http://arxiv.org/abs/2203.07031v1,Model Positionality and Computational Reflexivity: Promoting Reflexivity  in Data Science,"Data science and machine learning provide indispensable techniques forunderstanding phenomena at scale, but the discretionary choices made when doingthis work are often not recognized. Drawing from qualitative researchpractices, we describe how the concepts of positionality and reflexivity can beadapted to provide a framework for understanding, discussing, and disclosingthe discretionary choices and subjectivity inherent to data science work. Wefirst introduce the concepts of model positionality and computationalreflexivity that can help data scientists to reflect on and communicate thesocial and cultural context of a model's development and use, the dataannotators and their annotations, and the data scientists themselves. We thendescribe the unique challenges of adapting these concepts for data science workand offer annotator fingerprinting and position mining as promising solutions.Finally, we demonstrate these techniques in a case study of the development ofclassifiers for toxic commenting in online communities.","Scott Allen Cambo, Darren Gergle",2022-03-08T16:02:03Z,2022-03-08T16:02:03Z,"19 pages, 6 figures. To be published in CHI '22",cs.CY,http://arxiv.org/pdf/2203.07031v1,eng,,,Physics and Astronomy
253,http://arxiv.org/abs/2204.07876v1,Lodestar: Supporting Independent Learning and Rapid Experimentation  Through Data-Driven Analysis Recommendations,"Keeping abreast of current trends, technologies, and best practices invisualization and data analysis is becoming increasingly difficult, especiallyfor fledgling data scientists. In this paper, we propose Lodestar, aninteractive computational notebook that allows users to quickly explore andconstruct new data science workflows by selecting from a list of automatedanalysis recommendations. We derive our recommendations from directed graphs ofknown analysis states, with two input sources: one manually curated from onlinedata science tutorials, and another extracted through semi-automatic analysisof a corpus of over 6,000 Jupyter notebooks. We evaluate Lodestar in aformative study guiding our next set of improvements to the tool. Our resultssuggest that users find Lodestar useful for rapidly creating data scienceworkflows.","Deepthi Raghunandan, Zhe Cui, Kartik Krishnan, Segen Tirfe, Shenzhi Shi, Tejaswi Darshan Shrestha, Leilani Battle, Niklas Elmqvist",2022-04-16T21:32:12Z,2022-04-16T21:32:12Z,"This paper was presented as part of the workshop called Visualization
  in Data Science (at ACM KDD and IEEE VIS)",cs.HC,http://arxiv.org/pdf/2204.07876v1,eng,,,Computer Science
254,http://arxiv.org/abs/2311.11516v1,GPT in Data Science: A Practical Exploration of Model Selection,"There is an increasing interest in leveraging Large Language Models (LLMs)for managing structured data and enhancing data science processes. Despite thepotential benefits, this integration poses significant questions regardingtheir reliability and decision-making methodologies. It highlights theimportance of various factors in the model selection process, including thenature of the data, problem type, performance metrics, computational resources,interpretability vs accuracy, assumptions about data, and ethicalconsiderations. Our objective is to elucidate and express the factors andassumptions guiding GPT-4's model selection recommendations. We employ avariability model to depict these factors and use toy datasets to evaluate boththe model and the implementation of the identified heuristics. By contrastingthese outcomes with heuristics from other platforms, our aim is to determinethe effectiveness and distinctiveness of GPT-4's methodology. This research iscommitted to advancing our comprehension of AI decision-making processes,especially in the realm of model selection within data science. Our efforts aredirected towards creating AI systems that are more transparent andcomprehensible, contributing to a more responsible and efficient practice indata science.","Nathalia Nascimento, Cristina Tavares, Paulo Alencar, Donald Cowan",2023-11-20T03:42:24Z,2023-11-20T03:42:24Z,11 pages. To appear in IEEE BigData 2023,cs.AI,http://arxiv.org/pdf/2311.11516v1,eng,,,Social Sciences
255,http://arxiv.org/abs/2401.03769v1,FAIR approach for Low Frequency Radio Astronomy,"The Open Science paradigm and the FAIR principles (Findable, Accessible,Interoperable, Reusable) are aiming at fostering scientific return, andreinforcing the trust in science production. The MASER (Measuring, Analysingand Simulating Emissions in the Radio range) services implement Open Sciencethrough a series of existing solutions that have been put together, only addingnew pieces where needed. It is a ""science ready"" toolbox dedicated totime-domain low frequency radioastronomy, which data products mostly coverssolar and planetary observations.  MASER solutions are based on IVOA protocols for data discovery, on IHDEAtools for data exploration, and on a dedicated format developed by MASER forthe temporal-spectral annotations. The service also proposes a data repositoryfor sharing data collections, catalogues and associated documentation, as wellas supplementary materials associated to papers. Each collection is managedthrough a Data Management Plan, which purpose is two-fold: supporting theprovider for managing the collection content; and supporting the data centrefor resource management. Each product of the repository is citable with a DOI,and the landing page contains web semantics annotations (using schema.org)",Baptiste Cecconi,2024-01-08T09:48:52Z,2024-01-08T09:48:52Z,Submitted to the proceedings of the ADASS 2023 conference,astro-ph.IM,http://arxiv.org/pdf/2401.03769v1,eng,,,Biochemistry
256,http://arxiv.org/abs/2401.04876v1,WARP: The Data Reduction Pipeline for the WINERED spectrograph,"We present a data reduction pipeline written in Python for data obtained withthe near-infrared cross-dispersed echelle spectrograph, WINERED, which yields a0.91$-$1.35 $\mu$m spectrum with the resolving power of $R_{\text{max}} \equiv\lambda / \Delta \lambda = 28,000$ or 70,000 depending on the observing mode.The pipeline was developed to efficiently extract the spectrum from the rawdata with high quality. It comprises two modes: the calibration and the sciencemode. The calibration mode automatically produces the flat-fielding image, badpixel map, echellogram distortion map and the dispersion solution from the setof the calibration data. Using calibration images and parameters, the sciencedata of astronomical objects can be reduced automatically using the sciencemode. The science mode is also used for the real-time quick look at the dataduring observations. An example of the spectra reduced with WARP is presented.The effect of the highly inclined slit image on the spectral resolution isdiscussed.","Satoshi Hamano, Yuji Ikeda, Shogo Otsubo, Haruki Katoh, Kei Fukue, Noriyuki Matsunaga, Daisuke Taniguchi, Hideyo Kawakita, Keiichi Takenaka, Sohei Kondo, Hiroaki Sameshima",2024-01-10T02:03:21Z,2024-01-10T02:03:21Z,"20 pages, 13 figures, 1 table, accepted for publication in
  Publications of the Astronomical Society of the Pacific",astro-ph.IM,http://arxiv.org/pdf/2401.04876v1,eng,,,Medicine
257,http://arxiv.org/abs/0911.3558v1,A Meta-evaluation of Scientific Research Proposals: Different Ways of  Comparing Rejected to Awarded Applications,"Combining different data sets with information on grant and fellowshipapplications submitted to two renowned funding agencies, we are able to comparetheir funding decisions (award and rejection) with scientometric performanceindicators across two fields of science (life sciences and social sciences).The data sets involve 671 applications in social sciences and 668 applicationsin life sciences. In both fields, awarded applicants perform on average betterthan all rejected applicants. If only the most preeminent rejected applicantsare considered in both fields, they score better than the awardees on citationimpact. With regard to productivity we find differences between the fields:While the awardees in life sciences outperform on average the most preeminentrejected applicants, the situation is reversed in social sciences.","Lutz Bornmann, Loet Leydesdorff, Peter van den Besselaar",2009-11-18T14:41:41Z,2009-11-18T14:41:41Z,,cs.CY,http://arxiv.org/pdf/0911.3558v1,eng,,,Medicine
258,http://arxiv.org/abs/1608.05006v2,Automaticity in Computation and Student Success in Introductory Physical  Science Courses,"Between 1984 and 2011, the percentage of US bachelor degrees awarded inphysics declined by 25%, in chemistry declined by 33%, and overall in physicalsciences and engineering fell 40%. Data suggest that these declines arecorrelated to a deemphasis in most states of practicing computation skills inmathematics. Analysis of state standards put into place between 1990 and 2010find that most states directed teachers to deemphasize both memorization andstudent practice in computational problem solving. Available state test scoredata show a significant decline in student computation skills. In recentinternational testing, scores for US 16 to 24 year olds in numeracy finishedlast among 22 tested nations in the OECD. Recent studies in cognitive sciencehave found that to solve well-structured problems in the sciences, studentsmust first memorize fundamental facts and procedures in mathematics and scienceuntil they can be recalled with automaticity, then practice applying thoseskills in a variety of distinctive contexts. Actions are suggested to improveUS STEM graduation rates by aligning US math and science curricula with therecommendations of cognitive science.","JudithAnn R. Hartman, Eric A. Nelson",2016-08-17T16:07:57Z,2016-09-27T13:54:01Z,"26 pages, 5 figures",physics.ed-ph,http://arxiv.org/pdf/1608.05006v2,eng,,,Social Sciences
259,http://arxiv.org/abs/1907.13061v1,"Coercion, Consent, and Participation in Citizen Science","Throughout history, everyday people have contributed to science through amyriad of volunteer activities. This early participation required training andoften involved mentorship from scientists or senior citizen scientists (or, asthey were often called, gentleman scientists). During this learning process,participants learned how they and their data would be used both to advancescience, and in some cases, advance the careers of professional collaborators.Modern, online citizen science, allows participation with just a few clicks,and people may participate without understanding what they are contributing to.Too often, they happily see what they are doing as the privilege of paintingTom Sawyer's fence without realizing they are actually being used as merely ameans to a scientific end. This paper discusses the ethical dilemmas thatplague modern citizen science, including: the issues of informed consent, suchas not requiring logins; the issues of coercion inherent in mandatory classroomassignments requiring data submission; and the issues of using people merely asa means to an end that are inherent in technonationalism, and projects that donot provide utility to the users beyond the knowledge they helped. This work istested within the context of astronomy citizen science.","Alison Reiheld, Pamela L. Gay",2019-07-29T03:48:21Z,2019-07-29T03:48:21Z,submitted to journal of Science and Engineering Ethics,cs.CY,http://arxiv.org/pdf/1907.13061v1,eng,,,Social Sciences
260,http://arxiv.org/abs/2404.13722v1,MatInf -- an Extensible Open-Source Solution for Research Digitalisation  in Materials Science,"Information technology and data science development stimulate transformationin many fields of scientific knowledge. In recent years, a large number ofspecialized systems for information and knowledge management have been createdin materials science. However, the development and deployment of open adaptivesystems for research support in materials science based on the acquisition,storage, and processing of different types of information remains unsolved. Wepropose MatInf - an extensible, open-source solution for researchdigitalisation in materials science based on an adaptive, flexible informationmanagement system for heterogeneous data sources. MatInf can be easily adaptedto any materials science laboratory and is especially useful for collaborativeprojects between several labs. As an example, we demonstrate its application inhigh-throughput experimentation.","Victor Dudarev, Lars Banko, Alfred Ludwig",2024-04-21T17:35:04Z,2024-04-21T17:35:04Z,"7 pages, 5 figures, 10 references",cond-mat.mtrl-sci,http://arxiv.org/pdf/2404.13722v1,eng,,,Medicine
261,http://arxiv.org/abs/2404.18635v1,Citizen Science in European Research Infrastructures,"Major European Union-funded research infrastructure and open science projectshave traditionally included dissemination work, for mostly one-waycommunication of the research activities. Here we present and review ourradical re-envisioning of this work, by directly engaging citizen sciencevolunteers into the research. We summarise the citizen science in theHorizon-funded projects ASTERICS (Astronomy ESFRI and Research InfrastructureClusters) and ESCAPE (European Science Cluster of Astronomy and ParticlePhysics ESFRI Research Infrastructures), engaging hundreds of thousands ofvolunteers in providing millions of data mining classifications. Not only doesthis have enormously more scientific and societal impact than conventionaldissemination, but it facilitates the direct research involvement of what isoften arguably the most neglected stakeholder group in Horizon projects, thescience-inclined public. We conclude with recommendations and opportunities fordeploying crowdsourced data mining in the physical sciences, noting that theprimary goal is always the fundamental research question; if public engagementis the primary goal to optimise, then other, more targeted approaches may bemore effective.","Stephen Serjeant, James Pearson, Hugh Dickinson, Johanna Jarvis",2024-04-29T12:14:54Z,2024-04-29T12:14:54Z,"Accepted by European Physical Journal Plus. Invited review. 26 pages,
  1 figure",astro-ph.IM,http://arxiv.org/pdf/2404.18635v1,eng,,,Social Sciences
262,http://arxiv.org/abs/gr-qc/0403023v1,LISA Science Results in the Presence of Data Disturbances,"Each spacecraft in the Laser Interferometer Space Antenna houses a proof masswhich follows a geodesic through spacetime. Disturbances which change the proofmass position, momentum, and/or acceleration will appear in the LISA datastream as additive quadratic functions. These data disturbances inhibit signalextraction and must be removed. In this paper we discuss the identification andfitting of monochromatic signals in the data set in the presence of datadisturbances. We also present a preliminary analysis of the extent of scienceresult limitations with respect to the frequency of data disturbances.",Scott E Pollack,2004-03-04T18:31:41Z,2004-03-04T18:31:41Z,,gr-qc,http://arxiv.org/pdf/gr-qc/0403023v1,eng,,,Medicine
263,http://arxiv.org/abs/1506.05216v1,The k-NN algorithm for compositional data: a revised approach with and  without zero values present,"In compositional data, an observation is a vector with non-negativecomponents which sum to a constant, typically 1. Data of this type arise inmany areas, such as geology, archaeology, biology, economics and politicalscience among others. The goal of this paper is to extend the taxicab metricand a newly suggested metric for compositional data by employing a powertransformation. Both metrics are to be used in the k-nearest neighboursalgorithm regardless of the presence of zeros. Examples with real data areexhibited.",Michail Tsagris,2015-06-17T06:25:09Z,2015-06-17T06:25:09Z,"This manuscript will appear at the.
  http://www.jds-online.com/volume-12-number-3-july-2014",stat.ME,http://arxiv.org/pdf/1506.05216v1,eng,,,Medicine
264,http://arxiv.org/abs/2201.08288v1,Scalable $k$-d trees for distributed data,"Data structures known as $k$-d trees have numerous applications in scientificcomputing, particularly in areas of modern statistics and data science such asrange search in decision trees, clustering, nearest neighbors search, localregression, and so forth. In this article we present a scalable mechanism toconstruct $k$-d trees for distributed data, based on approximating medians foreach recursive subdivision of the data. We provide theoretical guarantees ofthe quality of approximation using this approach, along with a simulation studyquantifying the accuracy and scalability of our proposed approach in practice.","Aritra Chakravorty, William S. Cleveland, Patrick J. Wolfe",2022-01-20T16:47:48Z,2022-01-20T16:47:48Z,"34 pages, 3 figures; submitted for publication",cs.DS,http://arxiv.org/pdf/2201.08288v1,eng,,,Engineering
265,http://arxiv.org/abs/2311.06695v1,Conversational Data Exploration: A Game-Changer for Designing Data  Science Pipelines,"This paper proposes a conversational approach implemented by the systemChatin for driving an intuitive data exploration experience. Our work aims tounlock the full potential of data analytics and artificial intelligence with anew generation of data science solutions. Chatin is a cutting-edge tool thatdemocratises access to AI-driven solutions, empowering non-technical users fromvarious disciplines to explore data and extract knowledge from it.","Genoveva Vargas-Solar, Tania Cerquitelli, Javier A. Espinosa-Oviedo, François Cheval, Anthelme Buchaille, Luca Polgar",2023-11-12T00:22:09Z,2023-11-12T00:22:09Z,,cs.HC,http://arxiv.org/pdf/2311.06695v1,eng,,,Computer Science
266,http://arxiv.org/abs/1612.07140v2,A Guide to Teaching Data Science,"Demand for data science education is surging and traditional courses offeredby statistics departments are not meeting the needs of those seeking training.This has led to a number of opinion pieces advocating for an update to theStatistics curriculum. The unifying recommendation is computing should play amore prominent role. We strongly agree with this recommendation, but advocatethe main priority is to bring applications to the forefront as proposed byNolan and Speed (1999). We also argue that the individuals tasked withdeveloping data science courses should not only have statistical training, butalso have experience analyzing data with the main objective of solvingreal-world problems. Here, we share a set of general principles and offer adetailed guide derived from our successful experience developing and teaching agraduate-level, introductory data science course centered entirely on casestudies. We argue for the importance of statistical thinking, as defined byWild and Pfannkuck (1999) and describe how our approach teaches students threekey skills needed to succeed in data science, which we refer to as creating,connecting, and computing. This guide can also be used for statisticianswanting to gain more practical knowledge about data science before embarking onteaching an introductory course.","Stephanie C. Hicks, Rafael A. Irizarry",2016-12-21T14:32:35Z,2017-05-15T11:28:19Z,"2 tables, 3 figures, 2 supplemental figures",stat.OT,http://arxiv.org/pdf/1612.07140v2,eng,,,Social Sciences
267,http://arxiv.org/abs/1812.08032v2,Progressive Data Science: Potential and Challenges,"Data science requires time-consuming iterative manual activities. Inparticular, activities such as data selection, preprocessing, transformation,and mining, highly depend on iterative trial-and-error processes that could besped-up significantly by providing quick feedback on the impact of changes. Theidea of progressive data science is to compute the results of changes in aprogressive manner, returning a first approximation of results quickly andallow iterative refinements until converging to a final result. Enabling theuser to interact with the intermediate results allows an early detection oferroneous or suboptimal choices, the guided definition of modifications to thepipeline and their quick assessment. In this paper, we discuss theprogressiveness challenges arising in different steps of the data sciencepipeline. We describe how changes in each step of the pipeline impact thesubsequent steps and outline why progressive data science will help to make theprocess more effective. Computing progressive approximations of outcomesresulting from changes creates numerous research challenges, especially if thechanges are made in the early steps of the pipeline. We discuss thesechallenges and outline first steps towards progressiveness, which, we argue,will ultimately help to significantly speed-up the overall data scienceprocess.","Cagatay Turkay, Nicola Pezzotti, Carsten Binnig, Hendrik Strobelt, Barbara Hammer, Daniel A. Keim, Jean-Daniel Fekete, Themis Palpanas, Yunhai Wang, Florin Rusu",2018-12-19T15:45:03Z,2019-09-12T17:02:46Z,,cs.HC,http://arxiv.org/pdf/1812.08032v2,eng,,,Medicine
268,http://arxiv.org/abs/2310.03193v1,The Rise of Open Science: Tracking the Evolution and Perceived Value of  Data and Methods Link-Sharing Practices,"In recent years, funding agencies and journals increasingly advocate for openscience practices (e.g. data and method sharing) to improve the transparency,access, and reproducibility of science. However, quantifying these practices atscale has proven difficult. In this work, we leverage a large-scale dataset of1.1M papers from arXiv that are representative of the fields of physics, math,and computer science to analyze the adoption of data and method link-sharingpractices over time and their impact on article reception. To identify links todata and methods, we train a neural text classification model to automaticallyclassify URL types based on contextual mentions in papers. We find evidencethat the practice of link-sharing to methods and data is spreading as morepapers include such URLs over time. Reproducibility efforts may also bespreading because the same links are being increasingly reused across papers(especially in computer science); and these links are increasingly concentratedwithin fewer web domains (e.g. Github) over time. Lastly, articles that sharedata and method links receive increased recognition in terms of citation count,with a stronger effect when the shared links are active (rather than defunct).Together, these findings demonstrate the increased spread and perceived valueof data and method sharing practices in open science.","Hancheng Cao, Jesse Dodge, Kyle Lo, Daniel A. McFarland, Lucy Lu Wang",2023-10-04T22:34:56Z,2023-10-04T22:34:56Z,,cs.DL,http://arxiv.org/pdf/2310.03193v1,eng,,,Social Sciences
269,http://arxiv.org/abs/2407.16867v2,From Text to Insight: Large Language Models for Materials Science Data  Extraction,"The vast majority of materials science knowledge exists in unstructurednatural language, yet structured data is crucial for innovative and systematicmaterials design. Traditionally, the field has relied on manual curation andpartial automation for data extraction for specific use cases. The advent oflarge language models (LLMs) represents a significant shift, potentiallyenabling efficient extraction of structured, actionable data from unstructuredtext by non-experts. While applying LLMs to materials science data extractionpresents unique challenges, domain knowledge offers opportunities to guide andvalidate LLM outputs. This review provides a comprehensive overview ofLLM-based structured data extraction in materials science, synthesizing currentknowledge and outlining future directions. We address the lack of standardizedguidelines and present frameworks for leveraging the synergy between LLMs andmaterials science expertise. This work serves as a foundational resource forresearchers aiming to harness LLMs for data-driven materials research. Theinsights presented here could significantly enhance how researchers acrossdisciplines access and utilize scientific information, potentially acceleratingthe development of novel materials for critical societal needs.","Mara Schilling-Wilhelmi, Martiño Ríos-García, Sherjeel Shabih, María Victoria Gil, Santiago Miret, Christoph T. Koch, José A. Márquez, Kevin Maik Jablonka",2024-07-23T22:23:47Z,2024-12-02T15:42:53Z,,cond-mat.mtrl-sci,http://arxiv.org/pdf/2407.16867v2,eng,,,Physics and Astronomy
270,http://arxiv.org/abs/2005.05079v1,A Survey on Sampling and Profiling over Big Data (Technical Report),"Due to the development of internet technology and computer science, data isexploding at an exponential rate. Big data brings us new opportunities andchallenges. On the one hand, we can analyze and mine big data to discoverhidden information and get more potential value. On the other hand, the 5Vcharacteristic of big data, especially Volume which means large amount of data,brings challenges to storage and processing. For some traditional data miningalgorithms, machine learning algorithms and data profiling tasks, it is verydifficult to handle such a large amount of data. The large amount of data ishighly demanding hardware resources and time consuming. Sampling methods caneffectively reduce the amount of data and help speed up data processing. Hence,sampling technology has been widely studied and used in big data context, e.g.,methods for determining sample size, combining sampling with big dataprocessing frameworks. Data profiling is the activity that finds metadata ofdata set and has many use cases, e.g., performing data profiling tasks onrelational data, graph data, and time series data for anomaly detection anddata repair. However, data profiling is computationally expensive, especiallyfor large data sets. Therefore, this paper focuses on researching sampling andprofiling in big data context and investigates the application of sampling indifferent categories of data profiling tasks. From the experimental results ofthese studies, the results got from the sampled data are close to or evenexceed the results of the full amount of data. Therefore, sampling technologyplays an important role in the era of big data, and we also have reason tobelieve that sampling technology will become an indispensable step in big dataprocessing in the future.","Zhicheng Liu, Aoqian Zhang",2020-05-08T02:54:07Z,2020-05-08T02:54:07Z,,cs.DB,http://arxiv.org/pdf/2005.05079v1,eng,,,Computer Science
271,http://arxiv.org/abs/1504.04478v2,"Evaluating the Quality of RDF Data Sets on Common Vocabularies in the  Social, Behavioral, and Economic Sciences","From 2012 to 2015 together with other Linked Data community members andexperts from the social, behavioral, and economic sciences (SBE), we developeddiverse vocabularies to represent SBE metadata and tabular data in RDF. TheDDI-RDF Discovery Vocabulary (DDI-RDF) is designed to support thedissemination, management, and reuse of unit-record data, i.e., data aboutindividuals, households, and businesses, collected in form of responses tostudies and archived for research purposes. The RDF Data Cube Vocabulary (QB)is a W3C recommendation for expressing data cubes, i.e. multi-dimensionalaggregate data and its metadata. Physical Data Description (PHDD) is avocabulary to model data in rectangular format, i.e., tabular data. The datacould either be represented in records with character-separated values (CSV) orfixed length. The Simple Knowledge Organization System (SKOS) is a vocabularyto build knowledge organization systems such as thesauri, classificationschemes, and taxonomies. XKOS is a SKOS extension to describe formalstatistical classifications.  To ensure high quality of and trust in both metadata and data, theirrepresentation in RDF must satisfy certain criteria - specified in terms of RDFconstraints. In this paper, we evaluate the data quality of 15,694 data sets(4.26 billion triples) of research data for the social, behavioral, andeconomic sciences obtained from 33 SPARQL endpoints. We checked 115 constraintson three different and representative SBE vocabularies (DDI-RDF, QB, and SKOS)by means of the RDF Validator, a validation environment which is available athttp://purl.org/net/rdfval-demo.","Thomas Hartmann, Benjamin Zapilko, Joachim Wackerow, Kai Eckert",2015-04-17T10:42:09Z,2015-09-15T07:54:09Z,,cs.DL,http://arxiv.org/pdf/1504.04478v2,eng,,,Social Sciences
272,http://arxiv.org/abs/2102.09295v2,A Unified System for Data Analytics and In Situ Query Processing,"In today's world data is being generated at a high rate due to which it hasbecome inevitable to analyze and quickly get results from this data. Most ofthe relational databases primarily support SQL querying with a limited supportfor complex data analysis. Due to this reason, data scientists have no otheroption, but to use a different system for complex data analysis. Due to this,data science frameworks are in huge demand. But to use such a framework, allthe data needs to be loaded into it. This requires significant data movementacross multiple systems, which can be expensive.  We believe that it has become the need of the hour to come up with a singlesystem which can perform both data analysis tasks and SQL querying. This willsave the data scientists from the expensive data transfer operation acrosssystems. In our work, we present DaskDB, a system built over the Python's Daskframework, which is a scalable data science system having support for both dataanalytics and in situ SQL query processing over heterogeneous data sources.DaskDB supports invoking any Python APIs as User-Defined Functions (UDF) overSQL queries. So, it can be easily integrated with most existing Python datascience applications, without modifying the existing code. Since joining tworelations is a very vital but expensive operation, so a novel distributedlearned index is also introduced to improve the join performance. Ourexperimental evaluation demonstrates that DaskDB significantly outperformsexisting systems.","Alex Watson, Suvam Kumar Das, Suprio Ray",2021-02-18T12:16:20Z,2021-04-07T14:55:35Z,,cs.DB,http://arxiv.org/pdf/2102.09295v2,eng,,,Computer Science
273,http://arxiv.org/abs/2007.11281v2,Big Issues for Big Data: challenges for critical spatial data analytics,"In this paper we consider some of the issues of working with big data and bigspatial data and highlight the need for an open and critical framework. Wefocus on a set of challenges underlying the collection and analysis of bigdata. In particular, we consider 1) the issues related to inference whenworking with usually biased big data, challenging the assumed inferentialsuperiority of data with observations, n, approaching N, the population (n->N),and the need for data science analysis that answer questions of practicalsignificance or with greater emphasis n the size of the effect, rather than thetruth or falsehood of a statistical statement; 2) the need to accept messinessin your data and to document all operations undertaken on the data because ofthis support of openness and reproducibility paradigms; and 3) the need toexplicitly seek to understand the causes of bias, messiness etc in the data andthe inferential consequences of using such data in analyses, by adoptingcritical approaches to spatial data science. In particular we consider the needto place individual data science studies in a wider social and economiccontexts, along the the role of inferential theory in the presence of big data,and issues relating to messiness and complexity in big data.","Chris Brunsdon, Alexis Comber",2020-07-22T09:11:56Z,2020-08-11T12:56:18Z,0 figures. 10 pages,cs.CY,http://arxiv.org/pdf/2007.11281v2,eng,,,Computer Science
274,http://arxiv.org/abs/gr-qc/0606089v1,Addressing LISA Science Analysis Challenges,"The principal goal of the \emph{LISA Science Analysis Workshop} is toencourage the development and maturation of science analysis technology inpreparation for LISA science operations. Exactly because LISA is a pathfinderfor a new scientific discipline -- gravitational wave astronomy -- LISA dataprocessing and science analysis methodologies are in their infancy and requireconsiderable maturation if they are to be ready to take advantage of LISA data.Here we offer some thoughts, in anticipation of the LISA Science AnalysisWorkshop, on analysis research problems that demonstrate the capabilities ofdifferent proposed analysis methodologies and, simultaneously, help to pushthose techniques toward greater maturity. Particular emphasis is placed onformulating questions that can be turned into well-posed problems involvingtests run on specific data sets, which can be shared among different groups toenable the comparison of techniques on a well-defined platform.","Matthew J. Benacquista, Lee Samuel Finn, Shane L. Larson, Louis J. Rubbo",2006-06-21T03:04:32Z,2006-06-21T03:04:32Z,7 pages,gr-qc,http://arxiv.org/pdf/gr-qc/0606089v1,eng,,,Social Sciences
275,http://arxiv.org/abs/physics/0702118v1,Science Citation Index data: Two additional reasons against its use for  administrative purposes,"First, for decades the use of anonymity in reviews for science fundingproposals and for evaluating manuscripts for publication has been graduallycorrupting American science, encouraging and rewarding the dark elements ofhuman nature. Unethical reviewers, secure and unaccountable through anonymity,all too often make untrue and/or pejorative statements to eliminate theirprofessional competitors. Survival in this corrupt environment has led to aconsensus-only mentality. Consequently, important scientific contradictions, ifthey can be published at all, are selectively ignored in many instances out offear of anonymous retaliation. Science Citation Index data in such a corruptenvironment may be of little administrative value, except for possible use indocumenting scientific fraud. Second, as knowledge of the administrative use ofScience Citation Index data spreads, scientists will adapt and will shift toresearch on popular subjects to elicit greater numbers of citations, ratherthan to take the paths less trodden where important scientific discoveries maylay waiting.",J. Marvin Herndon,2007-02-14T18:46:11Z,2007-02-14T18:46:11Z,Accepted for publication in Current Science,physics.gen-ph,http://arxiv.org/pdf/physics/0702118v1,eng,,,Medicine
276,http://arxiv.org/abs/1707.05364v1,Modern Data Formats for Big Bioinformatics Data Analytics,"Next Generation Sequencing (NGS) technology has resulted in massive amountsof proteomics and genomics data. This data is of no use if it is not properlyanalyzed. ETL (Extraction, Transformation, Loading) is an important step indesigning data analytics applications. ETL requires proper understanding offeatures of data. Data format plays a key role in understanding of data,representation of data, space required to store data, data I/O duringprocessing of data, intermediate results of processing, in-memory analysis ofdata and overall time required to process data. Different data mining andmachine learning algorithms require input data in specific types and formats.This paper explores the data formats used by different tools and algorithms andalso presents modern data formats that are used on Big Data Platform. It willhelp researchers and developers in choosing appropriate data format to be usedfor a particular tool or algorithm.","Shahzad Ahmed, M. Usman Ali, Javed Ferzund, Muhammad Atif Sarwar, Abbas Rehman, Atif Mehmood",2017-05-05T11:35:53Z,2017-05-05T11:35:53Z,"12 Pages, 20 figures and 2 Tables",cs.DB,http://arxiv.org/pdf/1707.05364v1,eng,,,Computer Science
277,http://arxiv.org/abs/2310.17848v3,Boosting Data Analytics With Synthetic Volume Expansion,"Synthetic data generation, a cornerstone of Generative ArtificialIntelligence, promotes a paradigm shift in data science by addressing datascarcity and privacy while enabling unprecedented performance. As syntheticdata becomes more prevalent, concerns emerge regarding the accuracy ofstatistical methods when applied to synthetic data in contrast to raw data.This article explores the effectiveness of statistical methods on syntheticdata and the privacy risks of synthetic data. Regarding effectiveness, wepresent the Synthetic Data Generation for Analytics framework. This frameworkapplies statistical approaches to high-quality synthetic data produced bygenerative models like tabular diffusion models, which, initially trained onraw data, benefit from insights from pertinent studies through transferlearning. A key finding within this framework is the generational effect, whichreveals that the error rate of statistical methods on synthetic data decreaseswith the addition of more synthetic data but may eventually rise or stabilize.This phenomenon, stemming from the challenge of accurately mirroring raw datadistributions, highlights a ""reflection point""-an ideal volume of syntheticdata defined by specific error metrics. Through three case studies, sentimentanalysis, predictive modeling of structured data, and inference in tabulardata, we validate the superior performance of this framework compared toconventional approaches. On privacy, synthetic data imposes lower risks whilesupporting the differential privacy standard. These studies underscoresynthetic data's untapped potential in redefining data science's landscape.","Xiaotong Shen, Yifei Liu, Rex Shen",2023-10-27T01:57:27Z,2024-03-10T18:53:50Z,,stat.ML,http://arxiv.org/pdf/2310.17848v3,eng,,,Engineering
278,http://arxiv.org/abs/1301.2522v2,Science 3.0: Corrections to the Science 2.0 paradigm,"The concept of Science 2.0 was introduced almost a decade ago to describe thenew generation of online-based tools for researchers allowing easier datasharing, collaboration and publishing. Although technically sound, the conceptstill does not work as expected. Here we provide a systematic line of argumentsto modify the concept of Science 2.0, making it more consistent with the spiritand traditions of science and Internet. Our first correction to the Science 2.0paradigm concerns the open-access publication models charging fees to theauthors. As discussed elsewhere, we show that the monopoly of such publishingmodels increases biases and inequalities in the representation of scientificideas based on the author's income. Our second correction concernspost-publication comments online, which are all essentially non-anonymous inthe current Science 2.0 paradigm. We conclude that scientific post-publicationdiscussions require special anonymization systems. We further analyze thereasons of the failure of the current post-publication peer-review models andsuggest what needs to be changed in Science 3.0 to convert Internet into alarge journal club.",Vladimir B. Teif,2013-01-11T15:40:35Z,2013-01-19T17:02:45Z,7 figures,cs.DL,http://arxiv.org/pdf/1301.2522v2,eng,,,Medicine
279,http://arxiv.org/abs/2008.05561v1,The Right Tools for the Job: The Case for Spatial Science Tool-Building,"This paper was presented as the 8th annual Transactions in GIS plenaryaddress at the American Association of Geographers annual meeting inWashington, DC. The spatial sciences have recently seen growing calls for moreaccessible software and tools that better embody geographic science and theory.Urban spatial network science offers one clear opportunity: from multipleperspectives, tools to model and analyze nonplanar urban spatial networks havetraditionally been inaccessible, atheoretical, or otherwise limiting. Thispaper reflects on this state of the field. Then it discusses the motivation,experience, and outcomes of developing OSMnx, a tool intended to help addressthis. Next it reviews this tool's use in the recent multidisciplinary spatialnetwork science literature to highlight upstream and downstream benefits ofopen-source software development. Tool-building is an essential but poorlyincentivized component of academic geography and social science more broadly.To conduct better science, we need to build better tools. The paper concludeswith paths forward, emphasizing open-source software and reusable computationaldata science beyond mere reproducibility and replicability.",Geoff Boeing,2020-08-12T20:15:39Z,2020-08-12T20:15:39Z,,cs.CY,http://arxiv.org/pdf/2008.05561v1,eng,,,Social Sciences
280,http://arxiv.org/abs/1307.0358v1,A program for SAXS data processing and analysis,A computer program for small angle X-ray scattering (SAXS) data processingand analysis named S.exe written in Intel Visual Fortran has been developed.This paper briefly introduces its main theory and function.,Zhi-hong Li,2013-07-01T13:12:48Z,2013-07-01T13:12:48Z,,physics.data-an,http://arxiv.org/pdf/1307.0358v1,eng,,,Medicine
281,http://arxiv.org/abs/2011.08663v1,Occams Razor for Big Data? On Detecting Quality in Large Unstructured  Datasets,"Detecting quality in large unstructured datasets requires capacities farbeyond the limits of human perception and communicability and, as a result,there is an emerging trend towards increasingly complex analytic solutions indata science to cope with this problem. This new trend towards analyticcomplexity represents a severe challenge for the principle of parsimony orOccams Razor in science. This review article combines insight from variousdomains such as physics, computational science, data engineering, and cognitivescience to review the specific properties of big data. Problems for detectingdata quality without losing the principle of parsimony are then highlighted onthe basis of specific examples. Computational building block approaches fordata clustering can help to deal with large unstructured datasets in minimizedcomputation time, and meaning can be extracted rapidly from large sets ofunstructured image or video data parsimoniously through relatively simpleunsupervised machine learning algorithms. Why we still massively lack inexpertise for exploiting big data wisely to extract relevant information forspecific tasks, recognize patterns, generate new information, or store andfurther process large amounts of sensor data is then reviewed; examplesillustrating why we need subjective views and pragmatic methods to analyze bigdata contents are brought forward. The review concludes on how culturaldifferences between East and West are likely to affect the course of big dataanalytics, and the development of increasingly autonomous artificialintelligence aimed at coping with the big data deluge in the near future.","Birgitta Dresp-Langley, Ole Kristian Ekseth, Jan Fesl, Seiichi Gohshi, Marc Kurz, Hans-Werner Sehring",2020-11-12T16:06:01Z,2020-11-12T16:06:01Z,,cs.DB,http://arxiv.org/pdf/2011.08663v1,eng,,,Computer Science
282,http://arxiv.org/abs/2310.18011v3,Data journeys in popular science: Producing climate change and COVID-19  data visualizations at Scientific American,"Vast amounts of (open) data are increasingly used to make arguments aboutcrisis topics such as climate change and global pandemics. Data visualizationsare central to bringing these viewpoints to broader publics. However,visualizations often conceal the many contexts involved in their production,ranging from decisions made in research labs about collecting and sharing datato choices made in editorial rooms about which data stories to tell. In thispaper, we examine how data visualizations about climate change and COVID-19 areproduced in popular science magazines, using Scientific American, anestablished English-language popular science magazine, as a case study. To dothis, we apply the analytical concept of data journeys (Leonelli, 2020) in amixed methods study that centers on interviews with Scientific American staffand is supplemented by a visualization analysis of selected charts. Inparticular, we discuss the affordances of working with open data, the role ofcollaborative data practices, and how the magazine works to countermisinformation and increase transparency. This work provides an empiricalcontribution by providing insight into the data (visualization) practices ofscience communicators and demonstrating how the concept of data journeys can beused as an analytical framework.","Kathleen Gregory, Laura Koesten, Regina Schuster, Torsten Möller, Sarah Davies",2023-10-27T09:39:06Z,2024-03-27T08:13:14Z,"44 pages, 4 figures, 3 boxes",cs.DL,http://arxiv.org/pdf/2310.18011v3,eng,,,Social Sciences
283,http://arxiv.org/abs/1304.5743v1,Genericity versus expressivity - an exercise in semantic interoperable  research information systems for Web Science,"The web does not only enable new forms of science, it also creates newpossibilities to study science and new digital scholarship. This paper bringstogether multiple perspectives: from individual researchers seeking the bestoptions to display their activities and market their skills on the academic jobmarket; to academic institutions, national funding agencies, and countriesneeding to monitor the science system and account for public money spending. Wealso address the research interests aimed at better understanding theself-organising and complex nature of the science system through researchertracing, the identification of the emergence of new fields, and knowledgediscovery using large-data mining and non-linear dynamics. In particular thispaper draws attention to the need for standardisation and data interoperabilityin the area of research information as an indispensable pre-condition for anyscience modelling. We discuss which levels of complexity are needed to providea globally, interoperable, and expressive data infrastructure for researchinformation. With possible dynamic science model applications in mind, weintroduce the need for a ""middle-range"" level of complexity for datarepresentation and propose a conceptual model for research data based on a coreinternational ontology with national and local extensions.","Christophe Guéret, Tamy Chambers, Linda Reijnhoudt, Frank van der Most, Andrea Scharnhorst",2013-04-21T14:41:23Z,2013-04-21T14:41:23Z,Long version of a paper submitted to the WebScience 2013,cs.DL,http://arxiv.org/pdf/1304.5743v1,eng,,,Social Sciences
284,http://arxiv.org/abs/1011.1209v1,The Herschel Data Processing System - HIPE and Pipelines - Up and  Running Since the Start of the Mission,"The Herschel Space Observatory is the fourth cornerstone mission in the ESAscience programme and performs photometry and spectroscopy in the 55 - 672micron range. The development of the Herschel Data Processing System started in2002 to support the data analysis for Instrument Level Tests. The Herschel DataProcessing System was used for the pre-flight characterisation of theinstruments, and during various ground segment test campaigns. Following thesuccessful launch of Herschel 14th of May 2009 the Herschel Data ProcessingSystem demonstrated its maturity when the first PACS preview observation of M51was processed within 30 minutes of reception of the first science data afterlaunch. Also the first HIFI observations on DR21 were successfully reduced tohigh quality spectra, followed by SPIRE observations on M66 and M74. A fastturn-around cycle between data retrieval and the production of science-readyproducts was demonstrated during the Herschel Science Demonstration PhaseInitial Results Workshop held 7 months after launch, which is a clear proofthat the system has reached a good level of maturity. We will summarise thescope, the management and development methodology of the Herschel DataProcessing system, present some key software elements and give an overviewabout the current status and future development milestones.","Stephan Ott, Herschel Science Centre, European Space Agency",2010-11-04T16:38:46Z,2010-11-04T16:38:46Z,"Proceedings of the Astronomical Data Analysis Software and Systems
  XIX Conference held at the Renaissance Sapporo Hotel, Sapporo, Japan, 4-8
  October 2009, Edited by Y. Mizumoto, K.-I. Morita & M. Ohishi, Astronomical
  Society of the Pacific Conference Series, Volume 434, Pages 139-142",astro-ph.IM,http://arxiv.org/pdf/1011.1209v1,eng,,,Medicine
285,http://arxiv.org/abs/1909.02309v1,Human-AI Collaboration in Data Science: Exploring Data Scientists'  Perceptions of Automated AI,"The rapid advancement of artificial intelligence (AI) is changing our livesin many ways. One application domain is data science. New techniques inautomating the creation of AI, known as AutoAI or AutoML, aim to automate thework practices of data scientists. AutoAI systems are capable of autonomouslyingesting and pre-processing data, engineering new features, and creating andscoring models based on a target objectives (e.g. accuracy or run-timeefficiency). Though not yet widely adopted, we are interested in understandinghow AutoAI will impact the practice of data science. We conducted interviewswith 20 data scientists who work at a large, multinational technology companyand practice data science in various business settings. Our goal is tounderstand their current work practices and how these practices might changewith AutoAI. Reactions were mixed: while informants expressed concerns aboutthe trend of automating their jobs, they also strongly felt it was inevitable.Despite these concerns, they remained optimistic about their future jobsecurity due to a view that the future of data science work will be acollaboration between humans and AI systems, in which both automation and humanexpertise are indispensable.","Dakuo Wang, Justin D. Weisz, Michael Muller, Parikshit Ram, Werner Geyer, Casey Dugan, Yla Tausczik, Horst Samulowitz, Alexander Gray",2019-09-05T10:39:37Z,2019-09-05T10:39:37Z,,cs.HC,http://arxiv.org/pdf/1909.02309v1,eng,,,Medicine
286,http://arxiv.org/abs/2207.13404v1,COMPTEL data analysis using GammaLib and ctools,"More than 20 years after the end of NASA's Compton Gamma-Ray Observatorymission, the data collected by its Imaging Compton Telescope (COMPTEL) stillprovide the most comprehensive and deepest view of our Universe in MeV gammarays. While most of the COMPTEL data are archived at NASA's High EnergyAstrophysics Science Archive Research Center (HEASARC), the absence of anypublicly available software for their analysis means the data cannot benefitfrom the scientific advances made in the field of gamma-ray astronomy at higherenergies. To make this unique treasure again accessible for science, wedeveloped open source software that enables a comprehensive and modern analysisof the archived COMPTEL telescope data. Our software is based on a dedicatedplug-in to the GammaLib library, a community-developed toolbox for the analysisof astronomical gamma-ray data. We implemented high-level scripts for buildingscience analysis workflows in ctools, a community-developed gamma-ray astronomyscience analysis software framework. We describe the implementation of oursoftware and provide the underlying algorithms. Using data from the HEASARCarchive, we demonstrate that our software reproduces derived data products thatwere obtained in the past using the proprietary COMPTEL software. Wefurthermore demonstrate that our software reproduces COMPTEL science resultspublished in the literature. This brings the COMPTEL telescope data back intolife, allowing them to benefit from recent advances in gamma-ray astronomy, andgives the community a means to unveil its still hidden treasures.","Jürgen Knödlseder, Werner Collmar, Manon Jarry, Mark McConnell",2022-07-27T09:40:33Z,2022-07-27T09:40:33Z,"31 pages, 23 figures",astro-ph.IM,http://arxiv.org/pdf/2207.13404v1,eng,,,Computer Science
287,http://arxiv.org/abs/1906.10497v1,Characterizing IoT Data and its Quality for Use,"The Internet of Things (IoT) is a cyber physical social system thatencompasses science, enterprise and societal domains. Data is the mostimportant commodity in IoT, enabling the ""smarts"" through analytics anddecision making. IoT environments can generate and consume vast amounts ofdata. But managing this data effectively and gaining meaningful insights fromit requires us to understand its characteristics. Traditional scientific,enterprise and big data management approaches may not be adequate, and have toevolve. Further, these characteristics and the physical deployment environmentsalso impact the quality of the data for use. In this paper, we offer a taxonomyof IoT data characteristics, along with data quality considerations, that areconstructed from the ground-up based on the diverse IoT domains andapplications we review. We emphasize on the essential features, rather than avast array of attributes. We also indicate factors that influence the dataquality. Such a review is of value to IoT managers, data handlers andapplication composers in managing and making meaningful use of data, and forbig data platform developers to offer meaningful solutions to address theseconsiderations.","Nashez Zubair, Niranjan A, Kiran Hebbar, Yogesh Simmhan",2019-06-23T18:39:10Z,2019-06-23T18:39:10Z,"Tech Report on IoT Data and its Quality in light of various
  applications reviewed",cs.OH,http://arxiv.org/pdf/1906.10497v1,eng,,,Medicine
288,http://arxiv.org/abs/1910.08670v1,Context-Driven Data Mining through Bias Removal and Data Incompleteness  Mitigation,"The results of data mining endeavors are majorly driven by data quality.Throughout these deployments, serious show-stopper problems are stillunresolved, such as: data collection ambiguities, data imbalance, hidden biasesin data, the lack of domain information, and data incompleteness. This paper isbased on the premise that context can aid in mitigating these issues. In atraditional data science lifecycle, context is not considered. Context-drivenData Science Lifecycle (C-DSL); the main contribution of this paper, isdeveloped to address these challenges. Two case studies (using data-sets fromsports events) are developed to test C-DSL. Results from both case studies areevaluated using common data mining metrics such as: coefficient ofdetermination (R2 value) and confusion matrices. The work presented in thispaper aims to re-define the lifecycle and introduce tangible improvements toits outcomes.","Feras A. Batarseh, Ajay Kulkarni",2019-10-19T00:42:46Z,2019-10-19T00:42:46Z,"1st Workshop on Evaluation and Experimental Design in Data Mining and
  Machine Learning (EDML 2019) At SIAM - Society for Industrial and Applied
  Mathematics",cs.LG,http://arxiv.org/pdf/1910.08670v1,eng,,,Social Sciences
289,http://arxiv.org/abs/2406.13130v1,Advancing Retail Data Science: Comprehensive Evaluation of Synthetic  Data,"The evaluation of synthetic data generation is crucial, especially in theretail sector where data accuracy is paramount. This paper introduces acomprehensive framework for assessing synthetic retail data, focusing onfidelity, utility, and privacy. Our approach differentiates between continuousand discrete data attributes, providing precise evaluation criteria. Fidelityis measured through stability and generalizability. Stability ensures syntheticdata accurately replicates known data distributions, while generalizabilityconfirms its robustness in novel scenarios. Utility is demonstrated through thesynthetic data's effectiveness in critical retail tasks such as demandforecasting and dynamic pricing, proving its value in predictive analytics andstrategic planning. Privacy is safeguarded using Differential Privacy, ensuringsynthetic data maintains a perfect balance between resembling training andholdout datasets without compromising security. Our findings validate that thisframework provides reliable and scalable evaluation for synthetic retail data.It ensures high fidelity, utility, and privacy, making it an essential tool foradvancing retail data science. This framework meets the evolving needs of theretail industry with precision and confidence, paving the way for futureadvancements in synthetic data methodologies.","Yu Xia, Chi-Hua Wang, Joshua Mabry, Guang Cheng",2024-06-19T00:47:38Z,2024-06-19T00:47:38Z,,cs.LG,http://arxiv.org/pdf/2406.13130v1,eng,,,Computer Science
290,http://arxiv.org/abs/cs/0505008v1,Data Mining on Crash Simulation Data,The work presented in this paper is part of the cooperative research projectAUTO-OPT carried out by twelve partners from the automotive industries. Onemajor work package concerns the application of data mining methods in the areaof automotive design. Suitable methods for data preparation and data analysisare developed. The objective of the work is the re-use of data stored in thecrash-simulation department at BMW in order to gain deeper insight into theinterrelations between the geometric variations of the car during its designand its performance in crash testing. In this paper a method for data analysisof finite element models and results from crash simulation is proposed andapplication to recent data from the industrial partner BMW is demonstrated. Allnecessary steps from data pre-processing to re-integration into the workingenvironment of the engineer are covered.,"A. Kuhlmann, R. -M. Vetter, Ch. Luebbing, C. -A. Thole",2005-05-02T15:27:45Z,2005-05-02T15:27:45Z,"12 pages, 10 figures. Accepted for Lecture Notes in Computer Science
  (LNCS)",cs.IR,http://arxiv.org/pdf/cs/0505008v1,eng,,,Computer Science
291,http://arxiv.org/abs/1408.3170v1,The Value of Using Big Data Technologies in Computational Social Science,"The discovery of phenomena in social networks has prompted renewed interestsin the field. Data in social networks however can be massive, requiringscalable Big Data architecture. Conversely, research in Big Data needs thevolume and velocity of social media data for testing its scalability. Not onlyso, appropriate data processing and mining of acquired datasets involve complexissues in the variety, veracity, and variability of the data, after whichvisualisation must occur before we can see fruition in our efforts. Thisarticle presents topical, multimodal, and longitudinal social media datasetsfrom the integration of various scalable open source technologies. The articledetails the process that led to the discovery of social information landscapeswithin the Twitter social network, highlighting the experience of dealing withsocial media datasets, using a funneling approach so that data becomesmanageable. The article demonstrated the feasibility and value of usingscalable open source technologies for acquiring massive, connected datasets forresearch in the social sciences.",Eugene Ch'ng,2014-08-14T00:21:59Z,2014-08-14T00:21:59Z,"3rd ASE Big Data Science Conference, Tsinghua University Beijing, 3-7
  August 2014",cs.SI,http://arxiv.org/pdf/1408.3170v1,eng,,,Computer Science
292,http://arxiv.org/abs/1410.4839v2,The LIGO Open Science Center,"The LIGO Open Science Center (LOSC) fulfills LIGO's commitment to release,archive, and serve LIGO data in a broadly accessible way to the scientificcommunity and to the public, and to provide the information and tools necessaryto understand and use the data. In August 2014, the LOSC published the fulldataset from Initial LIGO's ""S5"" run at design sensitivity, the first suchlarge-scale release and a valuable testbed to explore the use of LIGO data bynon-LIGO researchers and by the public, and to help teach gravitational-wavedata analysis to students across the world. In addition to serving the S5 data,the LOSC web portal (losc.ligo.org) now offers documentation, data-location anddata-quality queries, tutorials and example code, and more. We review themission and plans of the LOSC, focusing on the S5 data release.","Michele Vallisneri, Jonah Kanner, Roy Williams, Alan Weinstein, Branson Stephens",2014-10-17T20:00:00Z,2015-01-01T23:29:52Z,"8 pages, 1 figure, proceedings of the 10th LISA Symposium, University
  of Florida, Gainesville, May 18-23, 2014; final published version; see
  losc.ligo.org for the S5 data release and more information about the LIGO
  Open Science Center",gr-qc,http://arxiv.org/pdf/1410.4839v2,eng,,,Medicine
293,http://arxiv.org/abs/1705.00070v1,Enabling Interactive Analytics of Secure Data using Cloud Kotta,"Research, especially in the social sciences and humanities, is increasinglyreliant on the application of data science methods to analyze large amounts of(often private) data. Secure data enclaves provide a solution for managing andanalyzing private data. However, such enclaves do not readily support discoveryscience---a form of exploratory or interactive analysis by which researchersexecute a range of (sometimes large) analyses in an iterative and collaborativemanner. The batch computing model offered by many data enclaves is well suitedto executing large compute tasks; however it is far from ideal for day-to-daydiscovery science. As researchers must submit jobs to queues and wait forresults, the high latencies inherent in queue-based, batch computing systemshinder interactive analysis. In this paper we describe how we have augmentedthe Cloud Kotta secure data enclave to support collaborative and interactiveanalysis of sensitive data. Our model uses Jupyter notebooks as a flexibleanalysis environment and Python language constructs to support the execution ofarbitrary functions on private data within this secure framework.","Yadu N. Babuji, Kyle Chard, Eamon Duede",2017-04-28T20:41:17Z,2017-04-28T20:41:17Z,"To appear in Proceedings of Workshop on Scientific Cloud Computing,
  Washington, DC USA, June 2017 (ScienceCloud 2017), 7 pages",cs.DC,http://arxiv.org/pdf/1705.00070v1,eng,,,Computer Science
294,http://arxiv.org/abs/2012.10444v1,"The Automated Data Extraction, Processing, and Tracking System for  CHARIS","CHARIS is an IFS designed for imaging and spectroscopy of disks andsub-stellar companions. To improve ease of use and efficiency of scienceproduction, we present progress on a fully-automated backend for CHARIS. ThisAutomated Data Extraction, Processing, and Tracking System (ADEPTS) will logdata files from CHARIS in a searchable database and perform all calibration anddata extraction, yielding science-grade data cubes. The extracted data willalso be run through a preset array of post-processing routines. Withsignificant parallelization of data processing, ADEPTS will dramatically reducethe time between data acquisition and the availability of science-grade dataproducts.","Taylor L. Tobin, Jeffery Chilcote, Timothy Brandt, Thayne Currie, Tyler Groff, Julien Lozi, Olivier Guyon",2020-12-18T18:59:52Z,2020-12-18T18:59:52Z,,astro-ph.IM,http://arxiv.org/pdf/2012.10444v1,eng,,,Medicine
295,http://arxiv.org/abs/2205.08018v1,A Survey on Semantics in Automated Data Science,"Data Scientists leverage common sense reasoning and domain knowledge tounderstand and enrich data for building predictive models. In recent years, wehave witnessed a surge in tools and techniques for {\em automated machinelearning}. While data scientists can employ various such tools to help withmodel building, many other aspects such as {\em feature engineering} thatrequire semantic understanding of concepts, remain manual to a large extent. Inthis paper we discuss important shortcomings of current automated data sciencesolutions and machine learning. We discuss how leveraging basic semanticreasoning on data in combination with novel tools for data science automationcan help with consistent and explainable data augmentation and transformation.Moreover, semantics can assist data scientists in a new manner by helping withchallenges related to {\em trust}, {\em bias}, and {\em explainability}.","Udayan Khurana, Kavitha Srinivas, Horst Samulowitz",2022-05-16T23:16:09Z,2022-05-16T23:16:09Z,,cs.AI,http://arxiv.org/pdf/2205.08018v1,eng,,,Medicine
296,http://arxiv.org/abs/1512.00127v1,The cost of reading research. A study of Computer Science publication  venues,"What does the cost of academic publishing look like to the common researchertoday? Our goal is to convey the current state of academic publishing,specifically in regards to the field of computer science and provide analysisand data to be used as a basis for future studies. We will focus on author andreader costs as they are the primary points of interaction within thepublishing world. In this work, we restrict our focus to only computer sciencein order to make the data collection more feasible (the authors are computerscientists) and hope future work can analyze and collect data across allacademic fields.","Joseph Paul Cohen, Carla Aravena, Wei Ding",2015-12-01T03:09:55Z,2015-12-01T03:09:55Z,,cs.DL,http://arxiv.org/pdf/1512.00127v1,eng,,,Medicine
297,http://arxiv.org/abs/1906.07011v1,Accuracy of citation data in Web of Science and Scopus,We present a large-scale analysis of the accuracy of citation data in the Webof Science and Scopus databases. The analysis is based on citations given inpublications in Elsevier journals. We reveal significant data quality problemsfor both databases. Missing and incorrect references are important problems inWeb of Science. Duplicate publications are a serious problem in Scopus.,"Nees Jan van Eck, Ludo Waltman",2019-06-17T13:03:45Z,2019-06-17T13:03:45Z,"Paper published in the Proceedings of the 16th International
  Conference of the International Society for Scientometrics and Informetrics
  (pp. 1087-1092)",cs.DL,http://arxiv.org/pdf/1906.07011v1,eng,,,Medicine
298,http://arxiv.org/abs/2101.06751v2,The KM3NeT Open Science System,"The KM3NeT neutrino detectors are currently under construction at twolocations in the Mediterranean Sea, aiming to detect the Cherenkov lightgenerated by high-energy relativistic charged particles in sea water. TheKM3NeT collaboration will produce scientific data valuable both for theastrophysics and neutrino physics communities as well as for the Earth and Seascience community. An Open Science Portal and infrastructure are underdevelopment to provide public access to open KM3NeT data, software andservices. In this contribution, the current architecture, interfaces and usageexamples are presented.","Jutta Schnabel, Tamas Gal, Zineb Aly",2021-01-17T18:56:35Z,2021-01-22T15:38:23Z,"4 pages, to appear in the proceedings of Astronomical Data Analysis
  Software and Systems XXX published by ASP",astro-ph.IM,http://arxiv.org/pdf/2101.06751v2,eng,,,Social Sciences
299,http://arxiv.org/abs/2208.09672v1,Comparing graph data science libraries for querying and analysing  datasets: towards data science queries on graphs,"This paper presents an experimental study to compare analysis tools withmanagement systems for querying and analysing graphs. Our experiment comparesclassic graph navigational operations queries where analytics tools andmanagement systems adopt different execution strategies. Then, our experimentaddresses data science pipelines with clustering and prediction models appliedto graphs. In this kind of experiment, we underline the interest in combiningboth approaches and the interest of relying on a parallel execution platformfor executing queries.","Genoveva Vargas-Solar, Pierre Marrec, Mirian Halfeld Ferrari Alves",2022-08-20T12:34:18Z,2022-08-20T12:34:18Z,,cs.DB,http://arxiv.org/pdf/2208.09672v1,eng,,,Computer Science
